{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-02T22:51:44.410607Z","iopub.execute_input":"2025-10-02T22:51:44.410944Z","iopub.status.idle":"2025-10-02T22:51:44.420756Z","shell.execute_reply.started":"2025-10-02T22:51:44.410918Z","shell.execute_reply":"2025-10-02T22:51:44.419647Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"tfx version 1.16.0 is latest stable as of Sep 28, 2025\n\nIt is compatible with python 3.9 and 3.10 only.\n\nThe current kaggle python docker image uses python 3.11.13.\n\nTo use an earlier version of python on Kaggle, one can install conda and create a virtual environment that is based on an earlier version of python. \n\nOnce conda is installed and a virtual environment is created for the earlier version of python, the virtual environment can be activated by activating conda and then activating the virtual environment.\n\nA bash shell in the notebook that is invoked from the magic command %%bash is a bash session for the extent of that specific cell.\nFor each new session invoked by the cell %%bash, the 2 activation commands need to be invoked before using the virtual environment.\n\nAside from running scripts in the magic bash shell cells, we can also run scripts using the python subprocess library as long as we prepend commands with the 2 conda activation statements (see details in the definition for the run_command below).\n\nWe have 2 ways to run commands within the virtual environment.\n\nThe notebook itself is still using the kaggle docker image environment without the newly built virtual environment.\nEven if we install and use ipykernel to register a kernel for the new virtual environment, I don't see a way to open the notebook to use the new kernel.\n\nSo, the notebook can be used for intermediate steps of EDA that \nuse libraries that don't require an earlier version of python, else the virtual environment for anything needing earlier python version.\n","metadata":{}},{"cell_type":"code","source":"!pwd\n!echo $HOME","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T22:51:44.422519Z","iopub.execute_input":"2025-10-02T22:51:44.422873Z","iopub.status.idle":"2025-10-02T22:51:44.670112Z","shell.execute_reply.started":"2025-10-02T22:51:44.422814Z","shell.execute_reply":"2025-10-02T22:51:44.669179Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n/root\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"%%bash: Executes the entire cell as a shell script. ","metadata":{}},{"cell_type":"code","source":"%%bash\nt0=$(date +%s%N)\nmkdir -p ~/miniconda3\nwget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n#install conda and activate to /usr/local\nbash ~/miniconda3/miniconda.sh -b -u -p /usr/local\nrm ~/miniconda3/miniconda.sh\nconda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\nconda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n\n. /usr/local/bin/activate\necho \"**$SHELL**\"\necho \"**$BASH**\"\nconda init --all\n\n. /root/.bashrc\nconda create -q --name my_tfx_env python=3.10 -y\nconda activate my_tfx_env\npython --version\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T22:51:44.671176Z","iopub.execute_input":"2025-10-02T22:51:44.671409Z","iopub.status.idle":"2025-10-02T22:52:22.040026Z","shell.execute_reply.started":"2025-10-02T22:51:44.671384Z","shell.execute_reply":"2025-10-02T22:52:22.039290Z"}},"outputs":[{"name":"stdout","text":"PREFIX=/usr/local\nUnpacking bootstrapper...\nUnpacking payload...\n\nInstalling base environment...\n\nPreparing transaction: ...working... done\nExecuting transaction: ...working... done\ninstallation finished.\nWARNING:\n    You currently have a PYTHONPATH environment variable set. This may cause\n    unexpected behavior when running the Python interpreter in Miniconda3.\n    For best results, please verify that your PYTHONPATH only points to\n    directories of packages that are compatible with the Python interpreter\n    in Miniconda3: /usr/local\naccepted Terms of Service for https://repo.anaconda.com/pkgs/main\naccepted Terms of Service for https://repo.anaconda.com/pkgs/r\n**/bin/bash**\n**/usr/bin/bash**\nno change     /usr/local/condabin/conda\nno change     /usr/local/bin/conda\nno change     /usr/local/bin/conda-env\nno change     /usr/local/bin/activate\nno change     /usr/local/bin/deactivate\nno change     /usr/local/etc/profile.d/conda.sh\nno change     /usr/local/etc/fish/conf.d/conda.fish\nno change     /usr/local/shell/condabin/Conda.psm1\nno change     /usr/local/shell/condabin/conda-hook.ps1\nno change     /usr/local/lib/python3.13/site-packages/xontrib/conda.xsh\nno change     /usr/local/etc/profile.d/conda.csh\nmodified      /root/.bashrc\nmodified      /root/.zshrc\nmodified      /root/.config/fish/config.fish\nmodified      /root/.xonshrc\nmodified      /root/.tcshrc\n\n==> For changes to take effect, close and re-open your current shell. <==\n\n2 channel Terms of Service accepted\nRetrieving notices: ...working... done\nChannels:\n - defaults\nPlatform: linux-64\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\n## Package Plan ##\n\n  environment location: /usr/local/envs/my_tfx_env\n\n  added / updated specs:\n    - python=3.10\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2025.9.9   |       h06a4308_0         127 KB\n    libzlib-1.3.1              |       hb25bd0a_0          59 KB\n    pip-25.2                   |     pyhc872135_0         1.2 MB\n    python-3.10.18             |       h1a3bd86_0        26.5 MB\n    setuptools-78.1.1          |  py310h06a4308_0         1.7 MB\n    wheel-0.45.1               |  py310h06a4308_0         115 KB\n    zlib-1.3.1                 |       hb25bd0a_0          96 KB\n    ------------------------------------------------------------\n                                           Total:        29.8 MB\n\nThe following NEW packages will be INSTALLED:\n\n  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 \n  ca-certificates    pkgs/main/linux-64::ca-certificates-2025.9.9-h06a4308_0 \n  expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 \n  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.40-h12ee557_0 \n  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n  libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 \n  libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 \n  libzlib            pkgs/main/linux-64::libzlib-1.3.1-hb25bd0a_0 \n  ncurses            pkgs/main/linux-64::ncurses-6.5-h7934f7d_0 \n  openssl            pkgs/main/linux-64::openssl-3.0.17-h5eee18b_0 \n  pip                pkgs/main/noarch::pip-25.2-pyhc872135_0 \n  pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 \n  python             pkgs/main/linux-64::python-3.10.18-h1a3bd86_0 \n  readline           pkgs/main/linux-64::readline-8.3-hc2a1206_0 \n  setuptools         pkgs/main/linux-64::setuptools-78.1.1-py310h06a4308_0 \n  sqlite             pkgs/main/linux-64::sqlite-3.50.2-hb25bd0a_1 \n  tk                 pkgs/main/linux-64::tk-8.6.15-h54e0aa7_0 \n  tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 \n  wheel              pkgs/main/linux-64::wheel-0.45.1-py310h06a4308_0 \n  xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 \n  xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 \n  xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 \n  xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 \n  xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n  zlib               pkgs/main/linux-64::zlib-1.3.1-hb25bd0a_0 \n\n\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\nPython 3.10.18\n37.338952360 seconds\nThu Oct  2 10:52:22 PM UTC 2025\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"to activate the conda environment, need to source from conda's activate (which I installed in /usr/local/bin above), then activate the conda virtual environment.\n\nthis has to be done for each magic shell cell","metadata":{}},{"cell_type":"code","source":"%%bash\nt0=$(date +%s%N)\n. /usr/local/bin/activate\nconda activate my_tfx_env\npython --version\n\n#consider conda install ipykernel\nconda install pip\n\n#see dependencies https://github.com/tensorflow/transform\npip -q install pyarrow==10.0.1\npip -q install apache-beam==2.59.0\npip -q install tensorflow==2.16.1\npip -q install tensorflow-transform==1.16.0\npip -q install tfx==1.16.0\n#\n#tf metadata 1.16.1\n#tfx-bsl\n#keeps protobuf 3.20.3\n#if use sparkrunner, install pyspark 4.0.0 or 3.3.x\n\npip list\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 60000000000\" | bc)\necho \"$t2 minutes\"\ndate\n#about 6-7 minutes for this cell.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T22:52:22.041482Z","iopub.execute_input":"2025-10-02T22:52:22.042174Z","iopub.status.idle":"2025-10-02T22:59:20.114024Z","shell.execute_reply.started":"2025-10-02T22:52:22.042150Z","shell.execute_reply":"2025-10-02T22:59:20.112801Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\n2 channel Terms of Service accepted\nChannels:\n - defaults\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n# All requested packages already installed.\n\nPackage                            Version\n---------------------------------- --------------\nabsl-py                            1.4.0\nannotated-types                    0.7.0\nanyio                              4.11.0\napache-beam                        2.59.0\nargon2-cffi                        25.1.0\nargon2-cffi-bindings               25.1.0\narrow                              1.3.0\nastunparse                         1.6.3\nasync-lru                          2.0.5\nasync-timeout                      5.0.1\nattrs                              23.2.0\nbabel                              2.17.0\nbackcall                           0.2.0\nbeautifulsoup4                     4.14.2\nbleach                             6.2.0\ncachetools                         5.5.2\ncertifi                            2025.8.3\ncffi                               2.0.0\ncharset-normalizer                 3.4.3\nclick                              8.3.0\ncloudpickle                        2.2.1\ncolorama                           0.4.6\ncomm                               0.2.3\ncrcmod                             1.7\ndebugpy                            1.8.17\ndecorator                          5.2.1\ndefusedxml                         0.7.1\ndill                               0.3.1.1\ndnspython                          2.8.0\ndocker                             7.1.0\ndocopt                             0.6.2\ndocstring_parser                   0.17.0\nexceptiongroup                     1.3.0\nfastavro                           1.12.0\nfasteners                          0.20\nfastjsonschema                     2.21.2\nflatbuffers                        25.9.23\nfqdn                               1.5.1\ngast                               0.6.0\ngoogle-api-core                    2.25.1\ngoogle-api-python-client           1.12.11\ngoogle-apitools                    0.5.31\ngoogle-auth                        2.41.1\ngoogle-auth-httplib2               0.2.0\ngoogle-cloud-aiplatform            1.118.0\ngoogle-cloud-bigquery              3.38.0\ngoogle-cloud-bigquery-storage      2.33.1\ngoogle-cloud-bigtable              2.32.0\ngoogle-cloud-core                  2.4.3\ngoogle-cloud-datastore             2.21.0\ngoogle-cloud-dlp                   3.32.0\ngoogle-cloud-language              2.17.2\ngoogle-cloud-pubsub                2.31.1\ngoogle-cloud-pubsublite            1.12.0\ngoogle-cloud-recommendations-ai    0.10.18\ngoogle-cloud-resource-manager      1.14.2\ngoogle-cloud-spanner               3.58.0\ngoogle-cloud-storage               2.19.0\ngoogle-cloud-videointelligence     2.16.2\ngoogle-cloud-vision                3.10.2\ngoogle-crc32c                      1.7.1\ngoogle-genai                       1.41.0\ngoogle-pasta                       0.2.0\ngoogle-resumable-media             2.7.2\ngoogleapis-common-protos           1.70.0\ngrpc-google-iam-v1                 0.14.2\ngrpc-interceptor                   0.15.4\ngrpcio                             1.75.1\ngrpcio-status                      1.49.0rc1\nh11                                0.16.0\nh5py                               3.14.0\nhdfs                               2.7.3\nhttpcore                           1.0.9\nhttplib2                           0.22.0\nhttpx                              0.28.1\nidna                               3.10\nimportlib_metadata                 8.7.0\nipykernel                          6.30.1\nipython                            7.34.0\nipython-genutils                   0.2.0\nipywidgets                         7.8.5\nisoduration                        20.11.0\njedi                               0.19.2\nJinja2                             3.1.6\njoblib                             1.5.2\nJs2Py                              0.74\njson5                              0.12.1\njsonpickle                         3.4.2\njsonpointer                        3.0.0\njsonschema                         4.25.1\njsonschema-specifications          2025.9.1\njupyter_client                     8.6.3\njupyter_core                       5.8.1\njupyter-events                     0.12.0\njupyter-lsp                        2.3.0\njupyter_server                     2.17.0\njupyter_server_terminals           0.5.3\njupyterlab                         4.4.9\njupyterlab_pygments                0.3.0\njupyterlab_server                  2.27.3\njupyterlab_widgets                 1.1.11\nkeras                              3.11.3\nkeras-tuner                        1.4.7\nkt-legacy                          1.0.5\nkubernetes                         26.1.0\nlark                               1.3.0\nlibclang                           18.1.1\nlxml                               6.0.2\nMarkdown                           3.9\nmarkdown-it-py                     4.0.0\nMarkupSafe                         3.0.3\nmatplotlib-inline                  0.1.7\nmdurl                              0.1.2\nmistune                            3.1.4\nml-dtypes                          0.3.2\nml-metadata                        1.16.0\nml-pipelines-sdk                   1.16.0\nnamex                              0.1.0\nnbclient                           0.10.2\nnbconvert                          7.16.6\nnbformat                           5.10.4\nnest-asyncio                       1.6.0\nnltk                               3.9.2\nnotebook                           7.4.7\nnotebook_shim                      0.2.4\nnumpy                              1.26.4\noauth2client                       4.1.3\noauthlib                           3.3.1\nobjsize                            0.7.1\nopentelemetry-api                  1.37.0\nopentelemetry-sdk                  1.37.0\nopentelemetry-semantic-conventions 0.58b0\nopt_einsum                         3.4.0\noptree                             0.17.0\norjson                             3.11.3\noverrides                          7.7.0\npackaging                          25.0\npandas                             1.5.3\npandocfilters                      1.5.1\nparso                              0.8.5\npexpect                            4.9.0\npickleshare                        0.7.5\npillow                             11.3.0\npip                                25.2\nplatformdirs                       4.4.0\nportalocker                        3.2.0\nportpicker                         1.6.0\nprometheus_client                  0.23.1\nprompt_toolkit                     3.0.52\nproto-plus                         1.26.1\nprotobuf                           3.20.3\npsutil                             7.1.0\nptyprocess                         0.7.0\npyarrow                            10.0.1\npyarrow-hotfix                     0.7\npyasn1                             0.6.1\npyasn1_modules                     0.4.2\npycparser                          2.23\npydantic                           2.11.9\npydantic_core                      2.33.2\npydot                              1.4.2\npyfarmhash                         0.3.2\nPygments                           2.19.2\npyjsparser                         2.7.1\nPyJWT                              2.10.1\npymongo                            4.15.2\npyparsing                          3.2.5\npython-dateutil                    2.9.0.post0\npython-json-logger                 3.3.0\npytz                               2025.2\nPyYAML                             6.0.3\npyzmq                              27.1.0\nredis                              5.3.1\nreferencing                        0.36.2\nregex                              2025.9.18\nrequests                           2.32.5\nrequests-oauthlib                  2.0.0\nrfc3339-validator                  0.1.4\nrfc3986-validator                  0.1.1\nrfc3987-syntax                     1.1.0\nrich                               14.1.0\nrouge_score                        0.1.2\nrpds-py                            0.27.1\nrsa                                4.9.1\nsacrebleu                          2.5.1\nscikit-learn                       1.5.1\nscipy                              1.12.0\nSend2Trash                         1.8.3\nsetuptools                         78.1.1\nshapely                            2.1.2\nsix                                1.17.0\nsniffio                            1.3.1\nsoupsieve                          2.8\nsqlparse                           0.5.3\ntabulate                           0.9.0\ntenacity                           9.1.2\ntensorboard                        2.16.2\ntensorboard-data-server            0.7.2\ntensorflow                         2.16.1\ntensorflow-data-validation         1.16.1\ntensorflow-estimator               2.15.0\ntensorflow-hub                     0.15.0\ntensorflow-io-gcs-filesystem       0.37.1\ntensorflow-metadata                1.16.1\ntensorflow_model_analysis          0.47.1\ntensorflow-serving-api             2.16.1\ntensorflow-transform               1.16.0\ntermcolor                          3.1.0\nterminado                          0.18.1\ntf_keras                           2.16.0\ntfx                                1.16.0\ntfx-bsl                            1.16.1\nthreadpoolctl                      3.6.0\ntinycss2                           1.4.0\ntomli                              2.2.1\ntornado                            6.5.2\ntqdm                               4.67.1\ntraitlets                          5.14.3\ntypes-python-dateutil              2.9.0.20250822\ntyping_extensions                  4.15.0\ntyping-inspection                  0.4.2\ntzlocal                            5.3.1\nuri-template                       1.3.0\nuritemplate                        3.0.1\nurllib3                            2.5.0\nwcwidth                            0.2.14\nwebcolors                          24.11.1\nwebencodings                       0.5.1\nwebsocket-client                   1.8.0\nwebsockets                         15.0.1\nWerkzeug                           3.1.3\nwheel                              0.45.1\nwidgetsnbextension                 3.6.10\nwrapt                              1.17.3\nzipp                               3.23.0\nzstandard                          0.25.0\n6.967355561 minutes\nThu Oct  2 10:59:20 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"\n\n==> WARNING: A newer version of conda exists. <==\n    current version: 25.7.0\n    latest version: 25.9.0\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n  DEPRECATION: Building 'crcmod' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'crcmod'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'dill' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'dill'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'hdfs' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'hdfs'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'pyjsparser' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pyjsparser'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'docopt' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'docopt'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'google-apitools' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'google-apitools'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'pyfarmhash' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pyfarmhash'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'rouge-score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge-score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%%bash\n. /usr/local/bin/activate\nconda activate my_tfx_env\npython --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T22:59:20.117141Z","iopub.execute_input":"2025-10-02T22:59:20.117465Z","iopub.status.idle":"2025-10-02T22:59:21.807095Z","shell.execute_reply.started":"2025-10-02T22:59:20.117434Z","shell.execute_reply":"2025-10-02T22:59:21.806206Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"The run_command is from\nhttps://www.kaggle.com/code/taylorsamarel/change-python-version-kaggle-v2-taylor-amarel","metadata":{}},{"cell_type":"code","source":"import subprocess\ndef run_command(cmd, capture=True, check=False):\n    cmds = f\". /usr/local/bin/activate; conda activate my_tfx_env; {cmd}\"\n    try:\n        result = subprocess.run(cmds, shell=True, capture_output=capture, text=True, check=check)\n        if capture:\n            return result.stdout.strip() if result.stdout else result.stderr.strip()\n        return result.returncode == 0\n    except Exception as e:\n        return str(e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T22:59:21.808330Z","iopub.execute_input":"2025-10-02T22:59:21.808674Z","iopub.status.idle":"2025-10-02T22:59:21.815657Z","shell.execute_reply.started":"2025-10-02T22:59:21.808645Z","shell.execute_reply":"2025-10-02T22:59:21.814671Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(run_command(\"python --version\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T22:59:21.816537Z","iopub.execute_input":"2025-10-02T22:59:21.816780Z","iopub.status.idle":"2025-10-02T22:59:23.428324Z","shell.execute_reply.started":"2025-10-02T22:59:21.816759Z","shell.execute_reply":"2025-10-02T22:59:23.427481Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"%%bash\nwget -q http://files.grouplens.org/datasets/movielens/ml-1m.zip -O /kaggle/working/ml-1m.zip\nunzip -o /kaggle/working/ml-1m.zip\nls /kaggle/working/ml-1m/\nrm /kaggle/working/ml-1m.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T22:59:23.429169Z","iopub.execute_input":"2025-10-02T22:59:23.429421Z","iopub.status.idle":"2025-10-02T22:59:25.371084Z","shell.execute_reply.started":"2025-10-02T22:59:23.429402Z","shell.execute_reply":"2025-10-02T22:59:25.370342Z"}},"outputs":[{"name":"stdout","text":"Archive:  /kaggle/working/ml-1m.zip\n   creating: ml-1m/\n  inflating: ml-1m/movies.dat        \n  inflating: ml-1m/ratings.dat       \n  inflating: ml-1m/README            \n  inflating: ml-1m/users.dat         \nmovies.dat\nratings.dat\nREADME\nusers.dat\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"%%bash\n#it can take a couple of minutes to get current version of recently uploaded file to github\n#wget -q -c --no-cache https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/main/src/test/python/test_tft.py -O /kaggle/working/test_tft.py\n#curl --header \"Cache-Control: no-cache\" \"https://api.github.com/repos/nking/recommender_systems/content/src/test/python/test_tft.py\" -o /kaggle/working/test_tft.py\n\nrm -f /kaggle/working/dataset_tfxio_example.py\nwget -q -c --no-cache https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/main/src/test/python/dataset_tfxio_example.py -O /kaggle/working/dataset_tfxio_example.py\n#ls -l /kaggle/working/\n\nrepo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/main/python'\ndeclare -a my_files=(\"ingest_movie_lens_beam.py\" \"CustomUTF8Coder.py\" \"ingest_movie_lens_component.py\" \"partition_funcs.py\" \"stringify_ingest_params.py\")\nfor item in \"${my_files[@]}\"\ndo\n  rm -f \"/kaggle/working/$item\"\n  echo \"$item\"\n  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\ndone\n\nrepo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/drafts/python'\ndeclare -a my_files=(\"ingest_movie_lens_tfx.py\")\nfor item in \"${my_files[@]}\"\ndo\n  rm -f \"/kaggle/working/$item\"\n  echo \"$item\"\n  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\ndone\n\n#repo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/test/python'\n#declare -a my_files=(\"IngestMovieLensComponentTest.py\")\n#for item in \"${my_files[@]}\"\n#do\n#  rm -f \"/kaggle/working/$item\"\n#  echo \"$item\"\n#  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\n#done\n\nls -l /kaggle/working/\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T00:13:45.936785Z","iopub.execute_input":"2025-10-03T00:13:45.937674Z","iopub.status.idle":"2025-10-03T00:13:47.179315Z","shell.execute_reply.started":"2025-10-03T00:13:45.937647Z","shell.execute_reply":"2025-10-03T00:13:47.178634Z"}},"outputs":[{"name":"stdout","text":"ingest_movie_lens_beam.py\nCustomUTF8Coder.py\ningest_movie_lens_component.py\npartition_funcs.py\nstringify_ingest_params.py\ningest_movie_lens_tfx.py\ntotal 80\ndrwxr-xr-x 4 root root  4096 Oct  2 23:22 bin\n-rw-r--r-- 1 root root   756 Oct  3 00:13 CustomUTF8Coder.py\n-rw-r--r-- 1 root root  2399 Oct  3 00:13 dataset_tfxio_example.py\n-rw-r--r-- 1 root root 11011 Oct  3 00:13 ingest_movie_lens_beam.py\n-rw-r--r-- 1 root root  8836 Oct  3 00:13 ingest_movie_lens_component.py\n-rw-r--r-- 1 root root  4112 Oct  2 22:59 IngestMovieLensComponentTest.py\n-rw-r--r-- 1 root root 18824 Oct  3 00:13 ingest_movie_lens_tfx.py\ndrwxr-x--- 2 root root  4096 Jan 29  2016 ml-1m\n-rw-r--r-- 1 root root  2707 Oct  3 00:13 partition_funcs.py\ndrwxr-xr-x 2 root root  4096 Oct  3 00:06 __pycache__\n-rw-r--r-- 1 root root  2206 Oct  3 00:13 stringify_ingest_params.py\nFri Oct  3 12:13:47 AM UTC 2025\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"#test that TFX and associated libraries are compatible:\nprint(run_command(\"python3 /kaggle/working/dataset_tfxio_example.py\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T22:59:26.660770Z","iopub.execute_input":"2025-10-02T22:59:26.661523Z","iopub.status.idle":"2025-10-02T22:59:39.083131Z","shell.execute_reply.started":"2025-10-02T22:59:26.661501Z","shell.execute_reply":"2025-10-02T22:59:39.082037Z"}},"outputs":[{"name":"stdout","text":"{'x_centered': [[-4.0], [-3.0], [-2.0], [-1.0], [0.0]],\n 'x_scaled': [[0.0], [0.125], [0.25], [0.375], [0.5]]}\n{'x_centered': [[1.0], [2.0], [3.0], [4.0]],\n 'x_scaled': [[0.625], [0.75], [0.875], [1.0]]}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run ingest using beam and TFX for python custom component\"\n\nt0=$(date +%s%N)\n\npython /kaggle/working/ingest_movie_lens_component.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T00:13:54.657950Z","iopub.execute_input":"2025-10-03T00:13:54.658876Z","iopub.status.idle":"2025-10-03T00:14:58.611947Z","shell.execute_reply.started":"2025-10-03T00:13:54.658847Z","shell.execute_reply":"2025-10-03T00:14:58.611128Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun ingest using beam and TFX for python custom component\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\nbegin test\ntests done\n62.280741259 seconds\nFri Oct  3 12:14:58 AM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"INFO:absl:Using deployment config:\n executor_specs {\n  key: \"ingest_movie_lens_component\"\n  value {\n    beam_executable_spec {\n      python_executor_spec {\n        class_path: \"__main__.ingest_movie_lens_component_Executor\"\n      }\n    }\n  }\n}\nmetadata_connection_config {\n  database_connection_config {\n    sqlite {\n      filename_uri: \"/kaggle/working/bin/metadata/movie_ens_ingest_test/metadata.db\"\n      connection_mode: READWRITE_OPENCREATE\n    }\n  }\n}\n\nINFO:absl:Using connection config:\n sqlite {\n  filename_uri: \"/kaggle/working/bin/metadata/movie_ens_ingest_test/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component ingest_movie_lens_component is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"__main__.ingest_movie_lens_component\"\n  }\n  id: \"ingest_movie_lens_component\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"movie_ens_ingest_test\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-03T00:14:05.407228\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"movie_ens_ingest_test.ingest_movie_lens_component\"\n      }\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"output_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"bucket_names\"\n    value {\n      field_value {\n        string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n      }\n    }\n  }\n  parameters {\n    key: \"buckets\"\n    value {\n      field_value {\n        string_value: \"[80, 10, 10]\"\n      }\n    }\n  }\n  parameters {\n    key: \"delim\"\n    value {\n      field_value {\n        string_value: \"::\"\n      }\n    }\n  }\n  parameters {\n    key: \"headers_present\"\n    value {\n      field_value {\n        string_value: \"false\"\n      }\n      schema {\n        value_type {\n          boolean_type {\n          }\n        }\n      }\n    }\n  }\n  parameters {\n    key: \"movies_key_col_dict\"\n    value {\n      field_value {\n        string_value: \"{\\\"movie_id\\\": 0, \\\"title\\\": 1, \\\"genres\\\": 2}\"\n      }\n    }\n  }\n  parameters {\n    key: \"movies_uri\"\n    value {\n      field_value {\n        string_value: \"/kaggle/working/ml-1m/movies.dat\"\n      }\n    }\n  }\n  parameters {\n    key: \"ratings_key_col_dict\"\n    value {\n      field_value {\n        string_value: \"{\\\"user_id\\\": 0, \\\"movie_id\\\": 1, \\\"rating\\\": 2, \\\"timestamp\\\": 3}\"\n      }\n    }\n  }\n  parameters {\n    key: \"ratings_uri\"\n    value {\n      field_value {\n        string_value: \"/kaggle/working/ml-1m/ratings.dat\"\n      }\n    }\n  }\n  parameters {\n    key: \"users_key_col_dict\"\n    value {\n      field_value {\n        string_value: \"{\\\"user_id\\\": 0, \\\"gender\\\": 1, \\\"age\\\": 2, \\\"occupation\\\": 3, \\\"zipcode\\\": 4}\"\n      }\n    }\n  }\n  parameters {\n    key: \"users_uri\"\n    value {\n      field_value {\n        string_value: \"/kaggle/working/ml-1m/users.dat\"\n      }\n    }\n  }\n}\nexecution_options {\n  caching_options {\n    enable_cache: true\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/metadata/movie_ens_ingest_test/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type pipeline_run and name 2025-10-03T00:14:05.407228\nDEBUG:absl:ID of context type {\n  name: \"pipeline_run\"\n}\nname {\n  field_value {\n    string_value: \"2025-10-03T00:14:05.407228\"\n  }\n}\n is 11.\nDEBUG:absl:Before conditional:\n{}\nDEBUG:absl:After conditional:\n{}\nINFO:absl:[ingest_movie_lens_component] Resolved inputs: ({},)\nDEBUG:absl:Prepared EXECUTION:\n type_id: 13\nlast_known_state: RUNNING\ncustom_properties {\n  key: \"__schema__headers_present__\"\n  value {\n    string_value: \"{\\n  \\\"value_type\\\": {\\n    \\\"boolean_type\\\": {}\\n  }\\n}\"\n  }\n}\ncustom_properties {\n  key: \"bucket_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\ncustom_properties {\n  key: \"buckets\"\n  value {\n    string_value: \"[80, 10, 10]\"\n  }\n}\ncustom_properties {\n  key: \"delim\"\n  value {\n    string_value: \"::\"\n  }\n}\ncustom_properties {\n  key: \"headers_present\"\n  value {\n    string_value: \"false\"\n  }\n}\ncustom_properties {\n  key: \"movies_key_col_dict\"\n  value {\n    string_value: \"{\\\"movie_id\\\": 0, \\\"title\\\": 1, \\\"genres\\\": 2}\"\n  }\n}\ncustom_properties {\n  key: \"movies_uri\"\n  value {\n    string_value: \"/kaggle/working/ml-1m/movies.dat\"\n  }\n}\ncustom_properties {\n  key: \"ratings_key_col_dict\"\n  value {\n    string_value: \"{\\\"user_id\\\": 0, \\\"movie_id\\\": 1, \\\"rating\\\": 2, \\\"timestamp\\\": 3}\"\n  }\n}\ncustom_properties {\n  key: \"ratings_uri\"\n  value {\n    string_value: \"/kaggle/working/ml-1m/ratings.dat\"\n  }\n}\ncustom_properties {\n  key: \"users_key_col_dict\"\n  value {\n    string_value: \"{\\\"user_id\\\": 0, \\\"gender\\\": 1, \\\"age\\\": 2, \\\"occupation\\\": 3, \\\"zipcode\\\": 4}\"\n  }\n}\ncustom_properties {\n  key: \"users_uri\"\n  value {\n    string_value: \"/kaggle/working/ml-1m/users.dat\"\n  }\n}\nname: \"eb1d7fbd-b649-4c05-be50-fddd021b4ca2\"\n\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/pipelines/movie_ens_ingest_test/ingest_movie_lens_component/output_examples/8\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/metadata/movie_ens_ingest_test/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Going to run a new execution 8\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1759450445.467093    1387 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=8, input_dict={}, output_dict=defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/pipelines/movie_ens_ingest_test/ingest_movie_lens_component/output_examples/8\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}), exec_properties={'ratings_uri': '/kaggle/working/ml-1m/ratings.dat', 'delim': '::', 'bucket_names': '[\"train\", \"eval\", \"test\"]', 'movies_uri': '/kaggle/working/ml-1m/movies.dat', 'headers_present': False, 'users_uri': '/kaggle/working/ml-1m/users.dat', 'ratings_key_col_dict': '{\"user_id\": 0, \"movie_id\": 1, \"rating\": 2, \"timestamp\": 3}', 'buckets': '[80, 10, 10]', 'movies_key_col_dict': '{\"movie_id\": 0, \"title\": 1, \"genres\": 2}', 'users_key_col_dict': '{\"user_id\": 0, \"gender\": 1, \"age\": 2, \"occupation\": 3, \"zipcode\": 4}'}, execution_output_uri='/kaggle/working/bin/pipelines/movie_ens_ingest_test/ingest_movie_lens_component/.system/executor_execution/8/executor_output.pb', stateful_working_dir='/kaggle/working/bin/pipelines/movie_ens_ingest_test/ingest_movie_lens_component/.system/stateful_working_dir/422a9e14-4026-4f00-a9aa-718c972656ad', tmp_dir='/kaggle/working/bin/pipelines/movie_ens_ingest_test/ingest_movie_lens_component/.system/executor_execution/8/.temp/', pipeline_node=node_info {\n  type {\n    name: \"__main__.ingest_movie_lens_component\"\n  }\n  id: \"ingest_movie_lens_component\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"movie_ens_ingest_test\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-03T00:14:05.407228\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"movie_ens_ingest_test.ingest_movie_lens_component\"\n      }\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"output_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"bucket_names\"\n    value {\n      field_value {\n        string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n      }\n    }\n  }\n  parameters {\n    key: \"buckets\"\n    value {\n      field_value {\n        string_value: \"[80, 10, 10]\"\n      }\n    }\n  }\n  parameters {\n    key: \"delim\"\n    value {\n      field_value {\n        string_value: \"::\"\n      }\n    }\n  }\n  parameters {\n    key: \"headers_present\"\n    value {\n      field_value {\n        string_value: \"false\"\n      }\n      schema {\n        value_type {\n          boolean_type {\n          }\n        }\n      }\n    }\n  }\n  parameters {\n    key: \"movies_key_col_dict\"\n    value {\n      field_value {\n        string_value: \"{\\\"movie_id\\\": 0, \\\"title\\\": 1, \\\"genres\\\": 2}\"\n      }\n    }\n  }\n  parameters {\n    key: \"movies_uri\"\n    value {\n      field_value {\n        string_value: \"/kaggle/working/ml-1m/movies.dat\"\n      }\n    }\n  }\n  parameters {\n    key: \"ratings_key_col_dict\"\n    value {\n      field_value {\n        string_value: \"{\\\"user_id\\\": 0, \\\"movie_id\\\": 1, \\\"rating\\\": 2, \\\"timestamp\\\": 3}\"\n      }\n    }\n  }\n  parameters {\n    key: \"ratings_uri\"\n    value {\n      field_value {\n        string_value: \"/kaggle/working/ml-1m/ratings.dat\"\n      }\n    }\n  }\n  parameters {\n    key: \"users_key_col_dict\"\n    value {\n      field_value {\n        string_value: \"{\\\"user_id\\\": 0, \\\"gender\\\": 1, \\\"age\\\": 2, \\\"occupation\\\": 3, \\\"zipcode\\\": 4}\"\n      }\n    }\n  }\n  parameters {\n    key: \"users_uri\"\n    value {\n      field_value {\n        string_value: \"/kaggle/working/ml-1m/users.dat\"\n      }\n    }\n  }\n}\nexecution_options {\n  caching_options {\n    enable_cache: true\n  }\n}\n, pipeline_info=id: \"movie_ens_ingest_test\"\n, pipeline_run_id='2025-10-03T00:14:05.407228', top_level_pipeline_run_id=None, frontend_url=None)\nINFO:absl:ingest_movie_lens_component\nDEBUG:absl:have ratings_tuple.  type=<class 'apache_beam.pvalue.DoOutputsTuple'>\nDEBUG:absl:output_examples.uri=/kaggle/working/bin/pipelines/movie_ens_ingest_test/ingest_movie_lens_component/output_examples/8\nINFO:absl:Cleaning up stateless execution info.\nINFO:absl:Execution 8 succeeded.\nINFO:absl:Cleaning up stateful execution info.\nINFO:absl:Deleted stateful_working_dir /kaggle/working/bin/pipelines/movie_ens_ingest_test/ingest_movie_lens_component/.system/stateful_working_dir/422a9e14-4026-4f00-a9aa-718c972656ad\nINFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/pipelines/movie_ens_ingest_test/ingest_movie_lens_component/output_examples/8\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}) for execution 8\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/metadata/movie_ens_ingest_test/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component ingest_movie_lens_component is finished.\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run ingest using beam and TFX for fully custom component\"\n\nt0=$(date +%s%N)\n\npython /kaggle/working/ingest_movie_lens_tfx.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T00:15:28.433160Z","iopub.execute_input":"2025-10-03T00:15:28.433453Z","iopub.status.idle":"2025-10-03T00:15:41.599367Z","shell.execute_reply.started":"2025-10-03T00:15:28.433433Z","shell.execute_reply":"2025-10-03T00:15:41.598498Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun ingest using beam and TFX for fully custom component\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\nbegin test\nexecutor_spec=<tfx.dsl.components.base.executor_spec.ExecutorClassSpec object at 0x78cd2980f970>\nDEBUG IngestMovieLensComponent init\n11.453704324 seconds\nFri Oct  3 12:15:41 AM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"INFO:absl:Excluding no splits because exclude_splits is not set.\nINFO:absl:Using deployment config:\n executor_specs {\n  key: \"IngestMovieLensComponent\"\n  value {\n    beam_executable_spec {\n      python_executor_spec {\n        class_path: \"__main__.IngestMovieLensExecutor\"\n      }\n    }\n  }\n}\nmetadata_connection_config {\n  database_connection_config {\n    sqlite {\n      filename_uri: \"/kaggle/working/bin/metadata/MovieLensIngestTest/metadata.db\"\n      connection_mode: READWRITE_OPENCREATE\n    }\n  }\n}\n\nINFO:absl:Using connection config:\n sqlite {\n  filename_uri: \"/kaggle/working/bin/metadata/MovieLensIngestTest/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component IngestMovieLensComponent is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"__main__.IngestMovieLensComponent\"\n  }\n  id: \"IngestMovieLensComponent\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"MovieLensIngestTest\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-03T00:15:39.151844\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"MovieLensIngestTest.IngestMovieLensComponent\"\n      }\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"output_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"bucket_names\"\n    value {\n      field_value {\n        string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n      }\n      schema {\n        value_type {\n          list_type {\n          }\n        }\n      }\n    }\n  }\n  parameters {\n    key: \"buckets\"\n    value {\n      field_value {\n        string_value: \"[80, 10, 10]\"\n      }\n      schema {\n        value_type {\n          list_type {\n          }\n        }\n      }\n    }\n  }\n  parameters {\n    key: \"delim\"\n    value {\n      field_value {\n        string_value: \"::\"\n      }\n    }\n  }\n  parameters {\n    key: \"headers_present\"\n    value {\n      field_value {\n        string_value: \"false\"\n      }\n      schema {\n        value_type {\n          boolean_type {\n          }\n        }\n      }\n    }\n  }\n  parameters {\n    key: \"movies_key_col_dict\"\n    value {\n      field_value {\n        string_value: \"{\\\"genres\\\": 2, \\\"movie_id\\\": 0, \\\"title\\\": 1}\"\n      }\n      schema {\n        value_type {\n          dict_type {\n          }\n        }\n      }\n    }\n  }\n  parameters {\n    key: \"movies_uri\"\n    value {\n      field_value {\n        string_value: \"/kaggle/working/ml-1m/movies.dat\"\n      }\n    }\n  }\n  parameters {\n    key: \"name\"\n    value {\n      field_value {\n        string_value: \"test_tfx_component\"\n      }\n    }\n  }\n  parameters {\n    key: \"ratings_key_col_dict\"\n    value {\n      field_value {\n        string_value: \"{\\\"movie_id\\\": 1, \\\"rating\\\": 2, \\\"timestamp\\\": 3, \\\"user_id\\\": 0}\"\n      }\n      schema {\n        value_type {\n          dict_type {\n          }\n        }\n      }\n    }\n  }\n  parameters {\n    key: \"ratings_uri\"\n    value {\n      field_value {\n        string_value: \"/kaggle/working/ml-1m/ratings.dat\"\n      }\n    }\n  }\n  parameters {\n    key: \"users_key_col_dict\"\n    value {\n      field_value {\n        string_value: \"{\\\"age\\\": 2, \\\"gender\\\": 1, \\\"occupation\\\": 3, \\\"user_id\\\": 0, \\\"zipcode\\\": 4}\"\n      }\n      schema {\n        value_type {\n          dict_type {\n          }\n        }\n      }\n    }\n  }\n  parameters {\n    key: \"users_uri\"\n    value {\n      field_value {\n        string_value: \"/kaggle/working/ml-1m/users.dat\"\n      }\n    }\n  }\n}\nexecution_options {\n  caching_options {\n    enable_cache: true\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/metadata/MovieLensIngestTest/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type pipeline_run and name 2025-10-03T00:15:39.151844\nDEBUG:absl:ID of context type {\n  name: \"pipeline_run\"\n}\nname {\n  field_value {\n    string_value: \"2025-10-03T00:15:39.151844\"\n  }\n}\n is 7.\nDEBUG:absl:Before conditional:\n{}\nDEBUG:absl:After conditional:\n{}\nINFO:absl:[IngestMovieLensComponent] Resolved inputs: ({},)\nDEBUG:absl:Prepared EXECUTION:\n type_id: 13\nlast_known_state: RUNNING\ncustom_properties {\n  key: \"__schema__bucket_names__\"\n  value {\n    string_value: \"{\\n  \\\"value_type\\\": {\\n    \\\"list_type\\\": {}\\n  }\\n}\"\n  }\n}\ncustom_properties {\n  key: \"__schema__buckets__\"\n  value {\n    string_value: \"{\\n  \\\"value_type\\\": {\\n    \\\"list_type\\\": {}\\n  }\\n}\"\n  }\n}\ncustom_properties {\n  key: \"__schema__headers_present__\"\n  value {\n    string_value: \"{\\n  \\\"value_type\\\": {\\n    \\\"boolean_type\\\": {}\\n  }\\n}\"\n  }\n}\ncustom_properties {\n  key: \"__schema__movies_key_col_dict__\"\n  value {\n    string_value: \"{\\n  \\\"value_type\\\": {\\n    \\\"dict_type\\\": {}\\n  }\\n}\"\n  }\n}\ncustom_properties {\n  key: \"__schema__ratings_key_col_dict__\"\n  value {\n    string_value: \"{\\n  \\\"value_type\\\": {\\n    \\\"dict_type\\\": {}\\n  }\\n}\"\n  }\n}\ncustom_properties {\n  key: \"__schema__users_key_col_dict__\"\n  value {\n    string_value: \"{\\n  \\\"value_type\\\": {\\n    \\\"dict_type\\\": {}\\n  }\\n}\"\n  }\n}\ncustom_properties {\n  key: \"bucket_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\ncustom_properties {\n  key: \"buckets\"\n  value {\n    string_value: \"[80, 10, 10]\"\n  }\n}\ncustom_properties {\n  key: \"delim\"\n  value {\n    string_value: \"::\"\n  }\n}\ncustom_properties {\n  key: \"headers_present\"\n  value {\n    string_value: \"false\"\n  }\n}\ncustom_properties {\n  key: \"movies_key_col_dict\"\n  value {\n    string_value: \"{\\\"genres\\\": 2, \\\"movie_id\\\": 0, \\\"title\\\": 1}\"\n  }\n}\ncustom_properties {\n  key: \"movies_uri\"\n  value {\n    string_value: \"/kaggle/working/ml-1m/movies.dat\"\n  }\n}\ncustom_properties {\n  key: \"name\"\n  value {\n    string_value: \"test_tfx_component\"\n  }\n}\ncustom_properties {\n  key: \"ratings_key_col_dict\"\n  value {\n    string_value: \"{\\\"movie_id\\\": 1, \\\"rating\\\": 2, \\\"timestamp\\\": 3, \\\"user_id\\\": 0}\"\n  }\n}\ncustom_properties {\n  key: \"ratings_uri\"\n  value {\n    string_value: \"/kaggle/working/ml-1m/ratings.dat\"\n  }\n}\ncustom_properties {\n  key: \"users_key_col_dict\"\n  value {\n    string_value: \"{\\\"age\\\": 2, \\\"gender\\\": 1, \\\"occupation\\\": 3, \\\"user_id\\\": 0, \\\"zipcode\\\": 4}\"\n  }\n}\ncustom_properties {\n  key: \"users_uri\"\n  value {\n    string_value: \"/kaggle/working/ml-1m/users.dat\"\n  }\n}\nname: \"0ca88a31-a02b-49b8-a979-dfac08ca4b65\"\n\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/pipelines/MovieLensIngestTest/IngestMovieLensComponent/output_examples/4\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/metadata/MovieLensIngestTest/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Going to run a new execution 4\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1759450539.214678    1432 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=4, input_dict={}, output_dict=defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/pipelines/MovieLensIngestTest/IngestMovieLensComponent/output_examples/4\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}), exec_properties={'movies_uri': '/kaggle/working/ml-1m/movies.dat', 'movies_key_col_dict': {'genres': 2, 'movie_id': 0, 'title': 1}, 'headers_present': False, 'bucket_names': ['train', 'eval', 'test'], 'name': 'test_tfx_component', 'users_key_col_dict': {'age': 2, 'gender': 1, 'occupation': 3, 'user_id': 0, 'zipcode': 4}, 'users_uri': '/kaggle/working/ml-1m/users.dat', 'buckets': [80, 10, 10], 'ratings_uri': '/kaggle/working/ml-1m/ratings.dat', 'ratings_key_col_dict': {'movie_id': 1, 'rating': 2, 'timestamp': 3, 'user_id': 0}, 'delim': '::'}, execution_output_uri='/kaggle/working/bin/pipelines/MovieLensIngestTest/IngestMovieLensComponent/.system/executor_execution/4/executor_output.pb', stateful_working_dir='/kaggle/working/bin/pipelines/MovieLensIngestTest/IngestMovieLensComponent/.system/stateful_working_dir/9321704d-b20e-405b-a88a-86b88355dc6b', tmp_dir='/kaggle/working/bin/pipelines/MovieLensIngestTest/IngestMovieLensComponent/.system/executor_execution/4/.temp/', pipeline_node=node_info {\n  type {\n    name: \"__main__.IngestMovieLensComponent\"\n  }\n  id: \"IngestMovieLensComponent\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"MovieLensIngestTest\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-03T00:15:39.151844\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"MovieLensIngestTest.IngestMovieLensComponent\"\n      }\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"output_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"bucket_names\"\n    value {\n      field_value {\n        string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n      }\n      schema {\n        value_type {\n          list_type {\n          }\n        }\n      }\n    }\n  }\n  parameters {\n    key: \"buckets\"\n    value {\n      field_value {\n        string_value: \"[80, 10, 10]\"\n      }\n      schema {\n        value_type {\n          list_type {\n          }\n        }\n      }\n    }\n  }\n  parameters {\n    key: \"delim\"\n    value {\n      field_value {\n        string_value: \"::\"\n      }\n    }\n  }\n  parameters {\n    key: \"headers_present\"\n    value {\n      field_value {\n        string_value: \"false\"\n      }\n      schema {\n        value_type {\n          boolean_type {\n          }\n        }\n      }\n    }\n  }\n  parameters {\n    key: \"movies_key_col_dict\"\n    value {\n      field_value {\n        string_value: \"{\\\"genres\\\": 2, \\\"movie_id\\\": 0, \\\"title\\\": 1}\"\n      }\n      schema {\n        value_type {\n          dict_type {\n          }\n        }\n      }\n    }\n  }\n  parameters {\n    key: \"movies_uri\"\n    value {\n      field_value {\n        string_value: \"/kaggle/working/ml-1m/movies.dat\"\n      }\n    }\n  }\n  parameters {\n    key: \"name\"\n    value {\n      field_value {\n        string_value: \"test_tfx_component\"\n      }\n    }\n  }\n  parameters {\n    key: \"ratings_key_col_dict\"\n    value {\n      field_value {\n        string_value: \"{\\\"movie_id\\\": 1, \\\"rating\\\": 2, \\\"timestamp\\\": 3, \\\"user_id\\\": 0}\"\n      }\n      schema {\n        value_type {\n          dict_type {\n          }\n        }\n      }\n    }\n  }\n  parameters {\n    key: \"ratings_uri\"\n    value {\n      field_value {\n        string_value: \"/kaggle/working/ml-1m/ratings.dat\"\n      }\n    }\n  }\n  parameters {\n    key: \"users_key_col_dict\"\n    value {\n      field_value {\n        string_value: \"{\\\"age\\\": 2, \\\"gender\\\": 1, \\\"occupation\\\": 3, \\\"user_id\\\": 0, \\\"zipcode\\\": 4}\"\n      }\n      schema {\n        value_type {\n          dict_type {\n          }\n        }\n      }\n    }\n  }\n  parameters {\n    key: \"users_uri\"\n    value {\n      field_value {\n        string_value: \"/kaggle/working/ml-1m/users.dat\"\n      }\n    }\n  }\n}\nexecution_options {\n  caching_options {\n    enable_cache: true\n  }\n}\n, pipeline_info=id: \"MovieLensIngestTest\"\n, pipeline_run_id='2025-10-03T00:15:39.151844', top_level_pipeline_run_id=None, frontend_url=None)\nDEBUG:absl:in IngestMovieLensExecutor.Do\nDEBUG:absl:in IngestMovieLensExecutor.GenerateExamplesByBeam\nDEBUG:absl:in IngestMovieLensExecutor.GetInputSourceToExamplePTransform\nDEBUG:absl:isplit_name=train\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/metadata/MovieLensIngestTest/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nERROR:absl:Execution 4 failed.\nINFO:absl:Cleaning up stateless execution info.\nTraceback (most recent call last):\n  File \"/kaggle/working/ingest_movie_lens_tfx.py\", line 439, in <module>\n    LocalDagRunner().run(my_pipeline)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/tfx_runner.py\", line 124, in run\n    return self.run_with_ir(pipeline_pb, run_options=run_options_pb, **kwargs)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/local/local_dag_runner.py\", line 109, in run_with_ir\n    component_launcher.launch()\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/launcher.py\", line 613, in launch\n    executor_output = self._run_executor(execution_info)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/launcher.py\", line 487, in _run_executor\n    executor_output = self._executor_operator.run_executor(execution_info)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/beam_executor_operator.py\", line 112, in run_executor\n    return python_executor_operator.run_with_executor(execution_info, executor)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/python_executor_operator.py\", line 84, in run_with_executor\n    result = executor.Do(\n  File \"/kaggle/working/ingest_movie_lens_tfx.py\", line 307, in Do\n    artifact_utils.get_split_uri( \\\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/types/standard_artifact_utils.py\", line 119, in get_split_uri\n    raise ValueError(\nValueError: Expected exactly one artifact with split 'train', but found matching artifacts [].\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run ingest using beam and DirectRunner\"\n\nt0=$(date +%s%N)\n\npython /kaggle/working/ingest_movie_lens_beam.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T22:59:40.734265Z","iopub.execute_input":"2025-10-02T22:59:40.734468Z","iopub.status.idle":"2025-10-02T23:01:09.906788Z","shell.execute_reply.started":"2025-10-02T22:59:40.734450Z","shell.execute_reply":"2025-10-02T23:01:09.905950Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun ingest using beam and DirectRunner\ntests done\n87.611079706 seconds\nThu Oct  2 11:01:09 PM UTC 2025\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\nmkdir /kaggle/working/bin\nrm -rf /kaggle/working/bin/*\n\nt0=$(date +%s%N)\n\npython -m unittest IngestMovieLensComponentTest.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T23:01:09.908064Z","iopub.execute_input":"2025-10-02T23:01:09.908388Z","iopub.status.idle":"2025-10-02T23:01:16.388630Z","shell.execute_reply.started":"2025-10-02T23:01:09.908357Z","shell.execute_reply":"2025-10-02T23:01:16.387672Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\n4.880092167 seconds\nThu Oct  2 11:01:16 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"E\n======================================================================\nERROR: IngestMovieLensComponentTest (unittest.loader._FailedTest)\n----------------------------------------------------------------------\nImportError: Failed to import test module: IngestMovieLensComponentTest\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/unittest/loader.py\", line 154, in loadTestsFromName\n    module = __import__(module_name)\n  File \"/kaggle/working/IngestMovieLensComponentTest.py\", line 24, in <module>\n    from ingest_movie_lens_tfx import IngestMovieLensComponent, IngestMovieLensExecutor\nModuleNotFoundError: No module named 'ingest_movie_lens_tfx'\n\n\n----------------------------------------------------------------------\nRan 1 test in 0.000s\n\nFAILED (errors=1)\n","output_type":"stream"}],"execution_count":13}]}