{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-10T01:00:04.784267Z","iopub.execute_input":"2025-10-10T01:00:04.784825Z","iopub.status.idle":"2025-10-10T01:00:04.799581Z","shell.execute_reply.started":"2025-10-10T01:00:04.784781Z","shell.execute_reply":"2025-10-10T01:00:04.798401Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Recommender System with TFX pipelines\nThe notebook builds MLOps components and pipelines using TFX for the recommender system [here.](https://www.kaggle.com/code/nicholeasuniquename/recommender-systems/)\n\n1. Create a virtual environment for TFX compatability\n2. Build the TFX components and upload to the public repository.\n3. Download the components and test them in the virtual environment here.\n4. Build the MLOps pipelines, upload to public repository.\n5. Download the pipelines and test in the virtual environment here.\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Creating the TFX compatible virtual environment\n\ntfx version 1.16.0 is latest stable as of Sep 28, 2025\n\nIt is compatible with python 3.9 and 3.10 only.\n\nThe current kaggle python docker image uses python 3.11.13.\n\nTo use an earlier version of python on Kaggle, one can install conda and create a virtual environment that is based on an earlier version of python. \n\nOnce conda is installed and a virtual environment is created for the earlier version of python, the virtual environment can be activated by activating conda and then activating the virtual environment.\n\nA bash shell in the notebook that is invoked from the magic command %%bash is a bash session for the extent of that specific cell.\nFor each new session invoked by the cell %%bash, the 2 activation commands need to be invoked before using the virtual environment.\n\nAside from running scripts in the magic bash shell cells, we can also run scripts using the python subprocess library as long as we prepend commands with the 2 conda activation statements (see details in the definition for the run_command below).\n\nWe have 2 ways to run commands within the virtual environment.\n\nThe notebook itself is still using the kaggle docker image environment without the newly built virtual environment.\nEven if we install and use ipykernel to register a kernel for the new virtual environment, I don't see a way to open the notebook to use the new kernel.  (In the Kaggle window, we have Session options, persistence option to persist files and variables, so it might be possible to restart the notebook with kernel selected as long as the kernel has Kaggle specific notebook support...)\n\nIn summary, the notebook as is can be used for intermediate steps of EDA where the EDA uses libraries that don't require an earlier version of python.  For MLOps steps that need an earlier version of python, the virtual environment is available.\n","metadata":{}},{"cell_type":"code","source":"!pwd\n!echo $HOME","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T01:00:04.801258Z","iopub.execute_input":"2025-10-10T01:00:04.801730Z","iopub.status.idle":"2025-10-10T01:00:05.055902Z","shell.execute_reply.started":"2025-10-10T01:00:04.801694Z","shell.execute_reply":"2025-10-10T01:00:05.054771Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n/root\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"%%bash: Executes the entire cell as a shell script. ","metadata":{}},{"cell_type":"code","source":"%%bash\nt0=$(date +%s%N)\nmkdir -p ~/miniconda3\nwget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n#install conda and activate to /usr/local\nbash ~/miniconda3/miniconda.sh -b -u -p /usr/local\nrm ~/miniconda3/miniconda.sh\nconda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\nconda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n\n. /usr/local/bin/activate\necho \"**$SHELL**\"\necho \"**$BASH**\"\nconda init --all\n\n. /root/.bashrc\nconda create -q --name my_tfx_env python=3.10 -y\nconda activate my_tfx_env\npython --version\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T01:00:05.057204Z","iopub.execute_input":"2025-10-10T01:00:05.057505Z","iopub.status.idle":"2025-10-10T01:00:43.313703Z","shell.execute_reply.started":"2025-10-10T01:00:05.057475Z","shell.execute_reply":"2025-10-10T01:00:43.312704Z"}},"outputs":[{"name":"stdout","text":"PREFIX=/usr/local\nUnpacking bootstrapper...\nUnpacking payload...\n\nInstalling base environment...\n\nPreparing transaction: ...working... done\nExecuting transaction: ...working... done\ninstallation finished.\nWARNING:\n    You currently have a PYTHONPATH environment variable set. This may cause\n    unexpected behavior when running the Python interpreter in Miniconda3.\n    For best results, please verify that your PYTHONPATH only points to\n    directories of packages that are compatible with the Python interpreter\n    in Miniconda3: /usr/local\naccepted Terms of Service for https://repo.anaconda.com/pkgs/main\naccepted Terms of Service for https://repo.anaconda.com/pkgs/r\n**/bin/bash**\n**/usr/bin/bash**\nno change     /usr/local/condabin/conda\nno change     /usr/local/bin/conda\nno change     /usr/local/bin/conda-env\nno change     /usr/local/bin/activate\nno change     /usr/local/bin/deactivate\nno change     /usr/local/etc/profile.d/conda.sh\nno change     /usr/local/etc/fish/conf.d/conda.fish\nno change     /usr/local/shell/condabin/Conda.psm1\nno change     /usr/local/shell/condabin/conda-hook.ps1\nno change     /usr/local/lib/python3.13/site-packages/xontrib/conda.xsh\nno change     /usr/local/etc/profile.d/conda.csh\nno change     /root/.bashrc\nno change     /root/.zshrc\nno change     /root/.config/fish/config.fish\nno change     /root/.xonshrc\nno change     /root/.tcshrc\nNo action taken.\n2 channel Terms of Service accepted\nChannels:\n - defaults\nPlatform: linux-64\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\n## Package Plan ##\n\n  environment location: /usr/local/envs/my_tfx_env\n\n  added / updated specs:\n    - python=3.10\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    setuptools-80.9.0          |  py310h06a4308_0         1.4 MB\n    ------------------------------------------------------------\n                                           Total:         1.4 MB\n\nThe following NEW packages will be INSTALLED:\n\n  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 \n  ca-certificates    pkgs/main/linux-64::ca-certificates-2025.9.9-h06a4308_0 \n  expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 \n  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.44-h153f514_2 \n  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n  libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 \n  libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 \n  libzlib            pkgs/main/linux-64::libzlib-1.3.1-hb25bd0a_0 \n  ncurses            pkgs/main/linux-64::ncurses-6.5-h7934f7d_0 \n  openssl            pkgs/main/linux-64::openssl-3.0.18-hd6dcaed_0 \n  pip                pkgs/main/noarch::pip-25.2-pyhc872135_0 \n  pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 \n  python             pkgs/main/linux-64::python-3.10.18-h1a3bd86_0 \n  readline           pkgs/main/linux-64::readline-8.3-hc2a1206_0 \n  setuptools         pkgs/main/linux-64::setuptools-80.9.0-py310h06a4308_0 \n  sqlite             pkgs/main/linux-64::sqlite-3.50.2-hb25bd0a_1 \n  tk                 pkgs/main/linux-64::tk-8.6.15-h54e0aa7_0 \n  tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 \n  wheel              pkgs/main/linux-64::wheel-0.45.1-py310h06a4308_0 \n  xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 \n  xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 \n  xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 \n  xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 \n  xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n  zlib               pkgs/main/linux-64::zlib-1.3.1-hb25bd0a_0 \n\n\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\nPython 3.10.18\n38.236438950 seconds\nFri Oct 10 01:00:43 AM UTC 2025\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"to activate the conda environment, need to source from conda's activate (which I installed in /usr/local/bin above), then activate the conda virtual environment.\n\nthis has to be done for each magic shell cell","metadata":{}},{"cell_type":"code","source":"%%bash\nt0=$(date +%s%N)\n. /usr/local/bin/activate\nconda activate my_tfx_env\npython --version\n\n#consider conda install ipykernel\nconda install pip\n\n#see dependencies https://github.com/tensorflow/transform\npip -q install pyarrow==10.0.1\npip -q install apache-beam==2.59.0\npip -q install tensorflow==2.16.1\npip -q install tensorflow-transform==1.16.0\npip -q install tfx==1.16.0\npip -q install pytest\n#\n#tf metadata 1.16.1\n#tfx-bsl\n#keeps protobuf 3.20.3\n#if use sparkrunner, install pyspark 4.0.0 or 3.3.x\n\npip list\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 60000000000\" | bc)\necho \"$t2 minutes\"\ndate\n#about 6-7 minutes for this cell.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T01:00:43.315670Z","iopub.execute_input":"2025-10-10T01:00:43.315947Z","iopub.status.idle":"2025-10-10T01:07:21.539790Z","shell.execute_reply.started":"2025-10-10T01:00:43.315925Z","shell.execute_reply":"2025-10-10T01:07:21.538519Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\n2 channel Terms of Service accepted\nChannels:\n - defaults\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n# All requested packages already installed.\n\nPackage                            Version\n---------------------------------- --------------\nabsl-py                            1.4.0\nannotated-types                    0.7.0\nanyio                              4.11.0\napache-beam                        2.59.0\nargon2-cffi                        25.1.0\nargon2-cffi-bindings               25.1.0\narrow                              1.3.0\nastunparse                         1.6.3\nasync-lru                          2.0.5\nasync-timeout                      5.0.1\nattrs                              23.2.0\nbabel                              2.17.0\nbackcall                           0.2.0\nbeautifulsoup4                     4.14.2\nbleach                             6.2.0\ncachetools                         5.5.2\ncertifi                            2025.10.5\ncffi                               2.0.0\ncharset-normalizer                 3.4.3\nclick                              8.3.0\ncloudpickle                        2.2.1\ncolorama                           0.4.6\ncomm                               0.2.3\ncrcmod                             1.7\ndebugpy                            1.8.17\ndecorator                          5.2.1\ndefusedxml                         0.7.1\ndill                               0.3.1.1\ndnspython                          2.8.0\ndocker                             7.1.0\ndocopt                             0.6.2\ndocstring_parser                   0.17.0\nexceptiongroup                     1.3.0\nfastavro                           1.12.0\nfasteners                          0.20\nfastjsonschema                     2.21.2\nflatbuffers                        25.9.23\nfqdn                               1.5.1\ngast                               0.6.0\ngoogle-api-core                    2.26.0\ngoogle-api-python-client           1.12.11\ngoogle-apitools                    0.5.31\ngoogle-auth                        2.41.1\ngoogle-auth-httplib2               0.2.0\ngoogle-cloud-aiplatform            1.120.0\ngoogle-cloud-bigquery              3.38.0\ngoogle-cloud-bigquery-storage      2.33.1\ngoogle-cloud-bigtable              2.33.0\ngoogle-cloud-core                  2.4.3\ngoogle-cloud-datastore             2.21.0\ngoogle-cloud-dlp                   3.32.0\ngoogle-cloud-language              2.17.2\ngoogle-cloud-pubsub                2.31.1\ngoogle-cloud-pubsublite            1.12.0\ngoogle-cloud-recommendations-ai    0.10.18\ngoogle-cloud-resource-manager      1.14.2\ngoogle-cloud-spanner               3.58.0\ngoogle-cloud-storage               2.19.0\ngoogle-cloud-videointelligence     2.16.2\ngoogle-cloud-vision                3.10.2\ngoogle-crc32c                      1.7.1\ngoogle-genai                       1.42.0\ngoogle-pasta                       0.2.0\ngoogle-resumable-media             2.7.2\ngoogleapis-common-protos           1.70.0\ngrpc-google-iam-v1                 0.14.2\ngrpc-interceptor                   0.15.4\ngrpcio                             1.75.1\ngrpcio-status                      1.49.0rc1\nh11                                0.16.0\nh5py                               3.14.0\nhdfs                               2.7.3\nhttpcore                           1.0.9\nhttplib2                           0.22.0\nhttpx                              0.28.1\nidna                               3.10\nimportlib_metadata                 8.7.0\niniconfig                          2.1.0\nipykernel                          6.30.1\nipython                            7.34.0\nipython-genutils                   0.2.0\nipywidgets                         7.8.5\nisoduration                        20.11.0\njedi                               0.19.2\nJinja2                             3.1.6\njoblib                             1.5.2\nJs2Py                              0.74\njson5                              0.12.1\njsonpickle                         3.4.2\njsonpointer                        3.0.0\njsonschema                         4.25.1\njsonschema-specifications          2025.9.1\njupyter_client                     8.6.3\njupyter_core                       5.8.1\njupyter-events                     0.12.0\njupyter-lsp                        2.3.0\njupyter_server                     2.17.0\njupyter_server_terminals           0.5.3\njupyterlab                         4.4.9\njupyterlab_pygments                0.3.0\njupyterlab_server                  2.27.3\njupyterlab_widgets                 1.1.11\nkeras                              3.11.3\nkeras-tuner                        1.4.7\nkt-legacy                          1.0.5\nkubernetes                         26.1.0\nlark                               1.3.0\nlibclang                           18.1.1\nlxml                               6.0.2\nMarkdown                           3.9\nmarkdown-it-py                     4.0.0\nMarkupSafe                         3.0.3\nmatplotlib-inline                  0.1.7\nmdurl                              0.1.2\nmistune                            3.1.4\nml-dtypes                          0.3.2\nml-metadata                        1.16.0\nml-pipelines-sdk                   1.16.0\nnamex                              0.1.0\nnbclient                           0.10.2\nnbconvert                          7.16.6\nnbformat                           5.10.4\nnest-asyncio                       1.6.0\nnltk                               3.9.2\nnotebook                           7.4.7\nnotebook_shim                      0.2.4\nnumpy                              1.26.4\noauth2client                       4.1.3\noauthlib                           3.3.1\nobjsize                            0.7.1\nopentelemetry-api                  1.37.0\nopentelemetry-sdk                  1.37.0\nopentelemetry-semantic-conventions 0.58b0\nopt_einsum                         3.4.0\noptree                             0.17.0\norjson                             3.11.3\noverrides                          7.7.0\npackaging                          25.0\npandas                             1.5.3\npandocfilters                      1.5.1\nparso                              0.8.5\npexpect                            4.9.0\npickleshare                        0.7.5\npillow                             11.3.0\npip                                25.2\nplatformdirs                       4.5.0\npluggy                             1.6.0\nportalocker                        3.2.0\nportpicker                         1.6.0\nprometheus_client                  0.23.1\nprompt_toolkit                     3.0.52\nproto-plus                         1.26.1\nprotobuf                           3.20.3\npsutil                             7.1.0\nptyprocess                         0.7.0\npyarrow                            10.0.1\npyarrow-hotfix                     0.7\npyasn1                             0.6.1\npyasn1_modules                     0.4.2\npycparser                          2.23\npydantic                           2.12.0\npydantic_core                      2.41.1\npydot                              1.4.2\npyfarmhash                         0.3.2\nPygments                           2.19.2\npyjsparser                         2.7.1\nPyJWT                              2.10.1\npymongo                            4.15.3\npyparsing                          3.2.5\npytest                             8.4.2\npython-dateutil                    2.9.0.post0\npython-json-logger                 4.0.0\npytz                               2025.2\nPyYAML                             6.0.3\npyzmq                              27.1.0\nredis                              5.3.1\nreferencing                        0.36.2\nregex                              2025.9.18\nrequests                           2.32.5\nrequests-oauthlib                  2.0.0\nrfc3339-validator                  0.1.4\nrfc3986-validator                  0.1.1\nrfc3987-syntax                     1.1.0\nrich                               14.2.0\nrouge_score                        0.1.2\nrpds-py                            0.27.1\nrsa                                4.9.1\nsacrebleu                          2.5.1\nscikit-learn                       1.5.1\nscipy                              1.12.0\nSend2Trash                         1.8.3\nsetuptools                         80.9.0\nshapely                            2.1.2\nsix                                1.17.0\nsniffio                            1.3.1\nsoupsieve                          2.8\nsqlparse                           0.5.3\ntabulate                           0.9.0\ntenacity                           9.1.2\ntensorboard                        2.16.2\ntensorboard-data-server            0.7.2\ntensorflow                         2.16.1\ntensorflow-data-validation         1.16.1\ntensorflow-estimator               2.15.0\ntensorflow-hub                     0.15.0\ntensorflow-io-gcs-filesystem       0.37.1\ntensorflow-metadata                1.16.1\ntensorflow_model_analysis          0.47.1\ntensorflow-serving-api             2.16.1\ntensorflow-transform               1.16.0\ntermcolor                          3.1.0\nterminado                          0.18.1\ntf_keras                           2.16.0\ntfx                                1.16.0\ntfx-bsl                            1.16.1\nthreadpoolctl                      3.6.0\ntinycss2                           1.4.0\ntomli                              2.3.0\ntornado                            6.5.2\ntqdm                               4.67.1\ntraitlets                          5.14.3\ntypes-python-dateutil              2.9.0.20251008\ntyping_extensions                  4.15.0\ntyping-inspection                  0.4.2\ntzlocal                            5.3.1\nuri-template                       1.3.0\nuritemplate                        3.0.1\nurllib3                            2.5.0\nwcwidth                            0.2.14\nwebcolors                          24.11.1\nwebencodings                       0.5.1\nwebsocket-client                   1.9.0\nwebsockets                         15.0.1\nWerkzeug                           3.1.3\nwheel                              0.45.1\nwidgetsnbextension                 3.6.10\nwrapt                              1.17.3\nzipp                               3.23.0\nzstandard                          0.25.0\n6.636703713 minutes\nFri Oct 10 01:07:21 AM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"\n\n==> WARNING: A newer version of conda exists. <==\n    current version: 25.7.0\n    latest version: 25.9.0\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%%bash\n. /usr/local/bin/activate\nconda activate my_tfx_env\npython --version\npip show apache-beam\n\n#refresh the test dirs\nrm -rf /kaggle/working/bin/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T01:07:21.541286Z","iopub.execute_input":"2025-10-10T01:07:21.541688Z","iopub.status.idle":"2025-10-10T01:07:24.529519Z","shell.execute_reply.started":"2025-10-10T01:07:21.541651Z","shell.execute_reply":"2025-10-10T01:07:24.528723Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nName: apache-beam\nVersion: 2.59.0\nSummary: Apache Beam SDK for Python\nHome-page: https://beam.apache.org\nAuthor: Apache Software Foundation\nAuthor-email: dev@beam.apache.org\nLicense: Apache License, Version 2.0\nLocation: /usr/local/envs/my_tfx_env/lib/python3.10/site-packages\nRequires: cloudpickle, crcmod, dill, fastavro, fasteners, grpcio, hdfs, httplib2, js2py, jsonpickle, jsonschema, numpy, objsize, orjson, packaging, proto-plus, protobuf, pyarrow, pyarrow-hotfix, pydot, pymongo, python-dateutil, pytz, redis, regex, requests, typing-extensions, zstandard\nRequired-by: tensorflow-data-validation, tensorflow-transform, tensorflow_model_analysis, tfx, tfx-bsl\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"The run_command is from\nhttps://www.kaggle.com/code/taylorsamarel/change-python-version-kaggle-v2-taylor-amarel","metadata":{}},{"cell_type":"code","source":"import subprocess\ndef run_command(cmd, capture=True, check=False):\n    cmds = f\". /usr/local/bin/activate; conda activate my_tfx_env; {cmd}\"\n    try:\n        result = subprocess.run(cmds, shell=True, capture_output=capture, text=True, check=check)\n        if capture:\n            return result.stdout.strip() if result.stdout else result.stderr.strip()\n        return result.returncode == 0\n    except Exception as e:\n        return str(e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T01:07:24.530379Z","iopub.execute_input":"2025-10-10T01:07:24.530666Z","iopub.status.idle":"2025-10-10T01:07:24.537088Z","shell.execute_reply.started":"2025-10-10T01:07:24.530644Z","shell.execute_reply":"2025-10-10T01:07:24.535994Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(run_command(\"python --version\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T01:07:24.538301Z","iopub.execute_input":"2025-10-10T01:07:24.539583Z","iopub.status.idle":"2025-10-10T01:07:26.255752Z","shell.execute_reply.started":"2025-10-10T01:07:24.539542Z","shell.execute_reply":"2025-10-10T01:07:26.254685Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### 1.a. Download a TFX test script and test that the library versions are compatible","metadata":{}},{"cell_type":"code","source":"%%bash\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\n#it can take a couple of minutes to get current version of recently uploaded file to github\n#wget -q -c --no-cache https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/main/src/test/python/test_tft.py -O /kaggle/working/test_tft.py\n#curl --header \"Cache-Control: no-cache\" \"https://api.github.com/repos/nking/recommender_systems/content/src/test/python/test_tft.py\" -o /kaggle/working/test_tft.py\n\nrm -f /kaggle/working/dataset_tfxio_example.py\nwget -q -c --no-cache https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/main/src/test/python/dataset_tfxio_example.py -O /kaggle/working/dataset_tfxio_example.py\n\nls -l /kaggle/working\n\n#run a test example from Google's TFX codebase:\npython3 /kaggle/working/dataset_tfxio_example.py\n\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T02:28:03.261278Z","iopub.execute_input":"2025-10-10T02:28:03.261742Z","iopub.status.idle":"2025-10-10T02:28:15.438319Z","shell.execute_reply.started":"2025-10-10T02:28:03.261705Z","shell.execute_reply":"2025-10-10T02:28:15.437239Z"}},"outputs":[{"name":"stdout","text":"total 112\ndrwxr-xr-x 6 root root  4096 Oct 10 01:17 bin\n-rw-r--r-- 1 root root  7273 Oct 10 02:09 csv_example_gen_test.py\n-rw-r--r-- 1 root root   777 Oct 10 02:09 CustomUTF8Coder.py\n-rw-r--r-- 1 root root  2392 Oct 10 02:28 dataset_tfxio_example.py\n-rw-r--r-- 1 root root  7899 Oct 10 02:09 ingest_movie_lens_beam.py\n-rw-r--r-- 1 root root  5043 Oct 10 02:09 ingest_movie_lens_beam_test.py\n-rw-r--r-- 1 root root  5796 Oct 10 02:09 ingest_movie_lens_component.py\n-rw-r--r-- 1 root root  9813 Oct 10 02:09 ingest_movie_lens_component_test.py\n-rw-r--r-- 1 root root 12556 Oct 10 02:09 ingest_movie_lens_custom_component.py\n-rw-r--r-- 1 root root 11628 Oct 10 02:09 ingest_movie_lens_custom_component_test.py\ndrwxr-x--- 3 root root  4096 Oct 10 01:07 ml-1m\n-rw-r--r-- 1 root root 11933 Oct 10 02:09 movie_lens_utils.py\n-rw-r--r-- 1 root root  4377 Oct 10 02:09 movie_lens_utils_test.py\ndrwxr-xr-x 2 root root  4096 Oct 10 02:15 __pycache__\n{'x_centered': [[-4.0], [-3.0], [-2.0], [-1.0], [0.0]],\n 'x_scaled': [[0.0], [0.125], [0.25], [0.375], [0.5]]}\n{'x_centered': [[1.0], [2.0], [3.0], [4.0]],\n 'x_scaled': [[0.625], [0.75], [0.875], [1.0]]}\nFri Oct 10 02:28:15 AM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"I1010 02:28:10.672368 138017414244160 pipeline.py:197] Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\nI1010 02:28:12.561774 138017414244160 statecache.py:214] Creating state cache with size 104857600\nI1010 02:28:12.734366 138017414244160 functional_saver.py:438] Sharding callback duration: 7\nI1010 02:28:12.777997 138017414244160 functional_saver.py:438] Sharding callback duration: 8\nINFO:tensorflow:Assets written to: /tmp/tmpxdy0vqmx/tftransform_tmp/67da4b526b5d4d3f86b05f8ac3165eb4/assets\nI1010 02:28:12.810341 138017414244160 builder_impl.py:829] Assets written to: /tmp/tmpxdy0vqmx/tftransform_tmp/67da4b526b5d4d3f86b05f8ac3165eb4/assets\nI1010 02:28:12.815073 138017414244160 fingerprinting_utils.py:49] Writing fingerprint to /tmp/tmpxdy0vqmx/tftransform_tmp/67da4b526b5d4d3f86b05f8ac3165eb4/fingerprint.pb\nINFO:tensorflow:struct2tensor is not available.\nI1010 02:28:13.202903 138017414244160 saved_transform_io.py:166] struct2tensor is not available.\nINFO:tensorflow:tensorflow_decision_forests is not available.\nI1010 02:28:13.203346 138017414244160 saved_transform_io.py:166] tensorflow_decision_forests is not available.\nINFO:tensorflow:tensorflow_text is not available.\nI1010 02:28:13.203634 138017414244160 saved_transform_io.py:166] tensorflow_text is not available.\nI1010 02:28:13.694511 138017414244160 functional_saver.py:438] Sharding callback duration: 7\nI1010 02:28:13.726811 138017414244160 functional_saver.py:438] Sharding callback duration: 7\nINFO:tensorflow:Assets written to: /tmp/tmpxdy0vqmx/tftransform_tmp/ec65bd1e9f4a4b2682c314f0cecb96af/assets\nI1010 02:28:13.737125 138017414244160 builder_impl.py:829] Assets written to: /tmp/tmpxdy0vqmx/tftransform_tmp/ec65bd1e9f4a4b2682c314f0cecb96af/assets\nI1010 02:28:13.739083 138017414244160 fingerprinting_utils.py:49] Writing fingerprint to /tmp/tmpxdy0vqmx/tftransform_tmp/ec65bd1e9f4a4b2682c314f0cecb96af/fingerprint.pb\nI1010 02:28:13.797385 138017414244160 tensor_representation_util.py:450] Feature x_centered has a shape . Setting to DenseTensor.\nI1010 02:28:13.797631 138017414244160 tensor_representation_util.py:450] Feature x_scaled has a shape . Setting to DenseTensor.\nINFO:tensorflow:struct2tensor is not available.\nI1010 02:28:13.897964 138017414244160 saved_transform_io.py:166] struct2tensor is not available.\nINFO:tensorflow:tensorflow_decision_forests is not available.\nI1010 02:28:13.898324 138017414244160 saved_transform_io.py:166] tensorflow_decision_forests is not available.\nINFO:tensorflow:tensorflow_text is not available.\nI1010 02:28:13.898539 138017414244160 saved_transform_io.py:166] tensorflow_text is not available.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"## 2.a. Download a MovieLens dataset","metadata":{}},{"cell_type":"code","source":"%%bash\nwget -q http://files.grouplens.org/datasets/movielens/ml-1m.zip -O /kaggle/working/ml-1m.zip\nunzip -o /kaggle/working/ml-1m.zip\nls /kaggle/working/ml-1m/\nrm /kaggle/working/ml-1m.zip\n\nhead -n 5 /kaggle/working/ml-1m/ratings.dat\nhead -n 5 /kaggle/working/ml-1m/users.dat\nhead -n 5 /kaggle/working/ml-1m/movies.dat","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T02:28:15.440092Z","iopub.execute_input":"2025-10-10T02:28:15.440443Z","iopub.status.idle":"2025-10-10T02:28:17.475154Z","shell.execute_reply.started":"2025-10-10T02:28:15.440391Z","shell.execute_reply":"2025-10-10T02:28:17.474343Z"}},"outputs":[{"name":"stdout","text":"Archive:  /kaggle/working/ml-1m.zip\n  inflating: ml-1m/movies.dat        \n  inflating: ml-1m/ratings.dat       \n  inflating: ml-1m/README            \n  inflating: ml-1m/users.dat         \nmovies.dat\nratings.dat\nREADME\ntmp\nusers.dat\n1::1193::5::978300760\n1::661::3::978302109\n1::914::3::978301968\n1::3408::4::978300275\n1::2355::5::978824291\n1::F::1::10::48067\n2::M::56::16::70072\n3::M::25::15::55117\n4::M::45::7::02460\n5::M::25::20::55455\n1::Toy Story (1995)::Animation|Children's|Comedy\n2::Jumanji (1995)::Adventure|Children's|Fantasy\n3::Grumpier Old Men (1995)::Comedy|Romance\n4::Waiting to Exhale (1995)::Comedy|Drama\n5::Father of the Bride Part II (1995)::Comedy\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"## 2.b. Write the TFX components, Beam PTransforms and unit tests\nand upload them to a reachable repository.  \nIf the repository is private, you can use Kaggle secrets to hold API keys, etc for use in download below.","metadata":{}},{"cell_type":"markdown","source":"## 3. Download the components and transforms","metadata":{}},{"cell_type":"markdown","source":"### 3.a. Ingestion\n\nThe first component is the ingestion and it's written using custom apache beam PTransforms and custom TFX components.\n\nCustomization was needed to ingest the 3 files (\"ratings.dat\", \"movies.dat\", \"users.dat\"), left join them on ratings, and then split them.\nThe components are called IngestMovieLensComponent and ingest_movie_lens_component for the fully customized  and the python function customized versions, respectively.\n\nI implemented the fully custom version and the python function component, but only one of them is needed.","metadata":{}},{"cell_type":"code","source":"%%bash\n#it can take a couple of minutes to get current version of recently uploaded file to github\n#wget -q -c --no-cache https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/main/src/test/python/test_tft.py -O /kaggle/working/test_tft.py\n#curl --header \"Cache-Control: no-cache\" \"https://api.github.com/repos/nking/recommender_systems/content/src/test/python/test_tft.py\" -o /kaggle/working/test_tft.py\n\nrepo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/main/python'\ndeclare -a my_files=(\"ingest_movie_lens_beam.py\" \"CustomUTF8Coder.py\" \"ingest_movie_lens_component.py\" \"movie_lens_utils.py\" \"ingest_movie_lens_custom_component.py\")\nfor item in \"${my_files[@]}\"\ndo\n  rm -f \"/kaggle/working/$item\"\n  echo \"$item\"\n  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\ndone\n\n#repo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/drafts/python'\n#declare -a my_files=(\"ingest_movie_lens_custom_component.py\")\n#for item in \"${my_files[@]}\"\n#do\n#  rm -f \"/kaggle/working/$item\"\n#  echo \"$item\"\n#  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\n#done\n\nrepo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/test/python'\ndeclare -a my_files=(\"ingest_movie_lens_beam_test.py\" \"ingest_movie_lens_component_test.py\" \"ingest_movie_lens_custom_component_test.py\" \"movie_lens_utils_test.py\" \"csv_example_gen_test.py\")\nfor item in \"${my_files[@]}\"\ndo\n  rm -f \"/kaggle/working/$item\"\n  echo \"$item\"\n  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\ndone\n\nls -l /kaggle/working/\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T03:18:14.881135Z","iopub.execute_input":"2025-10-10T03:18:14.881557Z","iopub.status.idle":"2025-10-10T03:18:16.708132Z","shell.execute_reply.started":"2025-10-10T03:18:14.881522Z","shell.execute_reply":"2025-10-10T03:18:16.707303Z"}},"outputs":[{"name":"stdout","text":"ingest_movie_lens_beam.py\nCustomUTF8Coder.py\ningest_movie_lens_component.py\nmovie_lens_utils.py\ningest_movie_lens_custom_component.py\ningest_movie_lens_beam_test.py\ningest_movie_lens_component_test.py\ningest_movie_lens_custom_component_test.py\nmovie_lens_utils_test.py\ncsv_example_gen_test.py\ntotal 112\ndrwxr-xr-x 6 root root  4096 Oct 10 01:17 bin\n-rw-r--r-- 1 root root  7335 Oct 10 03:18 csv_example_gen_test.py\n-rw-r--r-- 1 root root   777 Oct 10 03:18 CustomUTF8Coder.py\n-rw-r--r-- 1 root root  2392 Oct 10 02:28 dataset_tfxio_example.py\n-rw-r--r-- 1 root root  7899 Oct 10 03:18 ingest_movie_lens_beam.py\n-rw-r--r-- 1 root root  5043 Oct 10 03:18 ingest_movie_lens_beam_test.py\n-rw-r--r-- 1 root root  5796 Oct 10 03:18 ingest_movie_lens_component.py\n-rw-r--r-- 1 root root  9877 Oct 10 03:18 ingest_movie_lens_component_test.py\n-rw-r--r-- 1 root root 12556 Oct 10 03:18 ingest_movie_lens_custom_component.py\n-rw-r--r-- 1 root root 11768 Oct 10 03:18 ingest_movie_lens_custom_component_test.py\ndrwxr-x--- 3 root root  4096 Oct 10 02:28 ml-1m\n-rw-r--r-- 1 root root 11933 Oct 10 03:18 movie_lens_utils.py\n-rw-r--r-- 1 root root  4377 Oct 10 03:18 movie_lens_utils_test.py\ndrwxr-xr-x 2 root root  4096 Oct 10 02:33 __pycache__\nFri Oct 10 03:18:16 AM UTC 2025\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"### Run the unit tests","metadata":{}},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for CSVExampleGen\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/csv_example_gen_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T02:28:19.336098Z","iopub.execute_input":"2025-10-10T02:28:19.336380Z","iopub.status.idle":"2025-10-10T02:28:35.116382Z","shell.execute_reply.started":"2025-10-10T02:28:19.336360Z","shell.execute_reply":"2025-10-10T02:28:35.115311Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for CSVExampleGen\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\nkey=examples, value=OutputChannel(artifact_type=Examples, producer_component_id=CsvExampleGen, output_key=examples, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False)\nlisting files in output_data_dir /kaggle/working/bin/csv_comp_1/testRun:\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n14.148350710 seconds\nFri Oct 10 02:28:35 AM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"INFO:absl:tensorflow_io is not available: No module named 'tensorflow_io'\nINFO:absl:tensorflow_ranking is not available: No module named 'tensorflow_ranking'\nINFO:absl:tensorflow_text is not available: No module named 'tensorflow_text'\nINFO:absl:tensorflow_decision_forests is not available: No module named 'tensorflow_decision_forests'\nINFO:absl:struct2tensor is not available: No module named 'struct2tensor'\nINFO:absl:tensorflow_text is not available.\nINFO:absl:tensorflow_recommenders is not available.\nINFO:absl:Running driver for CsvExampleGen\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n}\n\nDEBUG:absl:Processing input /kaggle/working/ml-1m/tmp/.\nINFO:absl:select span and version = (0, None)\nINFO:absl:latest span and version = (0, None)\nDEBUG:absl:Resolved input artifacts are: {}\nDEBUG:absl:ID of run context test_csvgenexample is 1.\nDEBUG:absl:Pipeline context [test_csvgenexample : 1]\nDEBUG:absl:ID of run context test_csvgenexample.csv_comp_1 is 2.\nDEBUG:absl:Pipeline run context [test_csvgenexample.csv_comp_1 : 2]\nDEBUG:absl:Registering an execution type with id 12.\nDEBUG:absl:Prepared EXECUTION:\n type_id: 12\nlast_known_state: RUNNING\nproperties {\n  key: \"component_id\"\n  value {\n    string_value: \"CsvExampleGen\"\n  }\n}\nproperties {\n  key: \"custom_config\"\n  value {\n    string_value: \"None\"\n  }\n}\nproperties {\n  key: \"input_base\"\n  value {\n    string_value: \"/kaggle/working/ml-1m/tmp/\"\n  }\n}\nproperties {\n  key: \"input_config\"\n  value {\n    string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n  }\n}\nproperties {\n  key: \"input_fingerprint\"\n  value {\n    string_value: \"split:single_split,num_files:1,total_bytes:110208,xor_checksum:1760063309,sum_checksum:1760063309\"\n  }\n}\nproperties {\n  key: \"output_config\"\n  value {\n    string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 8,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"test\\\"\\n      }\\n    ]\\n  }\\n}\"\n  }\n}\nproperties {\n  key: \"output_data_format\"\n  value {\n    string_value: \"6\"\n  }\n}\nproperties {\n  key: \"output_file_format\"\n  value {\n    string_value: \"5\"\n  }\n}\nproperties {\n  key: \"pipeline_name\"\n  value {\n    string_value: \"test_csvgenexample\"\n  }\n}\nproperties {\n  key: \"pipeline_root\"\n  value {\n    string_value: \"/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample\"\n  }\n}\nproperties {\n  key: \"range_config\"\n  value {\n    string_value: \"None\"\n  }\n}\nproperties {\n  key: \"run_id\"\n  value {\n    string_value: \"csv_comp_1\"\n  }\n}\nproperties {\n  key: \"span\"\n  value {\n    string_value: \"0\"\n  }\n}\nproperties {\n  key: \"state\"\n  value {\n    string_value: \"new\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    string_value: \"None\"\n  }\n}\ntype: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n\nDEBUG:absl:Trying to fetch cached output artifacts with the following info: \ninput_artifacts: {} \nexec_properties: {'input_base': '/kaggle/working/ml-1m/tmp/', 'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"*\"\\n    }\\n  ]\\n}', 'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 8,\\n        \"name\": \"train\"\\n      },\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"eval\"\\n      },\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"test\"\\n      }\\n    ]\\n  }\\n}', 'output_data_format': 6, 'output_file_format': 5, 'custom_config': None, 'range_config': None, 'span': 0, 'version': None, 'input_fingerprint': 'split:single_split,num_files:1,total_bytes:110208,xor_checksum:1760063309,sum_checksum:1760063309'} \ncomponent_info ComponentInfo(component_type: tfx.components.example_gen.csv_example_gen.component.CsvExampleGen, component_id: CsvExampleGen, pipeline_info: PipelineInfo(pipeline_name: test_csvgenexample, pipeline_root: /kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample, run_id: csv_comp_1))\nDEBUG:absl:Prepared EXECUTION:\n type_id: 12\nlast_known_state: COMPLETE\nproperties {\n  key: \"component_id\"\n  value {\n    string_value: \"CsvExampleGen\"\n  }\n}\nproperties {\n  key: \"custom_config\"\n  value {\n    string_value: \"None\"\n  }\n}\nproperties {\n  key: \"input_base\"\n  value {\n    string_value: \"/kaggle/working/ml-1m/tmp/\"\n  }\n}\nproperties {\n  key: \"input_config\"\n  value {\n    string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n  }\n}\nproperties {\n  key: \"input_fingerprint\"\n  value {\n    string_value: \"split:single_split,num_files:1,total_bytes:110208,xor_checksum:1760063309,sum_checksum:1760063309\"\n  }\n}\nproperties {\n  key: \"output_config\"\n  value {\n    string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 8,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"test\\\"\\n      }\\n    ]\\n  }\\n}\"\n  }\n}\nproperties {\n  key: \"output_data_format\"\n  value {\n    string_value: \"6\"\n  }\n}\nproperties {\n  key: \"output_file_format\"\n  value {\n    string_value: \"5\"\n  }\n}\nproperties {\n  key: \"pipeline_name\"\n  value {\n    string_value: \"test_csvgenexample\"\n  }\n}\nproperties {\n  key: \"pipeline_root\"\n  value {\n    string_value: \"/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample\"\n  }\n}\nproperties {\n  key: \"range_config\"\n  value {\n    string_value: \"None\"\n  }\n}\nproperties {\n  key: \"run_id\"\n  value {\n    string_value: \"csv_comp_1\"\n  }\n}\nproperties {\n  key: \"span\"\n  value {\n    string_value: \"0\"\n  }\n}\nproperties {\n  key: \"state\"\n  value {\n    string_value: \"complete\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    string_value: \"None\"\n  }\n}\ntype: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n\nDEBUG:absl:Cached results not available, move on to new execution\nWARNING:absl:Output artifact uri /kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1 already exists\nDEBUG:absl:Output artifacts skeleton for the upcoming execution are: {'examples': [Artifact(artifact: uri: \"/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1\"\ncustom_properties {\n  key: \"input_fingerprint\"\n  value {\n    string_value: \"split:single_split,num_files:1,total_bytes:110208,xor_checksum:1760063309,sum_checksum:1760063309\"\n  }\n}\ncustom_properties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}\nDEBUG:absl:Execution properties for the upcoming execution are: {'input_base': '/kaggle/working/ml-1m/tmp/', 'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"*\"\\n    }\\n  ]\\n}', 'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 8,\\n        \"name\": \"train\"\\n      },\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"eval\"\\n      },\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"test\"\\n      }\\n    ]\\n  }\\n}', 'output_data_format': 6, 'output_file_format': 5, 'custom_config': None, 'range_config': None, 'span': 0, 'version': None, 'input_fingerprint': 'split:single_split,num_files:1,total_bytes:110208,xor_checksum:1760063309,sum_checksum:1760063309'}\nINFO:absl:Running executor for CsvExampleGen\nDEBUG:absl:Starting Executor execution.\nINFO:absl:Generating examples.\nINFO:absl:Processing input csv data /kaggle/working/ml-1m/tmp/* to TFExample.\nWARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\nWARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\nWARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\nWARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\nINFO:absl:Examples generated.\nINFO:absl:Running publisher for CsvExampleGen\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n}\n\nDEBUG:absl:MLMD store artifact_types=[]\nDEBUG:absl:MLMD store artifacts=[]\nDEBUG:absl:MLMD store executions=[]\nDEBUG:absl:contexts=[]\nDEBUG:absl:users_example_gen=CsvExampleGen(spec: <tfx.types.standard_component_specs.FileBasedExampleGenSpec object at 0x7f1e451023e0>, executor_spec: <tfx.dsl.components.base.executor_spec.BeamExecutorSpec object at 0x7f1e45102500>, driver_class: <class 'tfx.components.example_gen.driver.FileBasedDriver'>, component_id: CsvExampleGen, inputs: {}, outputs: {'examples': OutputChannel(artifact_type=Examples, producer_component_id=CsvExampleGen, output_key=examples, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False)})\n.s\n----------------------------------------------------------------------\nRan 2 tests in 3.024s\n\nOK (skipped=1)\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"%%bash\nhead -n 5 /kaggle/working/ml-1m/ratings.dat\nhead -n 5 /kaggle/working/ml-1m/users.dat\nhead -n 5 /kaggle/working/ml-1m/movies.dat","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T02:28:35.117555Z","iopub.execute_input":"2025-10-10T02:28:35.117953Z","iopub.status.idle":"2025-10-10T02:28:35.132684Z","shell.execute_reply.started":"2025-10-10T02:28:35.117834Z","shell.execute_reply":"2025-10-10T02:28:35.131805Z"}},"outputs":[{"name":"stdout","text":"1::1193::5::978300760\n1::661::3::978302109\n1::914::3::978301968\n1::3408::4::978300275\n1::2355::5::978824291\n1::F::1::10::48067\n2::M::56::16::70072\n3::M::25::15::55117\n4::M::45::7::02460\n5::M::25::20::55455\n1::Toy Story (1995)::Animation|Children's|Comedy\n2::Jumanji (1995)::Adventure|Children's|Fantasy\n3::Grumpier Old Men (1995)::Comedy|Romance\n4::Waiting to Exhale (1995)::Comedy|Drama\n5::Father of the Bride Part II (1995)::Comedy\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"!find /kaggle/working -type f\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T02:28:35.133641Z","iopub.execute_input":"2025-10-10T02:28:35.133889Z","iopub.status.idle":"2025-10-10T02:28:35.265497Z","shell.execute_reply.started":"2025-10-10T02:28:35.133870Z","shell.execute_reply":"2025-10-10T02:28:35.264326Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ingest_movie_lens_beam_test.py\n/kaggle/working/ingest_movie_lens_component.py\n/kaggle/working/dataset_tfxio_example.py\n/kaggle/working/ml-1m/tmp/users2.dat\n/kaggle/working/ml-1m/users.dat\n/kaggle/working/ml-1m/movies.dat\n/kaggle/working/ml-1m/ratings.dat\n/kaggle/working/ml-1m/README\n/kaggle/working/ingest_movie_lens_custom_component_test.py\n/kaggle/working/ingest_movie_lens_custom_component.py\n/kaggle/working/csv_example_gen_test.py\n/kaggle/working/movie_lens_utils_test.py\n/kaggle/working/movie_lens_utils.py\n/kaggle/working/__pycache__/ingest_movie_lens_beam_test.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils_test.cpython-310.pyc\n/kaggle/working/__pycache__/CustomUTF8Coder.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_component.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_custom_component.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_custom_component_test.cpython-310.pyc\n/kaggle/working/__pycache__/csv_example_gen_test.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_component_test.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_beam.cpython-310.pyc\n/kaggle/working/CustomUTF8Coder.py\n/kaggle/working/ingest_movie_lens_beam.py\n/kaggle/working/ingest_movie_lens_component_test.py\n/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1/Split-test/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1/Split-train/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1/Split-eval/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for utils methods\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/movie_lens_utils_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T02:28:35.266955Z","iopub.execute_input":"2025-10-10T02:28:35.267346Z","iopub.status.idle":"2025-10-10T02:28:41.973285Z","shell.execute_reply.started":"2025-10-10T02:28:35.267303Z","shell.execute_reply":"2025-10-10T02:28:41.972576Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for utils methods\n5.061283809 seconds\nFri Oct 10 02:28:41 AM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"...\n----------------------------------------------------------------------\nRan 3 tests in 0.001s\n\nOK\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for beam transforms\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/ingest_movie_lens_beam_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T02:28:41.974400Z","iopub.execute_input":"2025-10-10T02:28:41.974799Z","iopub.status.idle":"2025-10-10T02:30:14.819438Z","shell.execute_reply.started":"2025-10-10T02:28:41.974775Z","shell.execute_reply":"2025-10-10T02:30:14.818335Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for beam transforms\n91.207950183 seconds\nFri Oct 10 02:30:14 AM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"DEBUG:absl:columns=[('user_id', <class 'int'>), ('movie_id', <class 'int'>), ('rating', <class 'int'>), ('timestamp', <class 'int'>), ('gender', <class 'str'>), ('age', <class 'int'>), ('occupation', <class 'int'>), ('genres', <class 'str'>)]\nWARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['/kaggle/working/ingest_movie_lens_beam_test.py']\n.s\n----------------------------------------------------------------------\nRan 2 tests in 84.739s\n\nOK (skipped=1)\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for tfx python function custom component\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/ingest_movie_lens_component_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T02:30:14.820509Z","iopub.execute_input":"2025-10-10T02:30:14.820823Z","iopub.status.idle":"2025-10-10T02:33:50.464601Z","shell.execute_reply.started":"2025-10-10T02:30:14.820800Z","shell.execute_reply":"2025-10-10T02:33:50.463742Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for tfx python function custom component\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\nalt_output_data_dir=/tmp/runlvidiydx/tmpcofk59q1/test_ingest_movie_lens_component\nkey=output_examples\n  value=OutputChannel(artifact_type=Examples, producer_component_id=ingest_movie_lens_component, output_key=output_examples, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False)\nlisting files in PIPELINE_ROOT /kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline:\n/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1/Split-test/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1/Split-train/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1/Split-eval/data_tfrecord-00000-of-00001.tfrecord\n214.004767236 seconds\nFri Oct 10 02:33:50 AM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"DEBUG:absl:test output_config=split_config {\n  splits {\n    name: \"train\"\n    hash_buckets: 80\n  }\n  splits {\n    name: \"eval\"\n    hash_buckets: 10\n  }\n  splits {\n    name: \"test\"\n    hash_buckets: 10\n  }\n}\n\nDEBUG:absl:TYPE of ratings_example_gen=<class 'ingest_movie_lens_component.ingest_movie_lens_component'>\nINFO:absl:Using deployment config:\n executor_specs {\n  key: \"ingest_movie_lens_component\"\n  value {\n    beam_executable_spec {\n      python_executor_spec {\n        class_path: \"ingest_movie_lens_component.ingest_movie_lens_component_Executor\"\n      }\n    }\n  }\n}\nmetadata_connection_config {\n  database_connection_config {\n    sqlite {\n      filename_uri: \"/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\"\n      connection_mode: READWRITE_OPENCREATE\n    }\n  }\n}\n\nINFO:absl:Using connection config:\n sqlite {\n  filename_uri: \"/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component ingest_movie_lens_component is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"ingest_movie_lens_component.ingest_movie_lens_component\"\n  }\n  id: \"ingest_movie_lens_component\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonFuncCustomCompPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-10T02:30:26.129564\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonFuncCustomCompPipeline.ingest_movie_lens_component\"\n      }\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"output_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"infiles_dict_ser\"\n    value {\n      field_value {\n        string_value: \"gASVCQIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCEva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5ncy5kYXSUjA9oZWFkZXJzX3ByZXNlbnSUiYwFZGVsaW2UjAI6OpR1jAZtb3ZpZXOUfZQoaAN9lChoDH2UKGgHSwBoCGgLdYwFdGl0bGWUfZQoaAdLAWgIaAmMA3N0cpSTlHWMBmdlbnJlc5R9lChoB0sCaAhoHnV1aBKMIC9rYWdnbGUvd29ya2luZy9tbC0xbS9tb3ZpZXMuZGF0lGgUiWgVaBZ1jAV1c2Vyc5R9lChoA32UKGgFfZQoaAdLAGgIaAt1jAZnZW5kZXKUfZQoaAdLAWgIaB51jANhZ2WUfZQoaAdLAmgIaAt1jApvY2N1cGF0aW9ulH2UKGgHSwNoCGgLdYwHemlwY29kZZR9lChoB0sEaAhoHnV1aBKMHy9rYWdnbGUvd29ya2luZy9tbC0xbS91c2Vycy5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n      }\n    }\n  }\n  parameters {\n    key: \"output_config_ser\"\n    value {\n      field_value {\n        string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n      }\n    }\n  }\n}\nexecution_options {\n  caching_options {\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type pipeline and name TestPythonFuncCustomCompPipeline\nDEBUG:absl:ID of context type {\n  name: \"pipeline\"\n}\nname {\n  field_value {\n    string_value: \"TestPythonFuncCustomCompPipeline\"\n  }\n}\n is 1.\nDEBUG:absl:Failed to get context of type pipeline_run and name 2025-10-10T02:30:26.129564\nDEBUG:absl:ID of context type {\n  name: \"pipeline_run\"\n}\nname {\n  field_value {\n    string_value: \"2025-10-10T02:30:26.129564\"\n  }\n}\n is 2.\nDEBUG:absl:Failed to get context of type node and name TestPythonFuncCustomCompPipeline.ingest_movie_lens_component\nDEBUG:absl:ID of context type {\n  name: \"node\"\n}\nname {\n  field_value {\n    string_value: \"TestPythonFuncCustomCompPipeline.ingest_movie_lens_component\"\n  }\n}\n is 3.\nDEBUG:absl:Before conditional:\n{}\nDEBUG:absl:After conditional:\n{}\nINFO:absl:[ingest_movie_lens_component] Resolved inputs: ({},)\nDEBUG:absl:Prepared EXECUTION:\n type_id: 13\nlast_known_state: RUNNING\ncustom_properties {\n  key: \"infiles_dict_ser\"\n  value {\n    string_value: \"gASVCQIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCEva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5ncy5kYXSUjA9oZWFkZXJzX3ByZXNlbnSUiYwFZGVsaW2UjAI6OpR1jAZtb3ZpZXOUfZQoaAN9lChoDH2UKGgHSwBoCGgLdYwFdGl0bGWUfZQoaAdLAWgIaAmMA3N0cpSTlHWMBmdlbnJlc5R9lChoB0sCaAhoHnV1aBKMIC9rYWdnbGUvd29ya2luZy9tbC0xbS9tb3ZpZXMuZGF0lGgUiWgVaBZ1jAV1c2Vyc5R9lChoA32UKGgFfZQoaAdLAGgIaAt1jAZnZW5kZXKUfZQoaAdLAWgIaB51jANhZ2WUfZQoaAdLAmgIaAt1jApvY2N1cGF0aW9ulH2UKGgHSwNoCGgLdYwHemlwY29kZZR9lChoB0sEaAhoHnV1aBKMHy9rYWdnbGUvd29ya2luZy9tbC0xbS91c2Vycy5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n  }\n}\ncustom_properties {\n  key: \"output_config_ser\"\n  value {\n    string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n  }\n}\nname: \"b20b4f37-96bb-4d7e-8335-7aaf9a9d33d8\"\n\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type execution_cache and name f3534507293547bd644d1fc71668334bb2d50314dd2e507364b40947d3ab48f6\nDEBUG:absl:ID of context type {\n  name: \"execution_cache\"\n}\nname {\n  field_value {\n    string_value: \"f3534507293547bd644d1fc71668334bb2d50314dd2e507364b40947d3ab48f6\"\n  }\n}\n is 4.\nINFO:absl:Going to run a new execution 1\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1760063426.291592    3571 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=1, input_dict={}, output_dict=defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}), exec_properties={'output_config_ser': 'Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK', 'infiles_dict_ser': 'gASVCQIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCEva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5ncy5kYXSUjA9oZWFkZXJzX3ByZXNlbnSUiYwFZGVsaW2UjAI6OpR1jAZtb3ZpZXOUfZQoaAN9lChoDH2UKGgHSwBoCGgLdYwFdGl0bGWUfZQoaAdLAWgIaAmMA3N0cpSTlHWMBmdlbnJlc5R9lChoB0sCaAhoHnV1aBKMIC9rYWdnbGUvd29ya2luZy9tbC0xbS9tb3ZpZXMuZGF0lGgUiWgVaBZ1jAV1c2Vyc5R9lChoA32UKGgFfZQoaAdLAGgIaAt1jAZnZW5kZXKUfZQoaAdLAWgIaB51jANhZ2WUfZQoaAdLAmgIaAt1jApvY2N1cGF0aW9ulH2UKGgHSwNoCGgLdYwHemlwY29kZZR9lChoB0sEaAhoHnV1aBKMHy9rYWdnbGUvd29ya2luZy9tbC0xbS91c2Vycy5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg=='}, execution_output_uri='/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/.system/executor_execution/1/executor_output.pb', stateful_working_dir='/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/.system/stateful_working_dir/8d6f339f-e64b-45b4-b3f5-d5e6ae68bcd0', tmp_dir='/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/.system/executor_execution/1/.temp/', pipeline_node=node_info {\n  type {\n    name: \"ingest_movie_lens_component.ingest_movie_lens_component\"\n  }\n  id: \"ingest_movie_lens_component\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonFuncCustomCompPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-10T02:30:26.129564\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonFuncCustomCompPipeline.ingest_movie_lens_component\"\n      }\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"output_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"infiles_dict_ser\"\n    value {\n      field_value {\n        string_value: \"gASVCQIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCEva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5ncy5kYXSUjA9oZWFkZXJzX3ByZXNlbnSUiYwFZGVsaW2UjAI6OpR1jAZtb3ZpZXOUfZQoaAN9lChoDH2UKGgHSwBoCGgLdYwFdGl0bGWUfZQoaAdLAWgIaAmMA3N0cpSTlHWMBmdlbnJlc5R9lChoB0sCaAhoHnV1aBKMIC9rYWdnbGUvd29ya2luZy9tbC0xbS9tb3ZpZXMuZGF0lGgUiWgVaBZ1jAV1c2Vyc5R9lChoA32UKGgFfZQoaAdLAGgIaAt1jAZnZW5kZXKUfZQoaAdLAWgIaB51jANhZ2WUfZQoaAdLAmgIaAt1jApvY2N1cGF0aW9ulH2UKGgHSwNoCGgLdYwHemlwY29kZZR9lChoB0sEaAhoHnV1aBKMHy9rYWdnbGUvd29ya2luZy9tbC0xbS91c2Vycy5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n      }\n    }\n  }\n  parameters {\n    key: \"output_config_ser\"\n    value {\n      field_value {\n        string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n      }\n    }\n  }\n}\nexecution_options {\n  caching_options {\n  }\n}\n, pipeline_info=id: \"TestPythonFuncCustomCompPipeline\"\n, pipeline_run_id='2025-10-10T02:30:26.129564', top_level_pipeline_run_id=None, frontend_url=None)\nINFO:absl:ingest_movie_lens_component\nDEBUG:absl:output_examples was passed in to component\nDEBUG:absl:output_examples TYPE=<class 'tfx.types.standard_artifacts.Examples'>\nDEBUG:absl:output_examples=Artifact(artifact: uri: \"/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)\nDEBUG:absl:split_names=['train', 'eval', 'test']\nDEBUG:absl:columns=[('user_id', <class 'int'>), ('movie_id', <class 'int'>), ('rating', <class 'int'>), ('timestamp', <class 'int'>), ('gender', <class 'str'>), ('age', <class 'int'>), ('occupation', <class 'int'>), ('genres', <class 'str'>)]\nDEBUG:absl:cumulative_buckets=[80, 90, 100]\nDEBUG:absl:have ratings_tuple.  type=<class 'apache_beam.pvalue.DoOutputsTuple'>\nDEBUG:absl:prefix_path=/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1/Split-train/data_tfrecord\nDEBUG:absl:prefix_path=/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1/Split-eval/data_tfrecord\nDEBUG:absl:prefix_path=/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1/Split-test/data_tfrecord\nINFO:absl:output_examples written as TFRecords\nWARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\nINFO:absl:Cleaning up stateless execution info.\nINFO:absl:Execution 1 succeeded.\nINFO:absl:Cleaning up stateful execution info.\nINFO:absl:Deleted stateful_working_dir /kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/.system/stateful_working_dir/8d6f339f-e64b-45b4-b3f5-d5e6ae68bcd0\nINFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}) for execution 1\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component ingest_movie_lens_component is finished.\nDEBUG:absl:ratings_example_gen=ingest_movie_lens_component(spec: <tfx.dsl.component.experimental.utils.ingest_movie_lens_component_Spec object at 0x7ac515415870>, executor_spec: <tfx.dsl.components.base.executor_spec.BeamExecutorSpec object at 0x7ac5154158a0>, driver_class: <class 'tfx.dsl.components.base.base_driver.BaseDriver'>, component_id: ingest_movie_lens_component, inputs: {}, outputs: {'output_examples': OutputChannel(artifact_type=Examples, producer_component_id=ingest_movie_lens_component, output_key=output_examples, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False)})\nDEBUG:absl:ratings_example_gen.id=ingest_movie_lens_component\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:MLMD store artifact_types=[id: 15\nname: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n]\nDEBUG:absl:MLMD store artifacts=[id: 1\ntype_id: 15\nuri: \"/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1\"\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Examples\"\ncreate_time_since_epoch: 1760063628062\nlast_update_time_since_epoch: 1760063628062\n]\nDEBUG:absl:MLMD store executions=[id: 1\ntype_id: 13\nlast_known_state: COMPLETE\ncustom_properties {\n  key: \"infiles_dict_ser\"\n  value {\n    string_value: \"gASVCQIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCEva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5ncy5kYXSUjA9oZWFkZXJzX3ByZXNlbnSUiYwFZGVsaW2UjAI6OpR1jAZtb3ZpZXOUfZQoaAN9lChoDH2UKGgHSwBoCGgLdYwFdGl0bGWUfZQoaAdLAWgIaAmMA3N0cpSTlHWMBmdlbnJlc5R9lChoB0sCaAhoHnV1aBKMIC9rYWdnbGUvd29ya2luZy9tbC0xbS9tb3ZpZXMuZGF0lGgUiWgVaBZ1jAV1c2Vyc5R9lChoA32UKGgFfZQoaAdLAGgIaAt1jAZnZW5kZXKUfZQoaAdLAWgIaB51jANhZ2WUfZQoaAdLAmgIaAt1jApvY2N1cGF0aW9ulH2UKGgHSwNoCGgLdYwHemlwY29kZZR9lChoB0sEaAhoHnV1aBKMHy9rYWdnbGUvd29ya2luZy9tbC0xbS91c2Vycy5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n  }\n}\ncustom_properties {\n  key: \"output_config_ser\"\n  value {\n    string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n  }\n}\nname: \"b20b4f37-96bb-4d7e-8335-7aaf9a9d33d8\"\ntype: \"ingest_movie_lens_component.ingest_movie_lens_component\"\ncreate_time_since_epoch: 1760063426246\nlast_update_time_since_epoch: 1760063628063\n]\n.s\n----------------------------------------------------------------------\nRan 2 tests in 202.861s\n\nOK (skipped=1)\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"!find /kaggle/working -type f\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T02:33:50.467440Z","iopub.execute_input":"2025-10-10T02:33:50.467728Z","iopub.status.idle":"2025-10-10T02:33:50.594842Z","shell.execute_reply.started":"2025-10-10T02:33:50.467706Z","shell.execute_reply":"2025-10-10T02:33:50.593765Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ingest_movie_lens_beam_test.py\n/kaggle/working/ingest_movie_lens_component.py\n/kaggle/working/dataset_tfxio_example.py\n/kaggle/working/ml-1m/tmp/users2.dat\n/kaggle/working/ml-1m/users.dat\n/kaggle/working/ml-1m/movies.dat\n/kaggle/working/ml-1m/ratings.dat\n/kaggle/working/ml-1m/README\n/kaggle/working/ingest_movie_lens_custom_component_test.py\n/kaggle/working/ingest_movie_lens_custom_component.py\n/kaggle/working/csv_example_gen_test.py\n/kaggle/working/movie_lens_utils_test.py\n/kaggle/working/movie_lens_utils.py\n/kaggle/working/__pycache__/ingest_movie_lens_beam_test.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils_test.cpython-310.pyc\n/kaggle/working/__pycache__/CustomUTF8Coder.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_component.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_custom_component.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_custom_component_test.cpython-310.pyc\n/kaggle/working/__pycache__/csv_example_gen_test.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_component_test.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_beam.cpython-310.pyc\n/kaggle/working/CustomUTF8Coder.py\n/kaggle/working/ingest_movie_lens_beam.py\n/kaggle/working/ingest_movie_lens_component_test.py\n/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1/Split-test/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1/Split-train/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1/Split-eval/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for TFX fully custom component\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/ingest_movie_lens_custom_component_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T03:19:20.171366Z","iopub.execute_input":"2025-10-10T03:19:20.171690Z","iopub.status.idle":"2025-10-10T03:27:03.752607Z","shell.execute_reply.started":"2025-10-10T03:19:20.171669Z","shell.execute_reply":"2025-10-10T03:27:03.751454Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for TFX fully custom component\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\nalt_output_data_dir=/tmp/run669s4bzy/tmpvj8u5_nm/testRun2\nkey=output_examples, value=OutputChannel(artifact_type=Examples, producer_component_id=IngestMovieLensComponent, output_key=output_examples, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False)\nlisting files in output_data_dir /kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline:\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n461.879239119 seconds\nFri Oct 10 03:27:03 AM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"DEBUG:absl:test self.output_config=split_config {\n  splits {\n    name: \"train\"\n    hash_buckets: 80\n  }\n  splits {\n    name: \"eval\"\n    hash_buckets: 10\n  }\n  splits {\n    name: \"test\"\n    hash_buckets: 10\n  }\n}\n\nDEBUG:absl:in IngestMovieLensExecutor.Do\nDEBUG:absl:in IngestMovieLensExecutor.GenerateExamplesByBeam\nDEBUG:absl:about to read input and transform to tf.train.Example\nDEBUG:absl:infiles_dict_ser=gASVCQIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCEva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5ncy5kYXSUjA9oZWFkZXJzX3ByZXNlbnSUiYwFZGVsaW2UjAI6OpR1jAZtb3ZpZXOUfZQoaAN9lChoDH2UKGgHSwBoCGgLdYwFdGl0bGWUfZQoaAdLAWgIaAmMA3N0cpSTlHWMBmdlbnJlc5R9lChoB0sCaAhoHnV1aBKMIC9rYWdnbGUvd29ya2luZy9tbC0xbS9tb3ZpZXMuZGF0lGgUiWgVaBZ1jAV1c2Vyc5R9lChoA32UKGgFfZQoaAdLAGgIaAt1jAZnZW5kZXKUfZQoaAdLAWgIaB51jANhZ2WUfZQoaAdLAmgIaAt1jApvY2N1cGF0aW9ulH2UKGgHSwNoCGgLdYwHemlwY29kZZR9lChoB0sEaAhoHnV1aBKMHy9rYWdnbGUvd29ya2luZy9tbC0xbS91c2Vycy5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\ninfiles_dict={'ratings': {'cols': {'user_id': {'index': 0, 'type': <class 'int'>}, 'movie_id': {'index': 1, 'type': <class 'int'>}, 'rating': {'index': 2, 'type': <class 'int'>}, 'timestamp': {'index': 3, 'type': <class 'int'>}}, 'uri': '/kaggle/working/ml-1m/ratings.dat', 'headers_present': False, 'delim': '::'}, 'movies': {'cols': {'movie_id': {'index': 0, 'type': <class 'int'>}, 'title': {'index': 1, 'type': <class 'str'>}, 'genres': {'index': 2, 'type': <class 'str'>}}, 'uri': '/kaggle/working/ml-1m/movies.dat', 'headers_present': False, 'delim': '::'}, 'users': {'cols': {'user_id': {'index': 0, 'type': <class 'int'>}, 'gender': {'index': 1, 'type': <class 'str'>}, 'age': {'index': 2, 'type': <class 'int'>}, 'occupation': {'index': 3, 'type': <class 'int'>}, 'zipcode': {'index': 4, 'type': <class 'str'>}}, 'uri': '/kaggle/working/ml-1m/users.dat', 'headers_present': False, 'delim': '::'}, 'version': 1}\nDEBUG:absl:columns=[('user_id', <class 'int'>), ('movie_id', <class 'int'>), ('rating', <class 'int'>), ('timestamp', <class 'int'>), ('gender', <class 'str'>), ('age', <class 'int'>), ('occupation', <class 'int'>), ('genres', <class 'str'>)]\nDEBUG:absl:have read, left joined, converted to tf.tran.Example, and split.  about to write to uri\nDEBUG:absl:output_examples TYPE=<class 'tfx.types.standard_artifacts.Examples'>\nDEBUG:absl:output_examples=Artifact(artifact: uri: \"/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)\nDEBUG:absl:prefix_path=/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-train/data_tfrecord\nDEBUG:absl:prefix_path=/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-eval/data_tfrecord\nDEBUG:absl:prefix_path=/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-test/data_tfrecord\nINFO:absl:output_examples written as TFRecords\nWARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\nWARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\nWARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\nWARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n.DEBUG:absl:test self.output_config=split_config {\n  splits {\n    name: \"train\"\n    hash_buckets: 80\n  }\n  splits {\n    name: \"eval\"\n    hash_buckets: 10\n  }\n  splits {\n    name: \"test\"\n    hash_buckets: 10\n  }\n}\n\nDEBUG:absl:DEBUG IngestMovieLensComponent init\nINFO:absl:Using deployment config:\n executor_specs {\n  key: \"IngestMovieLensComponent\"\n  value {\n    beam_executable_spec {\n      python_executor_spec {\n        class_path: \"ingest_movie_lens_custom_component.IngestMovieLensExecutor\"\n      }\n    }\n  }\n}\nmetadata_connection_config {\n  database_connection_config {\n    sqlite {\n      filename_uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/tfx_metadata/metadata.db\"\n      connection_mode: READWRITE_OPENCREATE\n    }\n  }\n}\n\nINFO:absl:Using connection config:\n sqlite {\n  filename_uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component IngestMovieLensComponent is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"ingest_movie_lens_custom_component.IngestMovieLensComponent\"\n  }\n  id: \"IngestMovieLensComponent\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestFullyCustomCompPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-10T03:23:14.699407\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestFullyCustomCompPipeline.IngestMovieLensComponent\"\n      }\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"output_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"infiles_dict_ser\"\n    value {\n      field_value {\n        string_value: \"gASVCQIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCEva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5ncy5kYXSUjA9oZWFkZXJzX3ByZXNlbnSUiYwFZGVsaW2UjAI6OpR1jAZtb3ZpZXOUfZQoaAN9lChoDH2UKGgHSwBoCGgLdYwFdGl0bGWUfZQoaAdLAWgIaAmMA3N0cpSTlHWMBmdlbnJlc5R9lChoB0sCaAhoHnV1aBKMIC9rYWdnbGUvd29ya2luZy9tbC0xbS9tb3ZpZXMuZGF0lGgUiWgVaBZ1jAV1c2Vyc5R9lChoA32UKGgFfZQoaAdLAGgIaAt1jAZnZW5kZXKUfZQoaAdLAWgIaB51jANhZ2WUfZQoaAdLAmgIaAt1jApvY2N1cGF0aW9ulH2UKGgHSwNoCGgLdYwHemlwY29kZZR9lChoB0sEaAhoHnV1aBKMHy9rYWdnbGUvd29ya2luZy9tbC0xbS91c2Vycy5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n      }\n    }\n  }\n  parameters {\n    key: \"name\"\n    value {\n      field_value {\n        string_value: \"test_fully_custom_component\"\n      }\n    }\n  }\n  parameters {\n    key: \"output_config_ser\"\n    value {\n      field_value {\n        string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n      }\n    }\n  }\n}\nexecution_options {\n  caching_options {\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type pipeline and name TestFullyCustomCompPipeline\nDEBUG:absl:ID of context type {\n  name: \"pipeline\"\n}\nname {\n  field_value {\n    string_value: \"TestFullyCustomCompPipeline\"\n  }\n}\n is 1.\nDEBUG:absl:Failed to get context of type pipeline_run and name 2025-10-10T03:23:14.699407\nDEBUG:absl:ID of context type {\n  name: \"pipeline_run\"\n}\nname {\n  field_value {\n    string_value: \"2025-10-10T03:23:14.699407\"\n  }\n}\n is 2.\nDEBUG:absl:Failed to get context of type node and name TestFullyCustomCompPipeline.IngestMovieLensComponent\nDEBUG:absl:ID of context type {\n  name: \"node\"\n}\nname {\n  field_value {\n    string_value: \"TestFullyCustomCompPipeline.IngestMovieLensComponent\"\n  }\n}\n is 3.\nDEBUG:absl:Before conditional:\n{}\nDEBUG:absl:After conditional:\n{}\nINFO:absl:[IngestMovieLensComponent] Resolved inputs: ({},)\nDEBUG:absl:Prepared EXECUTION:\n type_id: 13\nlast_known_state: RUNNING\ncustom_properties {\n  key: \"infiles_dict_ser\"\n  value {\n    string_value: \"gASVCQIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCEva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5ncy5kYXSUjA9oZWFkZXJzX3ByZXNlbnSUiYwFZGVsaW2UjAI6OpR1jAZtb3ZpZXOUfZQoaAN9lChoDH2UKGgHSwBoCGgLdYwFdGl0bGWUfZQoaAdLAWgIaAmMA3N0cpSTlHWMBmdlbnJlc5R9lChoB0sCaAhoHnV1aBKMIC9rYWdnbGUvd29ya2luZy9tbC0xbS9tb3ZpZXMuZGF0lGgUiWgVaBZ1jAV1c2Vyc5R9lChoA32UKGgFfZQoaAdLAGgIaAt1jAZnZW5kZXKUfZQoaAdLAWgIaB51jANhZ2WUfZQoaAdLAmgIaAt1jApvY2N1cGF0aW9ulH2UKGgHSwNoCGgLdYwHemlwY29kZZR9lChoB0sEaAhoHnV1aBKMHy9rYWdnbGUvd29ya2luZy9tbC0xbS91c2Vycy5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n  }\n}\ncustom_properties {\n  key: \"name\"\n  value {\n    string_value: \"test_fully_custom_component\"\n  }\n}\ncustom_properties {\n  key: \"output_config_ser\"\n  value {\n    string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n  }\n}\nname: \"d057ceeb-dde2-456f-b0ba-437692041f01\"\n\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type execution_cache and name a1be5e1b8abb5d905868c991fecc59af64564e25e53c3f94959e3e69d5223e6c\nDEBUG:absl:ID of context type {\n  name: \"execution_cache\"\n}\nname {\n  field_value {\n    string_value: \"a1be5e1b8abb5d905868c991fecc59af64564e25e53c3f94959e3e69d5223e6c\"\n  }\n}\n is 4.\nINFO:absl:Going to run a new execution 1\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1760066594.847016    3769 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=1, input_dict={}, output_dict=defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}), exec_properties={'output_config_ser': 'Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK', 'infiles_dict_ser': 'gASVCQIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCEva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5ncy5kYXSUjA9oZWFkZXJzX3ByZXNlbnSUiYwFZGVsaW2UjAI6OpR1jAZtb3ZpZXOUfZQoaAN9lChoDH2UKGgHSwBoCGgLdYwFdGl0bGWUfZQoaAdLAWgIaAmMA3N0cpSTlHWMBmdlbnJlc5R9lChoB0sCaAhoHnV1aBKMIC9rYWdnbGUvd29ya2luZy9tbC0xbS9tb3ZpZXMuZGF0lGgUiWgVaBZ1jAV1c2Vyc5R9lChoA32UKGgFfZQoaAdLAGgIaAt1jAZnZW5kZXKUfZQoaAdLAWgIaB51jANhZ2WUfZQoaAdLAmgIaAt1jApvY2N1cGF0aW9ulH2UKGgHSwNoCGgLdYwHemlwY29kZZR9lChoB0sEaAhoHnV1aBKMHy9rYWdnbGUvd29ya2luZy9tbC0xbS91c2Vycy5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==', 'name': 'test_fully_custom_component'}, execution_output_uri='/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/.system/executor_execution/1/executor_output.pb', stateful_working_dir='/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/.system/stateful_working_dir/1352f37a-bdb2-40a8-9f0e-75f1359497db', tmp_dir='/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/.system/executor_execution/1/.temp/', pipeline_node=node_info {\n  type {\n    name: \"ingest_movie_lens_custom_component.IngestMovieLensComponent\"\n  }\n  id: \"IngestMovieLensComponent\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestFullyCustomCompPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-10T03:23:14.699407\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestFullyCustomCompPipeline.IngestMovieLensComponent\"\n      }\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"output_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"infiles_dict_ser\"\n    value {\n      field_value {\n        string_value: \"gASVCQIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCEva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5ncy5kYXSUjA9oZWFkZXJzX3ByZXNlbnSUiYwFZGVsaW2UjAI6OpR1jAZtb3ZpZXOUfZQoaAN9lChoDH2UKGgHSwBoCGgLdYwFdGl0bGWUfZQoaAdLAWgIaAmMA3N0cpSTlHWMBmdlbnJlc5R9lChoB0sCaAhoHnV1aBKMIC9rYWdnbGUvd29ya2luZy9tbC0xbS9tb3ZpZXMuZGF0lGgUiWgVaBZ1jAV1c2Vyc5R9lChoA32UKGgFfZQoaAdLAGgIaAt1jAZnZW5kZXKUfZQoaAdLAWgIaB51jANhZ2WUfZQoaAdLAmgIaAt1jApvY2N1cGF0aW9ulH2UKGgHSwNoCGgLdYwHemlwY29kZZR9lChoB0sEaAhoHnV1aBKMHy9rYWdnbGUvd29ya2luZy9tbC0xbS91c2Vycy5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n      }\n    }\n  }\n  parameters {\n    key: \"name\"\n    value {\n      field_value {\n        string_value: \"test_fully_custom_component\"\n      }\n    }\n  }\n  parameters {\n    key: \"output_config_ser\"\n    value {\n      field_value {\n        string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n      }\n    }\n  }\n}\nexecution_options {\n  caching_options {\n  }\n}\n, pipeline_info=id: \"TestFullyCustomCompPipeline\"\n, pipeline_run_id='2025-10-10T03:23:14.699407', top_level_pipeline_run_id=None, frontend_url=None)\nDEBUG:absl:in IngestMovieLensExecutor.Do\nDEBUG:absl:in IngestMovieLensExecutor.GenerateExamplesByBeam\nDEBUG:absl:about to read input and transform to tf.train.Example\nDEBUG:absl:infiles_dict_ser=gASVCQIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCEva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5ncy5kYXSUjA9oZWFkZXJzX3ByZXNlbnSUiYwFZGVsaW2UjAI6OpR1jAZtb3ZpZXOUfZQoaAN9lChoDH2UKGgHSwBoCGgLdYwFdGl0bGWUfZQoaAdLAWgIaAmMA3N0cpSTlHWMBmdlbnJlc5R9lChoB0sCaAhoHnV1aBKMIC9rYWdnbGUvd29ya2luZy9tbC0xbS9tb3ZpZXMuZGF0lGgUiWgVaBZ1jAV1c2Vyc5R9lChoA32UKGgFfZQoaAdLAGgIaAt1jAZnZW5kZXKUfZQoaAdLAWgIaB51jANhZ2WUfZQoaAdLAmgIaAt1jApvY2N1cGF0aW9ulH2UKGgHSwNoCGgLdYwHemlwY29kZZR9lChoB0sEaAhoHnV1aBKMHy9rYWdnbGUvd29ya2luZy9tbC0xbS91c2Vycy5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\ninfiles_dict={'ratings': {'cols': {'user_id': {'index': 0, 'type': <class 'int'>}, 'movie_id': {'index': 1, 'type': <class 'int'>}, 'rating': {'index': 2, 'type': <class 'int'>}, 'timestamp': {'index': 3, 'type': <class 'int'>}}, 'uri': '/kaggle/working/ml-1m/ratings.dat', 'headers_present': False, 'delim': '::'}, 'movies': {'cols': {'movie_id': {'index': 0, 'type': <class 'int'>}, 'title': {'index': 1, 'type': <class 'str'>}, 'genres': {'index': 2, 'type': <class 'str'>}}, 'uri': '/kaggle/working/ml-1m/movies.dat', 'headers_present': False, 'delim': '::'}, 'users': {'cols': {'user_id': {'index': 0, 'type': <class 'int'>}, 'gender': {'index': 1, 'type': <class 'str'>}, 'age': {'index': 2, 'type': <class 'int'>}, 'occupation': {'index': 3, 'type': <class 'int'>}, 'zipcode': {'index': 4, 'type': <class 'str'>}}, 'uri': '/kaggle/working/ml-1m/users.dat', 'headers_present': False, 'delim': '::'}, 'version': 1}\nDEBUG:absl:columns=[('user_id', <class 'int'>), ('movie_id', <class 'int'>), ('rating', <class 'int'>), ('timestamp', <class 'int'>), ('gender', <class 'str'>), ('age', <class 'int'>), ('occupation', <class 'int'>), ('genres', <class 'str'>)]\nDEBUG:absl:have read, left joined, converted to tf.tran.Example, and split.  about to write to uri\nDEBUG:absl:output_examples TYPE=<class 'list'>\nDEBUG:absl:output_examples=[Artifact(artifact: uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]\nDEBUG:absl:prefix_path=/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-train/data_tfrecord\nDEBUG:absl:prefix_path=/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-eval/data_tfrecord\nDEBUG:absl:prefix_path=/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-test/data_tfrecord\nINFO:absl:output_examples written as TFRecords\nINFO:absl:Cleaning up stateless execution info.\nINFO:absl:Execution 1 succeeded.\nINFO:absl:Cleaning up stateful execution info.\nINFO:absl:Deleted stateful_working_dir /kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/.system/stateful_working_dir/1352f37a-bdb2-40a8-9f0e-75f1359497db\nINFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}) for execution 1\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component IngestMovieLensComponent is finished.\nDEBUG:absl:TYPE of ratings_example_gen=<class 'ingest_movie_lens_custom_component.IngestMovieLensComponent'>\nDEBUG:absl:ratings_example_gen=IngestMovieLensComponent(spec: <ingest_movie_lens_custom_component.IngestMovieLensExecutorSpec object at 0x7d2b197cf8e0>, executor_spec: <tfx.dsl.components.base.executor_spec.BeamExecutorSpec object at 0x7d2b197cc400>, driver_class: <class 'tfx.dsl.components.base.base_driver.BaseDriver'>, component_id: IngestMovieLensComponent, inputs: {}, outputs: {'output_examples': OutputChannel(artifact_type=Examples, producer_component_id=IngestMovieLensComponent, output_key=output_examples, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False)})\nDEBUG:absl:ratings_example_gen.outputs[\"output_examples\"]=OutputChannel(artifact_type=Examples, producer_component_id=IngestMovieLensComponent, output_key=output_examples, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False)\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:MLMD store artifact_types=[id: 15\nname: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n]\nDEBUG:absl:MLMD store artifacts=[id: 1\ntype_id: 15\nuri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1\"\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Examples\"\ncreate_time_since_epoch: 1760066821334\nlast_update_time_since_epoch: 1760066821334\n]\nDEBUG:absl:MLMD store executions=[id: 1\ntype_id: 13\nlast_known_state: COMPLETE\ncustom_properties {\n  key: \"infiles_dict_ser\"\n  value {\n    string_value: \"gASVCQIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCEva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5ncy5kYXSUjA9oZWFkZXJzX3ByZXNlbnSUiYwFZGVsaW2UjAI6OpR1jAZtb3ZpZXOUfZQoaAN9lChoDH2UKGgHSwBoCGgLdYwFdGl0bGWUfZQoaAdLAWgIaAmMA3N0cpSTlHWMBmdlbnJlc5R9lChoB0sCaAhoHnV1aBKMIC9rYWdnbGUvd29ya2luZy9tbC0xbS9tb3ZpZXMuZGF0lGgUiWgVaBZ1jAV1c2Vyc5R9lChoA32UKGgFfZQoaAdLAGgIaAt1jAZnZW5kZXKUfZQoaAdLAWgIaB51jANhZ2WUfZQoaAdLAmgIaAt1jApvY2N1cGF0aW9ulH2UKGgHSwNoCGgLdYwHemlwY29kZZR9lChoB0sEaAhoHnV1aBKMHy9rYWdnbGUvd29ya2luZy9tbC0xbS91c2Vycy5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n  }\n}\ncustom_properties {\n  key: \"name\"\n  value {\n    string_value: \"test_fully_custom_component\"\n  }\n}\ncustom_properties {\n  key: \"output_config_ser\"\n  value {\n    string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n  }\n}\nname: \"d057ceeb-dde2-456f-b0ba-437692041f01\"\ntype: \"ingest_movie_lens_custom_component.IngestMovieLensComponent\"\ncreate_time_since_epoch: 1760066594801\nlast_update_time_since_epoch: 1760066821334\n]\n.s\n----------------------------------------------------------------------\nRan 3 tests in 450.595s\n\nOK (skipped=1)\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"!find /kaggle/working -type f","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T02:41:30.644778Z","iopub.execute_input":"2025-10-10T02:41:30.645055Z","iopub.status.idle":"2025-10-10T02:41:30.773708Z","shell.execute_reply.started":"2025-10-10T02:41:30.645033Z","shell.execute_reply":"2025-10-10T02:41:30.772442Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ingest_movie_lens_beam_test.py\n/kaggle/working/ingest_movie_lens_component.py\n/kaggle/working/dataset_tfxio_example.py\n/kaggle/working/ml-1m/tmp/users2.dat\n/kaggle/working/ml-1m/users.dat\n/kaggle/working/ml-1m/movies.dat\n/kaggle/working/ml-1m/ratings.dat\n/kaggle/working/ml-1m/README\n/kaggle/working/ingest_movie_lens_custom_component_test.py\n/kaggle/working/ingest_movie_lens_custom_component.py\n/kaggle/working/csv_example_gen_test.py\n/kaggle/working/movie_lens_utils_test.py\n/kaggle/working/movie_lens_utils.py\n/kaggle/working/__pycache__/ingest_movie_lens_beam_test.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils_test.cpython-310.pyc\n/kaggle/working/__pycache__/CustomUTF8Coder.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_component.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_custom_component.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_custom_component_test.cpython-310.pyc\n/kaggle/working/__pycache__/csv_example_gen_test.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_component_test.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_beam.cpython-310.pyc\n/kaggle/working/CustomUTF8Coder.py\n/kaggle/working/ingest_movie_lens_beam.py\n/kaggle/working/ingest_movie_lens_component_test.py\n/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1/Split-test/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1/Split-train/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_ingest_movie_lens_component/TestPythonFuncCustomCompPipeline/ingest_movie_lens_component/output_examples/1/Split-eval/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n","output_type":"stream"}],"execution_count":45}]}