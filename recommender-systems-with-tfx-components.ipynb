{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:36:30.943712Z","iopub.execute_input":"2025-10-15T23:36:30.944041Z","iopub.status.idle":"2025-10-15T23:36:30.952529Z","shell.execute_reply.started":"2025-10-15T23:36:30.944014Z","shell.execute_reply":"2025-10-15T23:36:30.951599Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Recommender System with TFX pipelines\nThe notebook builds MLOps components and pipelines using TFX for the recommender system [here.](https://www.kaggle.com/code/nicholeasuniquename/recommender-systems/)\n\n1. Create a virtual environment for TFX compatability\n2. Build the TFX components and upload to the public repository.\n3. Download the components and test them in the virtual environment here.\n4. Build the MLOps pipelines, upload to public repository.\n5. Download the pipelines and test in the virtual environment here.\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Creating the TFX compatible virtual environment\n\ntfx version 1.16.0 is latest stable as of Sep 28, 2025\n\nIt is compatible with python 3.9 and 3.10 only.\n\nThe current kaggle python docker image uses python 3.11.13.\n\nTo use an earlier version of python on Kaggle, one can install conda and create a virtual environment that is based on an earlier version of python. \n\nOnce conda is installed and a virtual environment is created for the earlier version of python, the virtual environment can be activated by activating conda and then activating the virtual environment.\n\nA bash shell in the notebook that is invoked from the magic command %%bash is a bash session for the extent of that specific cell.\nFor each new session invoked by the cell %%bash, the 2 activation commands need to be invoked before using the virtual environment.\n\nAside from running scripts in the magic bash shell cells, we can also run scripts using the python subprocess library as long as we prepend commands with the 2 conda activation statements (see details in the definition for the run_command below).\n\nWe have 2 ways to run commands within the virtual environment.\n\nThe notebook itself is still using the kaggle docker image environment without the newly built virtual environment.\nEven if we install and use ipykernel to register a kernel for the new virtual environment, I don't see a way to open the notebook to use the new kernel.  (In the Kaggle window, we have Session options, persistence option to persist files and variables, so it might be possible to restart the notebook with kernel selected as long as the kernel has Kaggle specific notebook support...)\n\nIn summary, the notebook as is can be used for intermediate steps of EDA where the EDA uses libraries that don't require an earlier version of python.  For MLOps steps that need an earlier version of python, the virtual environment is available.\n","metadata":{}},{"cell_type":"code","source":"!pwd\n!echo $HOME","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:36:30.962650Z","iopub.execute_input":"2025-10-15T23:36:30.963049Z","iopub.status.idle":"2025-10-15T23:36:31.212099Z","shell.execute_reply.started":"2025-10-15T23:36:30.963023Z","shell.execute_reply":"2025-10-15T23:36:31.211125Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n/root\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"%%bash: Executes the entire cell as a shell script. ","metadata":{}},{"cell_type":"code","source":"%%bash\nt0=$(date +%s%N)\nmkdir -p ~/miniconda3\nwget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n#install conda and activate to /usr/local\nbash ~/miniconda3/miniconda.sh -b -u -p /usr/local\nrm ~/miniconda3/miniconda.sh\nconda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\nconda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n\n. /usr/local/bin/activate\necho \"**$SHELL**\"\necho \"**$BASH**\"\nconda init --all\n\n. /root/.bashrc\nconda create -q --name my_tfx_env python=3.10 -y\nconda activate my_tfx_env\npython --version\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:36:31.214168Z","iopub.execute_input":"2025-10-15T23:36:31.214463Z","iopub.status.idle":"2025-10-15T23:37:10.186878Z","shell.execute_reply.started":"2025-10-15T23:36:31.214433Z","shell.execute_reply":"2025-10-15T23:37:10.186029Z"}},"outputs":[{"name":"stdout","text":"PREFIX=/usr/local\nUnpacking bootstrapper...\nUnpacking payload...\n\nInstalling base environment...\n\nPreparing transaction: ...working... done\nExecuting transaction: ...working... done\ninstallation finished.\nWARNING:\n    You currently have a PYTHONPATH environment variable set. This may cause\n    unexpected behavior when running the Python interpreter in Miniconda3.\n    For best results, please verify that your PYTHONPATH only points to\n    directories of packages that are compatible with the Python interpreter\n    in Miniconda3: /usr/local\naccepted Terms of Service for https://repo.anaconda.com/pkgs/main\naccepted Terms of Service for https://repo.anaconda.com/pkgs/r\n**/bin/bash**\n**/usr/bin/bash**\nno change     /usr/local/condabin/conda\nno change     /usr/local/bin/conda\nno change     /usr/local/bin/conda-env\nno change     /usr/local/bin/activate\nno change     /usr/local/bin/deactivate\nno change     /usr/local/etc/profile.d/conda.sh\nno change     /usr/local/etc/fish/conf.d/conda.fish\nno change     /usr/local/shell/condabin/Conda.psm1\nno change     /usr/local/shell/condabin/conda-hook.ps1\nno change     /usr/local/lib/python3.13/site-packages/xontrib/conda.xsh\nno change     /usr/local/etc/profile.d/conda.csh\nmodified      /root/.bashrc\nmodified      /root/.zshrc\nmodified      /root/.config/fish/config.fish\nmodified      /root/.xonshrc\nmodified      /root/.tcshrc\n\n==> For changes to take effect, close and re-open your current shell. <==\n\n2 channel Terms of Service accepted\nRetrieving notices: ...working... done\nChannels:\n - defaults\nPlatform: linux-64\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\n## Package Plan ##\n\n  environment location: /usr/local/envs/my_tfx_env\n\n  added / updated specs:\n    - python=3.10\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2025.9.9   |       h06a4308_0         127 KB\n    ld_impl_linux-64-2.44      |       h153f514_2         672 KB\n    libzlib-1.3.1              |       hb25bd0a_0          59 KB\n    openssl-3.0.18             |       hd6dcaed_0         4.5 MB\n    pip-25.2                   |     pyhc872135_1         1.1 MB\n    python-3.10.18             |       h1a3bd86_0        26.5 MB\n    setuptools-80.9.0          |  py310h06a4308_0         1.4 MB\n    wheel-0.45.1               |  py310h06a4308_0         115 KB\n    zlib-1.3.1                 |       hb25bd0a_0          96 KB\n    ------------------------------------------------------------\n                                           Total:        34.6 MB\n\nThe following NEW packages will be INSTALLED:\n\n  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 \n  ca-certificates    pkgs/main/linux-64::ca-certificates-2025.9.9-h06a4308_0 \n  expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 \n  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.44-h153f514_2 \n  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n  libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 \n  libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 \n  libzlib            pkgs/main/linux-64::libzlib-1.3.1-hb25bd0a_0 \n  ncurses            pkgs/main/linux-64::ncurses-6.5-h7934f7d_0 \n  openssl            pkgs/main/linux-64::openssl-3.0.18-hd6dcaed_0 \n  pip                pkgs/main/noarch::pip-25.2-pyhc872135_1 \n  pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 \n  python             pkgs/main/linux-64::python-3.10.18-h1a3bd86_0 \n  readline           pkgs/main/linux-64::readline-8.3-hc2a1206_0 \n  setuptools         pkgs/main/linux-64::setuptools-80.9.0-py310h06a4308_0 \n  sqlite             pkgs/main/linux-64::sqlite-3.50.2-hb25bd0a_1 \n  tk                 pkgs/main/linux-64::tk-8.6.15-h54e0aa7_0 \n  tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 \n  wheel              pkgs/main/linux-64::wheel-0.45.1-py310h06a4308_0 \n  xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 \n  xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 \n  xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 \n  xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 \n  xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n  zlib               pkgs/main/linux-64::zlib-1.3.1-hb25bd0a_0 \n\n\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\nPython 3.10.18\n38.933570776 seconds\nWed Oct 15 11:37:10 PM UTC 2025\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"to activate the conda environment, need to source from conda's activate (which I installed in /usr/local/bin above), then activate the conda virtual environment.\n\nthis has to be done for each magic shell cell","metadata":{}},{"cell_type":"code","source":"%%bash\nt0=$(date +%s%N)\n. /usr/local/bin/activate\nconda activate my_tfx_env\npython --version\n\n#consider conda install ipykernel\nconda install pip\n\n#conda config --add channels conda-forge\n#conda config --set channel_priority strict\n#conda install python-snappy\n# or:\n#conda install anaconda::python-snappy\n\n#see dependencies https://github.com/tensorflow/transform\npip -q install pyarrow==10.0.1\npip -q install apache-beam==2.59.0\npip -q install tensorflow==2.16.1\npip -q install tensorflow-transform==1.16.0\npip -q install tfx==1.16.0\npip -q install tensorflow-data-validation==1.16.0\npip -q install pytest\n# installs:\n#tf metadata 1.16.1\n#tfx-bsl 1.16.1\n#arrow 1.3.0\n#keeps protobuf 3.20.3\n\n#The Spark runner currently supports Sparkâ€™s 3.2.x branch.\n#Apache Beam Prism Runner. \n\n\npip list\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 60000000000\" | bc)\necho \"$t2 minutes\"\ndate\n#about 6-7 minutes for this cell.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:37:10.187953Z","iopub.execute_input":"2025-10-15T23:37:10.188214Z","iopub.status.idle":"2025-10-15T23:43:55.795634Z","shell.execute_reply.started":"2025-10-15T23:37:10.188192Z","shell.execute_reply":"2025-10-15T23:43:55.794643Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\n2 channel Terms of Service accepted\nChannels:\n - defaults\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n# All requested packages already installed.\n\nPackage                            Version\n---------------------------------- --------------\nabsl-py                            1.4.0\nannotated-types                    0.7.0\nanyio                              4.11.0\napache-beam                        2.59.0\nargon2-cffi                        25.1.0\nargon2-cffi-bindings               25.1.0\narrow                              1.3.0\nastunparse                         1.6.3\nasync-lru                          2.0.5\nasync-timeout                      5.0.1\nattrs                              23.2.0\nbabel                              2.17.0\nbackcall                           0.2.0\nbeautifulsoup4                     4.14.2\nbleach                             6.2.0\ncachetools                         5.5.2\ncertifi                            2025.10.5\ncffi                               2.0.0\ncharset-normalizer                 3.4.4\nclick                              8.3.0\ncloudpickle                        2.2.1\ncolorama                           0.4.6\ncomm                               0.2.3\ncrcmod                             1.7\ndebugpy                            1.8.17\ndecorator                          5.2.1\ndefusedxml                         0.7.1\ndill                               0.3.1.1\ndnspython                          2.8.0\ndocker                             7.1.0\ndocopt                             0.6.2\ndocstring_parser                   0.17.0\nexceptiongroup                     1.3.0\nfastavro                           1.12.1\nfasteners                          0.20\nfastjsonschema                     2.21.2\nflatbuffers                        25.9.23\nfqdn                               1.5.1\ngast                               0.6.0\ngoogle-api-core                    2.26.0\ngoogle-api-python-client           1.12.11\ngoogle-apitools                    0.5.31\ngoogle-auth                        2.41.1\ngoogle-auth-httplib2               0.2.0\ngoogle-cloud-aiplatform            1.121.0\ngoogle-cloud-bigquery              3.38.0\ngoogle-cloud-bigquery-storage      2.33.1\ngoogle-cloud-bigtable              2.33.0\ngoogle-cloud-core                  2.4.3\ngoogle-cloud-datastore             2.21.0\ngoogle-cloud-dlp                   3.32.0\ngoogle-cloud-language              2.17.2\ngoogle-cloud-pubsub                2.31.1\ngoogle-cloud-pubsublite            1.12.0\ngoogle-cloud-recommendations-ai    0.10.18\ngoogle-cloud-resource-manager      1.14.2\ngoogle-cloud-spanner               3.58.0\ngoogle-cloud-storage               2.19.0\ngoogle-cloud-videointelligence     2.16.2\ngoogle-cloud-vision                3.10.2\ngoogle-crc32c                      1.7.1\ngoogle-genai                       1.45.0\ngoogle-pasta                       0.2.0\ngoogle-resumable-media             2.7.2\ngoogleapis-common-protos           1.70.0\ngrpc-google-iam-v1                 0.14.3\ngrpc-interceptor                   0.15.4\ngrpcio                             1.75.1\ngrpcio-status                      1.49.0rc1\nh11                                0.16.0\nh5py                               3.15.0\nhdfs                               2.7.3\nhttpcore                           1.0.9\nhttplib2                           0.22.0\nhttpx                              0.28.1\nidna                               3.11\nimportlib_metadata                 8.7.0\niniconfig                          2.1.0\nipykernel                          7.0.1\nipython                            7.34.0\nipython-genutils                   0.2.0\nipywidgets                         7.8.5\nisoduration                        20.11.0\njedi                               0.19.2\nJinja2                             3.1.6\njoblib                             1.5.2\nJs2Py                              0.74\njson5                              0.12.1\njsonpickle                         3.4.2\njsonpointer                        3.0.0\njsonschema                         4.25.1\njsonschema-specifications          2025.9.1\njupyter_client                     8.6.3\njupyter_core                       5.8.1\njupyter-events                     0.12.0\njupyter-lsp                        2.3.0\njupyter_server                     2.17.0\njupyter_server_terminals           0.5.3\njupyterlab                         4.4.9\njupyterlab_pygments                0.3.0\njupyterlab_server                  2.27.3\njupyterlab_widgets                 1.1.11\nkeras                              3.11.3\nkeras-tuner                        1.4.7\nkt-legacy                          1.0.5\nkubernetes                         26.1.0\nlark                               1.3.0\nlibclang                           18.1.1\nlxml                               6.0.2\nMarkdown                           3.9\nmarkdown-it-py                     4.0.0\nMarkupSafe                         3.0.3\nmatplotlib-inline                  0.1.7\nmdurl                              0.1.2\nmistune                            3.1.4\nml-dtypes                          0.3.2\nml-metadata                        1.16.0\nml-pipelines-sdk                   1.16.0\nnamex                              0.1.0\nnbclient                           0.10.2\nnbconvert                          7.16.6\nnbformat                           5.10.4\nnest-asyncio                       1.6.0\nnltk                               3.9.2\nnotebook                           7.4.7\nnotebook_shim                      0.2.4\nnumpy                              1.26.4\noauth2client                       4.1.3\noauthlib                           3.3.1\nobjsize                            0.7.1\nopentelemetry-api                  1.37.0\nopentelemetry-sdk                  1.37.0\nopentelemetry-semantic-conventions 0.58b0\nopt_einsum                         3.4.0\noptree                             0.17.0\norjson                             3.11.3\noverrides                          7.7.0\npackaging                          25.0\npandas                             1.5.3\npandocfilters                      1.5.1\nparso                              0.8.5\npexpect                            4.9.0\npickleshare                        0.7.5\npillow                             12.0.0\npip                                25.2\nplatformdirs                       4.5.0\npluggy                             1.6.0\nportalocker                        3.2.0\nportpicker                         1.6.0\nprometheus_client                  0.23.1\nprompt_toolkit                     3.0.52\nproto-plus                         1.26.1\nprotobuf                           3.20.3\npsutil                             7.1.0\nptyprocess                         0.7.0\npyarrow                            10.0.1\npyarrow-hotfix                     0.7\npyasn1                             0.6.1\npyasn1_modules                     0.4.2\npycparser                          2.23\npydantic                           2.12.2\npydantic_core                      2.41.4\npydot                              1.4.2\npyfarmhash                         0.3.2\nPygments                           2.19.2\npyjsparser                         2.7.1\nPyJWT                              2.10.1\npymongo                            4.15.3\npyparsing                          3.2.5\npytest                             8.4.2\npython-dateutil                    2.9.0.post0\npython-json-logger                 4.0.0\npytz                               2025.2\nPyYAML                             6.0.3\npyzmq                              27.1.0\nredis                              5.3.1\nreferencing                        0.37.0\nregex                              2025.9.18\nrequests                           2.32.5\nrequests-oauthlib                  2.0.0\nrfc3339-validator                  0.1.4\nrfc3986-validator                  0.1.1\nrfc3987-syntax                     1.1.0\nrich                               14.2.0\nrouge_score                        0.1.2\nrpds-py                            0.27.1\nrsa                                4.9.1\nsacrebleu                          2.5.1\nscikit-learn                       1.5.1\nscipy                              1.12.0\nSend2Trash                         1.8.3\nsetuptools                         80.9.0\nshapely                            2.1.2\nsix                                1.17.0\nsniffio                            1.3.1\nsoupsieve                          2.8\nsqlparse                           0.5.3\ntabulate                           0.9.0\ntenacity                           9.1.2\ntensorboard                        2.16.2\ntensorboard-data-server            0.7.2\ntensorflow                         2.16.1\ntensorflow-data-validation         1.16.0\ntensorflow-estimator               2.15.0\ntensorflow-hub                     0.15.0\ntensorflow-io-gcs-filesystem       0.37.1\ntensorflow-metadata                1.16.1\ntensorflow_model_analysis          0.47.1\ntensorflow-serving-api             2.16.1\ntensorflow-transform               1.16.0\ntermcolor                          3.1.0\nterminado                          0.18.1\ntf_keras                           2.16.0\ntfx                                1.16.0\ntfx-bsl                            1.16.1\nthreadpoolctl                      3.6.0\ntinycss2                           1.4.0\ntomli                              2.3.0\ntornado                            6.5.2\ntqdm                               4.67.1\ntraitlets                          5.14.3\ntypes-python-dateutil              2.9.0.20251008\ntyping_extensions                  4.15.0\ntyping-inspection                  0.4.2\ntzlocal                            5.3.1\nuri-template                       1.3.0\nuritemplate                        3.0.1\nurllib3                            2.5.0\nwcwidth                            0.2.14\nwebcolors                          24.11.1\nwebencodings                       0.5.1\nwebsocket-client                   1.9.0\nwebsockets                         15.0.1\nWerkzeug                           3.1.3\nwheel                              0.45.1\nwidgetsnbextension                 3.6.10\nwrapt                              1.17.3\nzipp                               3.23.0\nzstandard                          0.25.0\n6.759799738 minutes\nWed Oct 15 11:43:55 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"\n\n==> WARNING: A newer version of conda exists. <==\n    current version: 25.7.0\n    latest version: 25.9.1\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n  DEPRECATION: Building 'crcmod' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'crcmod'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'dill' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'dill'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'hdfs' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'hdfs'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'pyjsparser' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pyjsparser'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'docopt' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'docopt'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'google-apitools' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'google-apitools'. Discussion can be found at https://github.com/pypa/pip/issues/6334\nWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/ab/4e/b4968130b4f0543c66b86e0aaa0e0c61bea1c0877b63b375420595e65428/ml_pipelines_sdk-1.16.0-py3-none-any.whl\n  DEPRECATION: Building 'pyfarmhash' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pyfarmhash'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'rouge-score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge-score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntfx 1.16.0 requires tensorflow-data-validation<1.17.0,>=1.16.1, but you have tensorflow-data-validation 1.16.0 which is incompatible.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!java --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:43:55.797588Z","iopub.execute_input":"2025-10-15T23:43:55.797851Z","iopub.status.idle":"2025-10-15T23:43:56.229897Z","shell.execute_reply.started":"2025-10-15T23:43:55.797828Z","shell.execute_reply":"2025-10-15T23:43:56.228714Z"}},"outputs":[{"name":"stdout","text":"openjdk 11.0.27 2025-04-15\nOpenJDK Runtime Environment (build 11.0.27+6-post-Ubuntu-0ubuntu122.04)\nOpenJDK 64-Bit Server VM (build 11.0.27+6-post-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"%%bash\n. /usr/local/bin/activate\nconda activate my_tfx_env\npython --version\npip show apache-beam\n\n#refresh the test dirs\nrm -rf /kaggle/working/bin/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:43:56.230825Z","iopub.execute_input":"2025-10-15T23:43:56.231138Z","iopub.status.idle":"2025-10-15T23:43:58.801848Z","shell.execute_reply.started":"2025-10-15T23:43:56.231081Z","shell.execute_reply":"2025-10-15T23:43:58.801162Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nName: apache-beam\nVersion: 2.59.0\nSummary: Apache Beam SDK for Python\nHome-page: https://beam.apache.org\nAuthor: Apache Software Foundation\nAuthor-email: dev@beam.apache.org\nLicense: Apache License, Version 2.0\nLocation: /usr/local/envs/my_tfx_env/lib/python3.10/site-packages\nRequires: cloudpickle, crcmod, dill, fastavro, fasteners, grpcio, hdfs, httplib2, js2py, jsonpickle, jsonschema, numpy, objsize, orjson, packaging, proto-plus, protobuf, pyarrow, pyarrow-hotfix, pydot, pymongo, python-dateutil, pytz, redis, regex, requests, typing-extensions, zstandard\nRequired-by: tensorflow-data-validation, tensorflow-transform, tensorflow_model_analysis, tfx, tfx-bsl\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"The run_command is from\nhttps://www.kaggle.com/code/taylorsamarel/change-python-version-kaggle-v2-taylor-amarel","metadata":{}},{"cell_type":"code","source":"import subprocess\ndef run_command(cmd, capture=True, check=False):\n    cmds = f\". /usr/local/bin/activate; conda activate my_tfx_env; {cmd}\"\n    try:\n        result = subprocess.run(cmds, shell=True, capture_output=capture, text=True, check=check)\n        if capture:\n            return result.stdout.strip() if result.stdout else result.stderr.strip()\n        return result.returncode == 0\n    except Exception as e:\n        return str(e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:43:58.802730Z","iopub.execute_input":"2025-10-15T23:43:58.802999Z","iopub.status.idle":"2025-10-15T23:43:58.809227Z","shell.execute_reply.started":"2025-10-15T23:43:58.802977Z","shell.execute_reply":"2025-10-15T23:43:58.808367Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(run_command(\"python --version\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:43:58.810041Z","iopub.execute_input":"2025-10-15T23:43:58.810296Z","iopub.status.idle":"2025-10-15T23:44:00.406238Z","shell.execute_reply.started":"2025-10-15T23:43:58.810267Z","shell.execute_reply":"2025-10-15T23:44:00.405234Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### 1.a. Download a TFX test script and test that the library versions are compatible","metadata":{}},{"cell_type":"code","source":"%%bash\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\n#it can take a couple of minutes to get current version of recently uploaded file to github\n#wget -q -c --no-cache https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/main/src/test/python/test_tft.py -O /kaggle/working/test_tft.py\n#curl --header \"Cache-Control: no-cache\" \"https://api.github.com/repos/nking/recommender_systems/content/src/test/python/test_tft.py\" -o /kaggle/working/test_tft.py\n\nrm -f /kaggle/working/dataset_tfxio_example.py\nwget -q -c --no-cache https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/main/src/test/python/dataset_tfxio_example.py -O /kaggle/working/dataset_tfxio_example.py\n\nls -l /kaggle/working\n\n#run a test example from Google's TFX codebase:\npython3 /kaggle/working/dataset_tfxio_example.py\n\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:44:00.407196Z","iopub.execute_input":"2025-10-15T23:44:00.407502Z","iopub.status.idle":"2025-10-15T23:44:11.606059Z","shell.execute_reply.started":"2025-10-15T23:44:00.407478Z","shell.execute_reply":"2025-10-15T23:44:11.605357Z"}},"outputs":[{"name":"stdout","text":"total 4\n-rw-r--r-- 1 root root 2392 Oct 15 23:44 dataset_tfxio_example.py\n{'x_centered': [[-4.0], [-3.0], [-2.0], [-1.0], [0.0]],\n 'x_scaled': [[0.0], [0.125], [0.25], [0.375], [0.5]]}\n{'x_centered': [[1.0], [2.0], [3.0], [4.0]],\n 'x_scaled': [[0.625], [0.75], [0.875], [1.0]]}\nWed Oct 15 11:44:11 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"I1015 23:44:07.491234 140284750362432 pipeline.py:197] Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\nI1015 23:44:09.148903 140284750362432 statecache.py:214] Creating state cache with size 104857600\nI1015 23:44:09.330093 140284750362432 functional_saver.py:438] Sharding callback duration: 7\nI1015 23:44:09.360643 140284750362432 functional_saver.py:438] Sharding callback duration: 7\nINFO:tensorflow:Assets written to: /tmp/tmpkgcnv68u/tftransform_tmp/13109f22d1ac463e810e5439f733ffe0/assets\nI1015 23:44:09.378553 140284750362432 builder_impl.py:829] Assets written to: /tmp/tmpkgcnv68u/tftransform_tmp/13109f22d1ac463e810e5439f733ffe0/assets\nI1015 23:44:09.380521 140284750362432 fingerprinting_utils.py:49] Writing fingerprint to /tmp/tmpkgcnv68u/tftransform_tmp/13109f22d1ac463e810e5439f733ffe0/fingerprint.pb\nINFO:tensorflow:struct2tensor is not available.\nI1015 23:44:09.687191 140284750362432 saved_transform_io.py:166] struct2tensor is not available.\nINFO:tensorflow:tensorflow_decision_forests is not available.\nI1015 23:44:09.687522 140284750362432 saved_transform_io.py:166] tensorflow_decision_forests is not available.\nINFO:tensorflow:tensorflow_text is not available.\nI1015 23:44:09.687716 140284750362432 saved_transform_io.py:166] tensorflow_text is not available.\nI1015 23:44:10.114267 140284750362432 functional_saver.py:438] Sharding callback duration: 6\nI1015 23:44:10.141787 140284750362432 functional_saver.py:438] Sharding callback duration: 7\nINFO:tensorflow:Assets written to: /tmp/tmpkgcnv68u/tftransform_tmp/cfc995074e5745baac91e4a32b95e066/assets\nI1015 23:44:10.153275 140284750362432 builder_impl.py:829] Assets written to: /tmp/tmpkgcnv68u/tftransform_tmp/cfc995074e5745baac91e4a32b95e066/assets\nI1015 23:44:10.155102 140284750362432 fingerprinting_utils.py:49] Writing fingerprint to /tmp/tmpkgcnv68u/tftransform_tmp/cfc995074e5745baac91e4a32b95e066/fingerprint.pb\nI1015 23:44:10.208414 140284750362432 tensor_representation_util.py:450] Feature x_centered has a shape . Setting to DenseTensor.\nI1015 23:44:10.208608 140284750362432 tensor_representation_util.py:450] Feature x_scaled has a shape . Setting to DenseTensor.\nINFO:tensorflow:struct2tensor is not available.\nI1015 23:44:10.331772 140284750362432 saved_transform_io.py:166] struct2tensor is not available.\nINFO:tensorflow:tensorflow_decision_forests is not available.\nI1015 23:44:10.332149 140284750362432 saved_transform_io.py:166] tensorflow_decision_forests is not available.\nINFO:tensorflow:tensorflow_text is not available.\nI1015 23:44:10.332359 140284750362432 saved_transform_io.py:166] tensorflow_text is not available.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## 2.a. Download a MovieLens dataset","metadata":{}},{"cell_type":"code","source":"%%bash\nwget -q http://files.grouplens.org/datasets/movielens/ml-1m.zip -O /kaggle/working/ml-1m.zip\nunzip -o /kaggle/working/ml-1m.zip\nls /kaggle/working/ml-1m/\nrm /kaggle/working/ml-1m.zip\n\nhead -n 5 /kaggle/working/ml-1m/ratings.dat\nhead -n 5 /kaggle/working/ml-1m/users.dat\nhead -n 5 /kaggle/working/ml-1m/movies.dat\n\n#making small subsets for tests\nhead -n 1000 /kaggle/working/ml-1m/ratings.dat > /kaggle/working/ml-1m/ratings_1000.dat\nhead -n 100 /kaggle/working/ml-1m/users.dat > /kaggle/working/ml-1m/users_100.dat\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:44:11.606795Z","iopub.execute_input":"2025-10-15T23:44:11.607041Z","iopub.status.idle":"2025-10-15T23:44:12.541305Z","shell.execute_reply.started":"2025-10-15T23:44:11.607021Z","shell.execute_reply":"2025-10-15T23:44:12.540458Z"}},"outputs":[{"name":"stdout","text":"Archive:  /kaggle/working/ml-1m.zip\n   creating: ml-1m/\n  inflating: ml-1m/movies.dat        \n  inflating: ml-1m/ratings.dat       \n  inflating: ml-1m/README            \n  inflating: ml-1m/users.dat         \nmovies.dat\nratings.dat\nREADME\nusers.dat\n1::1193::5::978300760\n1::661::3::978302109\n1::914::3::978301968\n1::3408::4::978300275\n1::2355::5::978824291\n1::F::1::10::48067\n2::M::56::16::70072\n3::M::25::15::55117\n4::M::45::7::02460\n5::M::25::20::55455\n1::Toy Story (1995)::Animation|Children's|Comedy\n2::Jumanji (1995)::Adventure|Children's|Fantasy\n3::Grumpier Old Men (1995)::Comedy|Romance\n4::Waiting to Exhale (1995)::Comedy|Drama\n5::Father of the Bride Part II (1995)::Comedy\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## 2.b. Write the TFX components, Beam PTransforms and unit tests\nand upload them to a reachable repository.  \nIf the repository is private, you can use Kaggle secrets to hold API keys, etc for use in download below.","metadata":{}},{"cell_type":"markdown","source":"## 3. Download the components and transforms","metadata":{}},{"cell_type":"markdown","source":"### 3.a. Ingestion\n\nThe first component is the ingestion and it's written using custom apache beam PTransforms and custom TFX components.\n\nCustomization was needed to ingest the 3 files (\"ratings.dat\", \"movies.dat\", \"users.dat\"), left join them on ratings, and then split them.\nThe components are called IngestMovieLensComponent and ingest_movie_lens_component for the fully customized  and the python function customized versions, respectively.\n\nI implemented the fully custom version and the python function component, but only one of them is needed.","metadata":{}},{"cell_type":"code","source":"%%bash\n#it can take a couple of minutes to get current version of recently uploaded file to github\n#wget -q -c --no-cache https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/main/src/test/python/test_tft.py -O /kaggle/working/test_tft.py\n#curl --header \"Cache-Control: no-cache\" \"https://api.github.com/repos/nking/recommender_systems/content/src/test/python/test_tft.py\" -o /kaggle/working/test_tft.py\n\nrepo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/main/python'\ndeclare -a my_files=(\"ingest_movie_lens_beam.py\" \"ingest_movie_lens_beam_pa.py\"\n  \"CustomUTF8Coder.py\" \"ingest_movie_lens_component.py\" \n  \"movie_lens_utils.py\" \"ingest_movie_lens_custom_component.py\"\n)\nfor item in \"${my_files[@]}\"\ndo\n  rm -f \"/kaggle/working/$item\"\n  echo \"$item\"\n  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\ndone\n\nrepo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/drafts/python'\ndeclare -a my_files=(\"transform_movie_lens.py\")\nfor item in \"${my_files[@]}\"\ndo\n  rm -f \"/kaggle/working/$item\"\n  echo \"$item\"\n  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\ndone\n\nrepo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/test/python'\ndeclare -a my_files=(\"ingest_movie_lens_beam_test.py\" \"ingest_movie_lens_beam_pa_test.py\"\n  \"ingest_movie_lens_component_test.py\" \"ingest_movie_lens_custom_component_test.py\" \n  \"movie_lens_utils_test.py\" \"csv_example_gen_test.py\" \n  \"helper.py\" \"transform_movie_lens_test.py\"\n)\nfor item in \"${my_files[@]}\"\ndo\n  rm -f \"/kaggle/working/$item\"\n  echo \"$item\"\n  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\ndone\n\nls -l /kaggle/working/\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:44:12.544045Z","iopub.execute_input":"2025-10-15T23:44:12.544297Z","iopub.status.idle":"2025-10-15T23:44:14.506860Z","shell.execute_reply.started":"2025-10-15T23:44:12.544277Z","shell.execute_reply":"2025-10-15T23:44:14.506167Z"}},"outputs":[{"name":"stdout","text":"ingest_movie_lens_beam.py\ningest_movie_lens_beam_pa.py\nCustomUTF8Coder.py\ningest_movie_lens_component.py\nmovie_lens_utils.py\ningest_movie_lens_custom_component.py\ntransform_movie_lens.py\ningest_movie_lens_beam_test.py\ningest_movie_lens_beam_pa_test.py\ningest_movie_lens_component_test.py\ningest_movie_lens_custom_component_test.py\nmovie_lens_utils_test.py\ncsv_example_gen_test.py\nhelper.py\ntransform_movie_lens_test.py\ntotal 152\n-rw-r--r-- 1 root root  7334 Oct 15 23:44 csv_example_gen_test.py\n-rw-r--r-- 1 root root   777 Oct 15 23:44 CustomUTF8Coder.py\n-rw-r--r-- 1 root root  2392 Oct 15 23:44 dataset_tfxio_example.py\n-rw-r--r-- 1 root root  3633 Oct 15 23:44 helper.py\n-rw-r--r-- 1 root root  9994 Oct 15 23:44 ingest_movie_lens_beam_pa.py\n-rw-r--r-- 1 root root  4543 Oct 15 23:44 ingest_movie_lens_beam_pa_test.py\n-rw-r--r-- 1 root root  7904 Oct 15 23:44 ingest_movie_lens_beam.py\n-rw-r--r-- 1 root root  5072 Oct 15 23:44 ingest_movie_lens_beam_test.py\n-rw-r--r-- 1 root root  6217 Oct 15 23:44 ingest_movie_lens_component.py\n-rw-r--r-- 1 root root 11212 Oct 15 23:44 ingest_movie_lens_component_test.py\n-rw-r--r-- 1 root root 13179 Oct 15 23:44 ingest_movie_lens_custom_component.py\n-rw-r--r-- 1 root root 12585 Oct 15 23:44 ingest_movie_lens_custom_component_test.py\ndrwxr-x--- 2 root root  4096 Oct 15 23:44 ml-1m\n-rw-r--r-- 1 root root 13778 Oct 15 23:44 movie_lens_utils.py\n-rw-r--r-- 1 root root  4376 Oct 15 23:44 movie_lens_utils_test.py\n-rw-r--r-- 1 root root  5076 Oct 15 23:44 transform_movie_lens.py\n-rw-r--r-- 1 root root  7714 Oct 15 23:44 transform_movie_lens_test.py\nWed Oct 15 11:44:14 PM UTC 2025\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"%%bash\n#it can take a couple of minutes to get current version of recently uploaded file to github\n#wget -q -c --no-cache https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/main/src/test/python/test_tft.py -O /kaggle/working/test_tft.py\n#curl --header \"Cache-Control: no-cache\" \"https://api.github.com/repos/nking/recommender_systems/content/src/test/python/test_tft.py\" -o /kaggle/working/test_tft.py\n\nrepo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/main/python'\ndeclare -a my_files=(\"ingest_movie_lens_beam.py\" \"ingest_movie_lens_beam_pa.py\"\n  \"CustomUTF8Coder.py\" \"ingest_movie_lens_component.py\" \n  \"movie_lens_utils.py\" \"ingest_movie_lens_custom_component.py\"\n)\nfor item in \"${my_files[@]}\"\ndo\n  rm -f \"/kaggle/working/$item\"\n  echo \"$item\"\n  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\ndone\n\nrepo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/drafts/python'\ndeclare -a my_files=(\"transform_movie_lens.py\")\nfor item in \"${my_files[@]}\"\ndo\n  rm -f \"/kaggle/working/$item\"\n  echo \"$item\"\n  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\ndone\n\nrepo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/test/python'\ndeclare -a my_files=(\"ingest_movie_lens_beam_test.py\" \"ingest_movie_lens_beam_pa_test.py\"\n  \"ingest_movie_lens_component_test.py\" \"ingest_movie_lens_custom_component_test.py\" \n  \"movie_lens_utils_test.py\" \"csv_example_gen_test.py\" \n  \"helper.py\" \"transform_movie_lens_test.py\"\n)\nfor item in \"${my_files[@]}\"\ndo\n  rm -f \"/kaggle/working/$item\"\n  echo \"$item\"\n  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\ndone\n\nls -l /kaggle/working/\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T00:33:18.473577Z","iopub.execute_input":"2025-10-16T00:33:18.474010Z","iopub.status.idle":"2025-10-16T00:33:20.689525Z","shell.execute_reply.started":"2025-10-16T00:33:18.473982Z","shell.execute_reply":"2025-10-16T00:33:20.688698Z"}},"outputs":[{"name":"stdout","text":"ingest_movie_lens_beam.py\ningest_movie_lens_beam_pa.py\nCustomUTF8Coder.py\ningest_movie_lens_component.py\nmovie_lens_utils.py\ningest_movie_lens_custom_component.py\ntransform_movie_lens.py\ningest_movie_lens_beam_test.py\ningest_movie_lens_beam_pa_test.py\ningest_movie_lens_component_test.py\ningest_movie_lens_custom_component_test.py\nmovie_lens_utils_test.py\ncsv_example_gen_test.py\nhelper.py\ntransform_movie_lens_test.py\ntotal 160\ndrwxr-xr-x 7 root root  4096 Oct 15 23:46 bin\n-rw-r--r-- 1 root root  7334 Oct 16 00:33 csv_example_gen_test.py\n-rw-r--r-- 1 root root   777 Oct 16 00:33 CustomUTF8Coder.py\n-rw-r--r-- 1 root root  2392 Oct 15 23:44 dataset_tfxio_example.py\n-rw-r--r-- 1 root root  3633 Oct 16 00:33 helper.py\n-rw-r--r-- 1 root root  9994 Oct 16 00:33 ingest_movie_lens_beam_pa.py\n-rw-r--r-- 1 root root  4543 Oct 16 00:33 ingest_movie_lens_beam_pa_test.py\n-rw-r--r-- 1 root root  7904 Oct 16 00:33 ingest_movie_lens_beam.py\n-rw-r--r-- 1 root root  5072 Oct 16 00:33 ingest_movie_lens_beam_test.py\n-rw-r--r-- 1 root root  6217 Oct 16 00:33 ingest_movie_lens_component.py\n-rw-r--r-- 1 root root 11212 Oct 16 00:33 ingest_movie_lens_component_test.py\n-rw-r--r-- 1 root root 13179 Oct 16 00:33 ingest_movie_lens_custom_component.py\n-rw-r--r-- 1 root root 12585 Oct 16 00:33 ingest_movie_lens_custom_component_test.py\ndrwxr-x--- 3 root root  4096 Oct 15 23:44 ml-1m\n-rw-r--r-- 1 root root 13778 Oct 16 00:33 movie_lens_utils.py\n-rw-r--r-- 1 root root  4376 Oct 16 00:33 movie_lens_utils_test.py\ndrwxr-xr-x 2 root root  4096 Oct 16 00:13 __pycache__\n-rw-r--r-- 1 root root  4271 Oct 16 00:33 transform_movie_lens.py\n-rw-r--r-- 1 root root  7714 Oct 16 00:33 transform_movie_lens_test.py\nThu Oct 16 12:33:20 AM UTC 2025\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"### Run the unit tests","metadata":{}},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for CSVExampleGen\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/csv_example_gen_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:44:16.082742Z","iopub.execute_input":"2025-10-15T23:44:16.083095Z","iopub.status.idle":"2025-10-15T23:44:30.790089Z","shell.execute_reply.started":"2025-10-15T23:44:16.083058Z","shell.execute_reply":"2025-10-15T23:44:30.789369Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for CSVExampleGen\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\nkey=examples, value=OutputChannel(artifact_type=Examples, producer_component_id=CsvExampleGen, output_key=examples, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False)\nlisting files in output_data_dir /kaggle/working/bin/csv_comp_1/testRun:\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n13.066261994 seconds\nWed Oct 15 11:44:30 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"INFO:absl:tensorflow_io is not available: No module named 'tensorflow_io'\nINFO:absl:tensorflow_ranking is not available: No module named 'tensorflow_ranking'\nINFO:absl:tensorflow_text is not available: No module named 'tensorflow_text'\nINFO:absl:tensorflow_decision_forests is not available: No module named 'tensorflow_decision_forests'\nINFO:absl:struct2tensor is not available: No module named 'struct2tensor'\nINFO:absl:tensorflow_text is not available.\nINFO:absl:tensorflow_recommenders is not available.\nINFO:absl:Running driver for CsvExampleGen\nINFO:absl:MetadataStore with DB connection initialized\nINFO:absl:select span and version = (0, None)\nINFO:absl:latest span and version = (0, None)\nINFO:absl:Running executor for CsvExampleGen\nINFO:absl:Generating examples.\nINFO:absl:Processing input csv data /kaggle/working/ml-1m/tmp/* to TFExample.\nWARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\nINFO:absl:Examples generated.\nINFO:absl:Running publisher for CsvExampleGen\nINFO:absl:MetadataStore with DB connection initialized\nINFO:absl:MetadataStore with DB connection initialized\n.s\n----------------------------------------------------------------------\nRan 2 tests in 2.816s\n\nOK (skipped=1)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"%%bash\nhead -n 5 /kaggle/working/ml-1m/ratings.dat\nhead -n 5 /kaggle/working/ml-1m/users.dat\nhead -n 5 /kaggle/working/ml-1m/movies.dat","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:44:30.790804Z","iopub.execute_input":"2025-10-15T23:44:30.791181Z","iopub.status.idle":"2025-10-15T23:44:30.805294Z","shell.execute_reply.started":"2025-10-15T23:44:30.791158Z","shell.execute_reply":"2025-10-15T23:44:30.804407Z"}},"outputs":[{"name":"stdout","text":"1::1193::5::978300760\n1::661::3::978302109\n1::914::3::978301968\n1::3408::4::978300275\n1::2355::5::978824291\n1::F::1::10::48067\n2::M::56::16::70072\n3::M::25::15::55117\n4::M::45::7::02460\n5::M::25::20::55455\n1::Toy Story (1995)::Animation|Children's|Comedy\n2::Jumanji (1995)::Adventure|Children's|Fantasy\n3::Grumpier Old Men (1995)::Comedy|Romance\n4::Waiting to Exhale (1995)::Comedy|Drama\n5::Father of the Bride Part II (1995)::Comedy\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"!find /kaggle/working -type f\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:44:30.806232Z","iopub.execute_input":"2025-10-15T23:44:30.806823Z","iopub.status.idle":"2025-10-15T23:44:30.948175Z","shell.execute_reply.started":"2025-10-15T23:44:30.806792Z","shell.execute_reply":"2025-10-15T23:44:30.946669Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/transform_movie_lens_test.py\n/kaggle/working/ml-1m/ratings_1000.dat\n/kaggle/working/ml-1m/README\n/kaggle/working/ml-1m/users.dat\n/kaggle/working/ml-1m/movies.dat\n/kaggle/working/ml-1m/tmp/users2.dat\n/kaggle/working/ml-1m/ratings.dat\n/kaggle/working/ml-1m/users_100.dat\n/kaggle/working/csv_example_gen_test.py\n/kaggle/working/helper.py\n/kaggle/working/dataset_tfxio_example.py\n/kaggle/working/ingest_movie_lens_beam_pa.py\n/kaggle/working/CustomUTF8Coder.py\n/kaggle/working/ingest_movie_lens_beam_pa_test.py\n/kaggle/working/ingest_movie_lens_component_test.py\n/kaggle/working/movie_lens_utils_test.py\n/kaggle/working/ingest_movie_lens_component.py\n/kaggle/working/movie_lens_utils.py\n/kaggle/working/ingest_movie_lens_beam_test.py\n/kaggle/working/ingest_movie_lens_custom_component.py\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/ingest_movie_lens_custom_component_test.py\n/kaggle/working/__pycache__/CustomUTF8Coder.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_beam.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_custom_component.cpython-310.pyc\n/kaggle/working/__pycache__/csv_example_gen_test.cpython-310.pyc\n/kaggle/working/transform_movie_lens.py\n/kaggle/working/ingest_movie_lens_beam.py\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for utils methods\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/movie_lens_utils_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:44:30.949462Z","iopub.execute_input":"2025-10-15T23:44:30.949740Z","iopub.status.idle":"2025-10-15T23:44:37.079981Z","shell.execute_reply.started":"2025-10-15T23:44:30.949712Z","shell.execute_reply":"2025-10-15T23:44:37.079254Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for utils methods\n4.632561172 seconds\nWed Oct 15 11:44:37 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"...\n----------------------------------------------------------------------\nRan 3 tests in 0.000s\n\nOK\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for beam transforms\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/ingest_movie_lens_beam_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:44:37.080832Z","iopub.execute_input":"2025-10-15T23:44:37.081125Z","iopub.status.idle":"2025-10-15T23:45:52.975666Z","shell.execute_reply.started":"2025-10-15T23:44:37.081104Z","shell.execute_reply":"2025-10-15T23:45:52.974850Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for beam transforms\n74.409821475 seconds\nWed Oct 15 11:45:52 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['/kaggle/working/ingest_movie_lens_beam_test.py']\nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760571887   nanos: 684462070 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760571887   nanos: 692865133 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760571887   nanos: 701386928 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760571887   nanos: 709638357 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760571887   nanos: 740774869 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760571887   nanos: 738510608 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760571887   nanos: 754511356 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760571887   nanos: 755640983 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n.s\n----------------------------------------------------------------------\nRan 2 tests in 68.567s\n\nOK (skipped=1)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for tfx python function custom component\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/ingest_movie_lens_component_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:45:52.976623Z","iopub.execute_input":"2025-10-15T23:45:52.976855Z","iopub.status.idle":"2025-10-15T23:46:14.213810Z","shell.execute_reply.started":"2025-10-15T23:45:52.976834Z","shell.execute_reply":"2025-10-15T23:46:14.212885Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for tfx python function custom component\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\n19.729816471 seconds\nWed Oct 15 11:46:14 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"INFO:absl:Excluding no splits because exclude_splits is not set.\nINFO:absl:Excluding no splits because exclude_splits is not set.\nINFO:absl:Using deployment config:\n executor_specs {\n  key: \"MovieLensExampleGen\"\n  value {\n    beam_executable_spec {\n      python_executor_spec {\n        class_path: \"ingest_movie_lens_component.MovieLensExampleGen_Executor\"\n      }\n    }\n  }\n}\nexecutor_specs {\n  key: \"SchemaGen\"\n  value {\n    python_class_executable_spec {\n      class_path: \"tfx.components.schema_gen.executor.Executor\"\n    }\n  }\n}\nexecutor_specs {\n  key: \"StatisticsGen\"\n  value {\n    beam_executable_spec {\n      python_executor_spec {\n        class_path: \"tfx.components.statistics_gen.executor.Executor\"\n      }\n    }\n  }\n}\nmetadata_connection_config {\n  database_connection_config {\n    sqlite {\n      filename_uri: \"/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\"\n      connection_mode: READWRITE_OPENCREATE\n    }\n  }\n}\n\nINFO:absl:Using connection config:\n sqlite {\n  filename_uri: \"/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component MovieLensExampleGen is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"ingest_movie_lens_component.MovieLensExampleGen\"\n  }\n  id: \"MovieLensExampleGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonFuncCustomCompPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-15T23:46:03.584027\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonFuncCustomCompPipeline.MovieLensExampleGen\"\n      }\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"output_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"infiles_dict_ser\"\n    value {\n      field_value {\n        string_value: \"gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n      }\n    }\n  }\n  parameters {\n    key: \"output_config_ser\"\n    value {\n      field_value {\n        string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n      }\n    }\n  }\n}\ndownstream_nodes: \"StatisticsGen\"\nexecution_options {\n  caching_options {\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nINFO:absl:[MovieLensExampleGen] Resolved inputs: ({},)\nINFO:absl:MetadataStore with DB connection initialized\nINFO:absl:Going to run a new execution 1\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1760571963.776451    1149 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=1, input_dict={}, output_dict=defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}), exec_properties={'output_config_ser': 'Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK', 'infiles_dict_ser': 'gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg=='}, execution_output_uri='/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/.system/executor_execution/1/executor_output.pb', stateful_working_dir='/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/.system/stateful_working_dir/4184e27b-308a-4570-9991-8493d180d966', tmp_dir='/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/.system/executor_execution/1/.temp/', pipeline_node=node_info {\n  type {\n    name: \"ingest_movie_lens_component.MovieLensExampleGen\"\n  }\n  id: \"MovieLensExampleGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonFuncCustomCompPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-15T23:46:03.584027\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonFuncCustomCompPipeline.MovieLensExampleGen\"\n      }\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"output_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"infiles_dict_ser\"\n    value {\n      field_value {\n        string_value: \"gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n      }\n    }\n  }\n  parameters {\n    key: \"output_config_ser\"\n    value {\n      field_value {\n        string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n      }\n    }\n  }\n}\ndownstream_nodes: \"StatisticsGen\"\nexecution_options {\n  caching_options {\n  }\n}\n, pipeline_info=id: \"TestPythonFuncCustomCompPipeline\"\n, pipeline_run_id='2025-10-15T23:46:03.584027', top_level_pipeline_run_id=None, frontend_url=None)\nINFO:absl:MovieLensExampleGen\nINFO:absl:output_examples written as TFRecords\nWARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\nINFO:absl:Cleaning up stateless execution info.\nINFO:absl:Execution 1 succeeded.\nINFO:absl:Cleaning up stateful execution info.\nINFO:absl:Deleted stateful_working_dir /kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/.system/stateful_working_dir/4184e27b-308a-4570-9991-8493d180d966\nINFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}) for execution 1\nINFO:absl:MetadataStore with DB connection initialized\nINFO:absl:Component MovieLensExampleGen is finished.\nINFO:absl:Component StatisticsGen is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n    base_type: PROCESS\n  }\n  id: \"StatisticsGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonFuncCustomCompPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-15T23:46:03.584027\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonFuncCustomCompPipeline.StatisticsGen\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"examples\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"MovieLensExampleGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonFuncCustomCompPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-15T23:46:03.584027\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonFuncCustomCompPipeline.MovieLensExampleGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"Examples\"\n            base_type: DATASET\n          }\n        }\n        output_key: \"output_examples\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"statistics\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleStatistics\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          base_type: STATISTICS\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"exclude_splits\"\n    value {\n      field_value {\n        string_value: \"[]\"\n      }\n    }\n  }\n}\nupstream_nodes: \"MovieLensExampleGen\"\ndownstream_nodes: \"SchemaGen\"\nexecution_options {\n  caching_options {\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nWARNING:absl:ArtifactQuery.property_predicate is not supported.\nINFO:absl:[StatisticsGen] Resolved inputs: ({'examples': [Artifact(artifact: id: 1\ntype_id: 15\nuri: \"/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    int_value: 1\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Examples\"\ncreate_time_since_epoch: 1760571966106\nlast_update_time_since_epoch: 1760571966106\n, artifact_type: id: 15\nname: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]},)\nINFO:absl:MetadataStore with DB connection initialized\nINFO:absl:Going to run a new execution 2\nI0000 00:00:1760571966.196896    1149 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=2, input_dict={'examples': [Artifact(artifact: id: 1\ntype_id: 15\nuri: \"/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    int_value: 1\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Examples\"\ncreate_time_since_epoch: 1760571966106\nlast_update_time_since_epoch: 1760571966106\n, artifact_type: id: 15\nname: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2\"\n, artifact_type: name: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/.system/executor_execution/2/executor_output.pb', stateful_working_dir='/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/.system/stateful_working_dir/8ee5cf65-9430-4347-a995-94c3492fb72c', tmp_dir='/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/.system/executor_execution/2/.temp/', pipeline_node=node_info {\n  type {\n    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n    base_type: PROCESS\n  }\n  id: \"StatisticsGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonFuncCustomCompPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-15T23:46:03.584027\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonFuncCustomCompPipeline.StatisticsGen\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"examples\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"MovieLensExampleGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonFuncCustomCompPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-15T23:46:03.584027\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonFuncCustomCompPipeline.MovieLensExampleGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"Examples\"\n            base_type: DATASET\n          }\n        }\n        output_key: \"output_examples\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"statistics\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleStatistics\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          base_type: STATISTICS\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"exclude_splits\"\n    value {\n      field_value {\n        string_value: \"[]\"\n      }\n    }\n  }\n}\nupstream_nodes: \"MovieLensExampleGen\"\ndownstream_nodes: \"SchemaGen\"\nexecution_options {\n  caching_options {\n  }\n}\n, pipeline_info=id: \"TestPythonFuncCustomCompPipeline\"\n, pipeline_run_id='2025-10-15T23:46:03.584027', top_level_pipeline_run_id=None, frontend_url=None)\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nINFO:absl:Generating statistics for split train.\nINFO:absl:Statistics for split train written to /kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-train.\nINFO:absl:Generating statistics for split eval.\nINFO:absl:Statistics for split eval written to /kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-eval.\nINFO:absl:Generating statistics for split test.\nINFO:absl:Statistics for split test written to /kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-test.\nINFO:absl:Cleaning up stateless execution info.\nINFO:absl:Execution 2 succeeded.\nINFO:absl:Cleaning up stateful execution info.\nINFO:absl:Deleted stateful_working_dir /kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/.system/stateful_working_dir/8ee5cf65-9430-4347-a995-94c3492fb72c\nINFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2\"\n, artifact_type: name: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)]}) for execution 2\nINFO:absl:MetadataStore with DB connection initialized\nINFO:absl:Component StatisticsGen is finished.\nINFO:absl:Component SchemaGen is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"tfx.components.schema_gen.component.SchemaGen\"\n    base_type: PROCESS\n  }\n  id: \"SchemaGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonFuncCustomCompPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-15T23:46:03.584027\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonFuncCustomCompPipeline.SchemaGen\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"statistics\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"StatisticsGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonFuncCustomCompPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-15T23:46:03.584027\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonFuncCustomCompPipeline.StatisticsGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"ExampleStatistics\"\n            base_type: STATISTICS\n          }\n        }\n        output_key: \"statistics\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"schema\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Schema\"\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"exclude_splits\"\n    value {\n      field_value {\n        string_value: \"[]\"\n      }\n    }\n  }\n  parameters {\n    key: \"infer_feature_shape\"\n    value {\n      field_value {\n        int_value: 1\n      }\n    }\n  }\n}\nupstream_nodes: \"StatisticsGen\"\nexecution_options {\n  caching_options {\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nWARNING:absl:ArtifactQuery.property_predicate is not supported.\nINFO:absl:[SchemaGen] Resolved inputs: ({'statistics': [Artifact(artifact: id: 2\ntype_id: 17\nuri: \"/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"sample_rate_by_split\"\n  value {\n    struct_value {\n      fields {\n        key: \"__value__\"\n        value {\n          string_value: \"{\\\"eval\\\": 1.0, \\\"test\\\": 1.0, \\\"train\\\": 1.0}\"\n        }\n      }\n    }\n  }\n}\ncustom_properties {\n  key: \"stats_dashboard_link\"\n  value {\n    string_value: \"\"\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"ExampleStatistics\"\ncreate_time_since_epoch: 1760571971792\nlast_update_time_since_epoch: 1760571971792\n, artifact_type: id: 17\nname: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)]},)\nINFO:absl:MetadataStore with DB connection initialized\nINFO:absl:Going to run a new execution 3\nI0000 00:00:1760571971.870746    1149 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=3, input_dict={'statistics': [Artifact(artifact: id: 2\ntype_id: 17\nuri: \"/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"sample_rate_by_split\"\n  value {\n    struct_value {\n      fields {\n        key: \"__value__\"\n        value {\n          string_value: \"{\\\"eval\\\": 1.0, \\\"test\\\": 1.0, \\\"train\\\": 1.0}\"\n        }\n      }\n    }\n  }\n}\ncustom_properties {\n  key: \"stats_dashboard_link\"\n  value {\n    string_value: \"\"\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"ExampleStatistics\"\ncreate_time_since_epoch: 1760571971792\nlast_update_time_since_epoch: 1760571971792\n, artifact_type: id: 17\nname: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)]}, output_dict=defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/SchemaGen/schema/3\"\n, artifact_type: name: \"Schema\"\n)]}), exec_properties={'infer_feature_shape': 1, 'exclude_splits': '[]'}, execution_output_uri='/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/SchemaGen/.system/executor_execution/3/executor_output.pb', stateful_working_dir='/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/SchemaGen/.system/stateful_working_dir/53074663-611b-45ac-883b-1af87a724f34', tmp_dir='/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/SchemaGen/.system/executor_execution/3/.temp/', pipeline_node=node_info {\n  type {\n    name: \"tfx.components.schema_gen.component.SchemaGen\"\n    base_type: PROCESS\n  }\n  id: \"SchemaGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonFuncCustomCompPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-15T23:46:03.584027\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonFuncCustomCompPipeline.SchemaGen\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"statistics\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"StatisticsGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonFuncCustomCompPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-15T23:46:03.584027\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonFuncCustomCompPipeline.StatisticsGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"ExampleStatistics\"\n            base_type: STATISTICS\n          }\n        }\n        output_key: \"statistics\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"schema\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Schema\"\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"exclude_splits\"\n    value {\n      field_value {\n        string_value: \"[]\"\n      }\n    }\n  }\n  parameters {\n    key: \"infer_feature_shape\"\n    value {\n      field_value {\n        int_value: 1\n      }\n    }\n  }\n}\nupstream_nodes: \"StatisticsGen\"\nexecution_options {\n  caching_options {\n  }\n}\n, pipeline_info=id: \"TestPythonFuncCustomCompPipeline\"\n, pipeline_run_id='2025-10-15T23:46:03.584027', top_level_pipeline_run_id=None, frontend_url=None)\nINFO:absl:Processing schema from statistics for split train.\nINFO:absl:Processing schema from statistics for split eval.\nINFO:absl:Processing schema from statistics for split test.\nINFO:absl:Schema written to /kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/SchemaGen/schema/3/schema.pbtxt.\nINFO:absl:Cleaning up stateless execution info.\nINFO:absl:Execution 3 succeeded.\nINFO:absl:Cleaning up stateful execution info.\nINFO:absl:Deleted stateful_working_dir /kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/SchemaGen/.system/stateful_working_dir/53074663-611b-45ac-883b-1af87a724f34\nINFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/SchemaGen/schema/3\"\n, artifact_type: name: \"Schema\"\n)]}) for execution 3\nINFO:absl:MetadataStore with DB connection initialized\nINFO:absl:Component SchemaGen is finished.\nINFO:absl:MetadataStore with DB connection initialized\n.s\n----------------------------------------------------------------------\nRan 2 tests in 9.460s\n\nOK (skipped=1)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"!find /kaggle/working -type f\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:46:14.214907Z","iopub.execute_input":"2025-10-15T23:46:14.215271Z","iopub.status.idle":"2025-10-15T23:46:14.338371Z","shell.execute_reply.started":"2025-10-15T23:46:14.215234Z","shell.execute_reply":"2025-10-15T23:46:14.337407Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/transform_movie_lens_test.py\n/kaggle/working/ml-1m/ratings_1000.dat\n/kaggle/working/ml-1m/README\n/kaggle/working/ml-1m/users.dat\n/kaggle/working/ml-1m/movies.dat\n/kaggle/working/ml-1m/tmp/users2.dat\n/kaggle/working/ml-1m/ratings.dat\n/kaggle/working/ml-1m/users_100.dat\n/kaggle/working/csv_example_gen_test.py\n/kaggle/working/helper.py\n/kaggle/working/dataset_tfxio_example.py\n/kaggle/working/ingest_movie_lens_beam_pa.py\n/kaggle/working/CustomUTF8Coder.py\n/kaggle/working/ingest_movie_lens_beam_pa_test.py\n/kaggle/working/ingest_movie_lens_component_test.py\n/kaggle/working/movie_lens_utils_test.py\n/kaggle/working/ingest_movie_lens_component.py\n/kaggle/working/movie_lens_utils.py\n/kaggle/working/ingest_movie_lens_beam_test.py\n/kaggle/working/ingest_movie_lens_custom_component.py\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-eval/FeatureStats.pb\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-train/FeatureStats.pb\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-test/FeatureStats.pb\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/SchemaGen/schema/3/schema.pbtxt\n/kaggle/working/ingest_movie_lens_custom_component_test.py\n/kaggle/working/__pycache__/helper.cpython-310.pyc\n/kaggle/working/__pycache__/CustomUTF8Coder.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils_test.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_beam.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_custom_component.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_beam_test.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_component_test.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_component.cpython-310.pyc\n/kaggle/working/__pycache__/csv_example_gen_test.cpython-310.pyc\n/kaggle/working/transform_movie_lens.py\n/kaggle/working/ingest_movie_lens_beam.py\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for TFX fully custom component\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/ingest_movie_lens_custom_component_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:46:14.339682Z","iopub.execute_input":"2025-10-15T23:46:14.340056Z","iopub.status.idle":"2025-10-15T23:46:37.259603Z","shell.execute_reply.started":"2025-10-15T23:46:14.340015Z","shell.execute_reply":"2025-10-15T23:46:37.258743Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for TFX fully custom component\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\n21.428175851 seconds\nWed Oct 15 11:46:37 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"INFO:absl:output_examples written as TFRecords\nWARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n.INFO:absl:Excluding no splits because exclude_splits is not set.\nINFO:absl:Excluding no splits because exclude_splits is not set.\nINFO:absl:Using deployment config:\n executor_specs {\n  key: \"IngestMovieLensComponent\"\n  value {\n    beam_executable_spec {\n      python_executor_spec {\n        class_path: \"ingest_movie_lens_custom_component.IngestMovieLensExecutor\"\n      }\n    }\n  }\n}\nexecutor_specs {\n  key: \"SchemaGen\"\n  value {\n    python_class_executable_spec {\n      class_path: \"tfx.components.schema_gen.executor.Executor\"\n    }\n  }\n}\nexecutor_specs {\n  key: \"StatisticsGen\"\n  value {\n    beam_executable_spec {\n      python_executor_spec {\n        class_path: \"tfx.components.statistics_gen.executor.Executor\"\n      }\n    }\n  }\n}\nmetadata_connection_config {\n  database_connection_config {\n    sqlite {\n      filename_uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/tfx_metadata/metadata.db\"\n      connection_mode: READWRITE_OPENCREATE\n    }\n  }\n}\n\nINFO:absl:Using connection config:\n sqlite {\n  filename_uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component IngestMovieLensComponent is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"ingest_movie_lens_custom_component.IngestMovieLensComponent\"\n  }\n  id: \"IngestMovieLensComponent\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestFullyCustomCompPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-15T23:46:27.149705\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestFullyCustomCompPipeline.IngestMovieLensComponent\"\n      }\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"output_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"infiles_dict_ser\"\n    value {\n      field_value {\n        string_value: \"gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n      }\n    }\n  }\n  parameters {\n    key: \"name\"\n    value {\n      field_value {\n        string_value: \"test_fully_custom_component\"\n      }\n    }\n  }\n  parameters {\n    key: \"output_config_ser\"\n    value {\n      field_value {\n        string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n      }\n    }\n  }\n}\ndownstream_nodes: \"StatisticsGen\"\nexecution_options {\n  caching_options {\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nINFO:absl:[IngestMovieLensComponent] Resolved inputs: ({},)\nINFO:absl:MetadataStore with DB connection initialized\nINFO:absl:Going to run a new execution 1\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1760571987.322239    1378 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=1, input_dict={}, output_dict=defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}), exec_properties={'output_config_ser': 'Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK', 'infiles_dict_ser': 'gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==', 'name': 'test_fully_custom_component'}, execution_output_uri='/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/.system/executor_execution/1/executor_output.pb', stateful_working_dir='/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/.system/stateful_working_dir/40bc1aa4-6968-433b-bb7f-da425afbe734', tmp_dir='/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/.system/executor_execution/1/.temp/', pipeline_node=node_info {\n  type {\n    name: \"ingest_movie_lens_custom_component.IngestMovieLensComponent\"\n  }\n  id: \"IngestMovieLensComponent\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestFullyCustomCompPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-15T23:46:27.149705\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestFullyCustomCompPipeline.IngestMovieLensComponent\"\n      }\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"output_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"infiles_dict_ser\"\n    value {\n      field_value {\n        string_value: \"gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n      }\n    }\n  }\n  parameters {\n    key: \"name\"\n    value {\n      field_value {\n        string_value: \"test_fully_custom_component\"\n      }\n    }\n  }\n  parameters {\n    key: \"output_config_ser\"\n    value {\n      field_value {\n        string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n      }\n    }\n  }\n}\ndownstream_nodes: \"StatisticsGen\"\nexecution_options {\n  caching_options {\n  }\n}\n, pipeline_info=id: \"TestFullyCustomCompPipeline\"\n, pipeline_run_id='2025-10-15T23:46:27.149705', top_level_pipeline_run_id=None, frontend_url=None)\nINFO:absl:output_examples written as TFRecords\nINFO:absl:Cleaning up stateless execution info.\nINFO:absl:Execution 1 succeeded.\nINFO:absl:Cleaning up stateful execution info.\nINFO:absl:Deleted stateful_working_dir /kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/.system/stateful_working_dir/40bc1aa4-6968-433b-bb7f-da425afbe734\nINFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}) for execution 1\nINFO:absl:MetadataStore with DB connection initialized\nINFO:absl:Component IngestMovieLensComponent is finished.\nINFO:absl:Component StatisticsGen is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n    base_type: PROCESS\n  }\n  id: \"StatisticsGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestFullyCustomCompPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-15T23:46:27.149705\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestFullyCustomCompPipeline.StatisticsGen\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"examples\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"IngestMovieLensComponent\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestFullyCustomCompPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-15T23:46:27.149705\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestFullyCustomCompPipeline.IngestMovieLensComponent\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"Examples\"\n            base_type: DATASET\n          }\n        }\n        output_key: \"output_examples\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"statistics\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleStatistics\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          base_type: STATISTICS\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"exclude_splits\"\n    value {\n      field_value {\n        string_value: \"[]\"\n      }\n    }\n  }\n}\nupstream_nodes: \"IngestMovieLensComponent\"\ndownstream_nodes: \"SchemaGen\"\nexecution_options {\n  caching_options {\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nWARNING:absl:ArtifactQuery.property_predicate is not supported.\nINFO:absl:[StatisticsGen] Resolved inputs: ({'examples': [Artifact(artifact: id: 1\ntype_id: 15\nuri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    int_value: 1\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Examples\"\ncreate_time_since_epoch: 1760571989196\nlast_update_time_since_epoch: 1760571989196\n, artifact_type: id: 15\nname: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]},)\nINFO:absl:MetadataStore with DB connection initialized\nINFO:absl:Going to run a new execution 2\nI0000 00:00:1760571989.271763    1378 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=2, input_dict={'examples': [Artifact(artifact: id: 1\ntype_id: 15\nuri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    int_value: 1\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Examples\"\ncreate_time_since_epoch: 1760571989196\nlast_update_time_since_epoch: 1760571989196\n, artifact_type: id: 15\nname: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/statistics/2\"\n, artifact_type: name: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/.system/executor_execution/2/executor_output.pb', stateful_working_dir='/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/.system/stateful_working_dir/7255e0d9-f04c-463e-b2e0-f4b7edd49dea', tmp_dir='/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/.system/executor_execution/2/.temp/', pipeline_node=node_info {\n  type {\n    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n    base_type: PROCESS\n  }\n  id: \"StatisticsGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestFullyCustomCompPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-15T23:46:27.149705\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestFullyCustomCompPipeline.StatisticsGen\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"examples\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"IngestMovieLensComponent\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestFullyCustomCompPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-15T23:46:27.149705\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestFullyCustomCompPipeline.IngestMovieLensComponent\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"Examples\"\n            base_type: DATASET\n          }\n        }\n        output_key: \"output_examples\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"statistics\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleStatistics\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          base_type: STATISTICS\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"exclude_splits\"\n    value {\n      field_value {\n        string_value: \"[]\"\n      }\n    }\n  }\n}\nupstream_nodes: \"IngestMovieLensComponent\"\ndownstream_nodes: \"SchemaGen\"\nexecution_options {\n  caching_options {\n  }\n}\n, pipeline_info=id: \"TestFullyCustomCompPipeline\"\n, pipeline_run_id='2025-10-15T23:46:27.149705', top_level_pipeline_run_id=None, frontend_url=None)\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nINFO:absl:Generating statistics for split train.\nINFO:absl:Statistics for split train written to /kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/statistics/2/Split-train.\nINFO:absl:Generating statistics for split eval.\nINFO:absl:Statistics for split eval written to /kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/statistics/2/Split-eval.\nINFO:absl:Generating statistics for split test.\nINFO:absl:Statistics for split test written to /kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/statistics/2/Split-test.\nINFO:absl:Cleaning up stateless execution info.\nINFO:absl:Execution 2 succeeded.\nINFO:absl:Cleaning up stateful execution info.\nINFO:absl:Deleted stateful_working_dir /kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/.system/stateful_working_dir/7255e0d9-f04c-463e-b2e0-f4b7edd49dea\nINFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/statistics/2\"\n, artifact_type: name: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)]}) for execution 2\nINFO:absl:MetadataStore with DB connection initialized\nINFO:absl:Component StatisticsGen is finished.\nINFO:absl:Component SchemaGen is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"tfx.components.schema_gen.component.SchemaGen\"\n    base_type: PROCESS\n  }\n  id: \"SchemaGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestFullyCustomCompPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-15T23:46:27.149705\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestFullyCustomCompPipeline.SchemaGen\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"statistics\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"StatisticsGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestFullyCustomCompPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-15T23:46:27.149705\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestFullyCustomCompPipeline.StatisticsGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"ExampleStatistics\"\n            base_type: STATISTICS\n          }\n        }\n        output_key: \"statistics\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"schema\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Schema\"\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"exclude_splits\"\n    value {\n      field_value {\n        string_value: \"[]\"\n      }\n    }\n  }\n  parameters {\n    key: \"infer_feature_shape\"\n    value {\n      field_value {\n        int_value: 1\n      }\n    }\n  }\n}\nupstream_nodes: \"StatisticsGen\"\nexecution_options {\n  caching_options {\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nWARNING:absl:ArtifactQuery.property_predicate is not supported.\nINFO:absl:[SchemaGen] Resolved inputs: ({'statistics': [Artifact(artifact: id: 2\ntype_id: 17\nuri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/statistics/2\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"sample_rate_by_split\"\n  value {\n    struct_value {\n      fields {\n        key: \"__value__\"\n        value {\n          string_value: \"{\\\"eval\\\": 1.0, \\\"test\\\": 1.0, \\\"train\\\": 1.0}\"\n        }\n      }\n    }\n  }\n}\ncustom_properties {\n  key: \"stats_dashboard_link\"\n  value {\n    string_value: \"\"\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"ExampleStatistics\"\ncreate_time_since_epoch: 1760571994839\nlast_update_time_since_epoch: 1760571994839\n, artifact_type: id: 17\nname: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)]},)\nINFO:absl:MetadataStore with DB connection initialized\nINFO:absl:Going to run a new execution 3\nI0000 00:00:1760571994.918270    1378 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=3, input_dict={'statistics': [Artifact(artifact: id: 2\ntype_id: 17\nuri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/statistics/2\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"sample_rate_by_split\"\n  value {\n    struct_value {\n      fields {\n        key: \"__value__\"\n        value {\n          string_value: \"{\\\"eval\\\": 1.0, \\\"test\\\": 1.0, \\\"train\\\": 1.0}\"\n        }\n      }\n    }\n  }\n}\ncustom_properties {\n  key: \"stats_dashboard_link\"\n  value {\n    string_value: \"\"\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"ExampleStatistics\"\ncreate_time_since_epoch: 1760571994839\nlast_update_time_since_epoch: 1760571994839\n, artifact_type: id: 17\nname: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)]}, output_dict=defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/SchemaGen/schema/3\"\n, artifact_type: name: \"Schema\"\n)]}), exec_properties={'infer_feature_shape': 1, 'exclude_splits': '[]'}, execution_output_uri='/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/SchemaGen/.system/executor_execution/3/executor_output.pb', stateful_working_dir='/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/SchemaGen/.system/stateful_working_dir/85f2ef78-ee5c-4ba0-8e70-c2c32b2015a8', tmp_dir='/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/SchemaGen/.system/executor_execution/3/.temp/', pipeline_node=node_info {\n  type {\n    name: \"tfx.components.schema_gen.component.SchemaGen\"\n    base_type: PROCESS\n  }\n  id: \"SchemaGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestFullyCustomCompPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-15T23:46:27.149705\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestFullyCustomCompPipeline.SchemaGen\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"statistics\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"StatisticsGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestFullyCustomCompPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-15T23:46:27.149705\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestFullyCustomCompPipeline.StatisticsGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"ExampleStatistics\"\n            base_type: STATISTICS\n          }\n        }\n        output_key: \"statistics\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"schema\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Schema\"\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"exclude_splits\"\n    value {\n      field_value {\n        string_value: \"[]\"\n      }\n    }\n  }\n  parameters {\n    key: \"infer_feature_shape\"\n    value {\n      field_value {\n        int_value: 1\n      }\n    }\n  }\n}\nupstream_nodes: \"StatisticsGen\"\nexecution_options {\n  caching_options {\n  }\n}\n, pipeline_info=id: \"TestFullyCustomCompPipeline\"\n, pipeline_run_id='2025-10-15T23:46:27.149705', top_level_pipeline_run_id=None, frontend_url=None)\nINFO:absl:Processing schema from statistics for split train.\nINFO:absl:Processing schema from statistics for split eval.\nINFO:absl:Processing schema from statistics for split test.\nINFO:absl:Schema written to /kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/SchemaGen/schema/3/schema.pbtxt.\nINFO:absl:Cleaning up stateless execution info.\nINFO:absl:Execution 3 succeeded.\nINFO:absl:Cleaning up stateful execution info.\nINFO:absl:Deleted stateful_working_dir /kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/SchemaGen/.system/stateful_working_dir/85f2ef78-ee5c-4ba0-8e70-c2c32b2015a8\nINFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/SchemaGen/schema/3\"\n, artifact_type: name: \"Schema\"\n)]}) for execution 3\nINFO:absl:MetadataStore with DB connection initialized\nINFO:absl:Component SchemaGen is finished.\nINFO:absl:MetadataStore with DB connection initialized\n.s\n----------------------------------------------------------------------\nRan 3 tests in 11.257s\n\nOK (skipped=1)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"%%bash\n#it can take a couple of minutes to get current version of recently uploaded file to github\n#wget -q -c --no-cache https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/main/src/test/python/test_tft.py -O /kaggle/working/test_tft.py\n#curl --header \"Cache-Control: no-cache\" \"https://api.github.com/repos/nking/recommender_systems/content/src/test/python/test_tft.py\" -o /kaggle/working/test_tft.py\n\nrepo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/main/python'\ndeclare -a my_files=(\"ingest_movie_lens_beam.py\" \"ingest_movie_lens_beam_pa.py\"\n  \"CustomUTF8Coder.py\" \"ingest_movie_lens_component.py\" \n  \"movie_lens_utils.py\" \"ingest_movie_lens_custom_component.py\"\n)\nfor item in \"${my_files[@]}\"\ndo\n  rm -f \"/kaggle/working/$item\"\n  echo \"$item\"\n  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\ndone\n\nrepo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/drafts/python'\ndeclare -a my_files=(\"transform_movie_lens.py\")\nfor item in \"${my_files[@]}\"\ndo\n  rm -f \"/kaggle/working/$item\"\n  echo \"$item\"\n  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\ndone\n\nrepo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/test/python'\ndeclare -a my_files=(\"ingest_movie_lens_beam_test.py\" \"ingest_movie_lens_beam_pa_test.py\"\n  \"ingest_movie_lens_component_test.py\" \"ingest_movie_lens_custom_component_test.py\" \n  \"movie_lens_utils_test.py\" \"csv_example_gen_test.py\" \n  \"helper.py\" \"transform_movie_lens_test.py\"\n)\nfor item in \"${my_files[@]}\"\ndo\n  rm -f \"/kaggle/working/$item\"\n  echo \"$item\"\n  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\ndone\n\nls -l /kaggle/working/\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T00:33:35.545423Z","iopub.execute_input":"2025-10-16T00:33:35.546012Z","iopub.status.idle":"2025-10-16T00:33:36.682227Z","shell.execute_reply.started":"2025-10-16T00:33:35.545982Z","shell.execute_reply":"2025-10-16T00:33:36.681476Z"}},"outputs":[{"name":"stdout","text":"ingest_movie_lens_beam.py\ningest_movie_lens_beam_pa.py\nCustomUTF8Coder.py\ningest_movie_lens_component.py\nmovie_lens_utils.py\ningest_movie_lens_custom_component.py\ntransform_movie_lens.py\ningest_movie_lens_beam_test.py\ningest_movie_lens_beam_pa_test.py\ningest_movie_lens_component_test.py\ningest_movie_lens_custom_component_test.py\nmovie_lens_utils_test.py\ncsv_example_gen_test.py\nhelper.py\ntransform_movie_lens_test.py\ntotal 160\ndrwxr-xr-x 7 root root  4096 Oct 15 23:46 bin\n-rw-r--r-- 1 root root  7334 Oct 16 00:33 csv_example_gen_test.py\n-rw-r--r-- 1 root root   777 Oct 16 00:33 CustomUTF8Coder.py\n-rw-r--r-- 1 root root  2392 Oct 15 23:44 dataset_tfxio_example.py\n-rw-r--r-- 1 root root  3633 Oct 16 00:33 helper.py\n-rw-r--r-- 1 root root  9994 Oct 16 00:33 ingest_movie_lens_beam_pa.py\n-rw-r--r-- 1 root root  4543 Oct 16 00:33 ingest_movie_lens_beam_pa_test.py\n-rw-r--r-- 1 root root  7904 Oct 16 00:33 ingest_movie_lens_beam.py\n-rw-r--r-- 1 root root  5072 Oct 16 00:33 ingest_movie_lens_beam_test.py\n-rw-r--r-- 1 root root  6217 Oct 16 00:33 ingest_movie_lens_component.py\n-rw-r--r-- 1 root root 11212 Oct 16 00:33 ingest_movie_lens_component_test.py\n-rw-r--r-- 1 root root 13179 Oct 16 00:33 ingest_movie_lens_custom_component.py\n-rw-r--r-- 1 root root 12585 Oct 16 00:33 ingest_movie_lens_custom_component_test.py\ndrwxr-x--- 3 root root  4096 Oct 15 23:44 ml-1m\n-rw-r--r-- 1 root root 13778 Oct 16 00:33 movie_lens_utils.py\n-rw-r--r-- 1 root root  4376 Oct 16 00:33 movie_lens_utils_test.py\ndrwxr-xr-x 2 root root  4096 Oct 16 00:13 __pycache__\n-rw-r--r-- 1 root root  4271 Oct 16 00:33 transform_movie_lens.py\n-rw-r--r-- 1 root root  7714 Oct 16 00:33 transform_movie_lens_test.py\nThu Oct 16 12:33:36 AM UTC 2025\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for preprocessing Transform\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/transform_movie_lens_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T00:33:36.684015Z","iopub.execute_input":"2025-10-16T00:33:36.684265Z","iopub.status.idle":"2025-10-16T00:34:45.919762Z","shell.execute_reply.started":"2025-10-16T00:33:36.684245Z","shell.execute_reply":"2025-10-16T00:34:45.918792Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for preprocessing Transform\nrunning bdist_wheel\nrunning build\nrunning build_py\ncreating build/lib\ncopying transform_movie_lens_test.py -> build/lib\ncopying csv_example_gen_test.py -> build/lib\ncopying helper.py -> build/lib\ncopying dataset_tfxio_example.py -> build/lib\ncopying ingest_movie_lens_beam_pa.py -> build/lib\ncopying CustomUTF8Coder.py -> build/lib\ncopying ingest_movie_lens_beam_pa_test.py -> build/lib\ncopying ingest_movie_lens_component_test.py -> build/lib\ncopying movie_lens_utils_test.py -> build/lib\ncopying ingest_movie_lens_component.py -> build/lib\ncopying movie_lens_utils.py -> build/lib\ncopying ingest_movie_lens_beam_test.py -> build/lib\ncopying ingest_movie_lens_custom_component.py -> build/lib\ncopying ingest_movie_lens_custom_component_test.py -> build/lib\ncopying transform_movie_lens.py -> build/lib\ncopying ingest_movie_lens_beam.py -> build/lib\ninstalling to /tmp/tmp1ubyc3ot\nrunning install\nrunning install_lib\ncopying build/lib/helper.py -> /tmp/tmp1ubyc3ot/.\ncopying build/lib/ingest_movie_lens_beam_test.py -> /tmp/tmp1ubyc3ot/.\ncopying build/lib/movie_lens_utils_test.py -> /tmp/tmp1ubyc3ot/.\ncopying build/lib/ingest_movie_lens_component_test.py -> /tmp/tmp1ubyc3ot/.\ncopying build/lib/ingest_movie_lens_custom_component_test.py -> /tmp/tmp1ubyc3ot/.\ncopying build/lib/csv_example_gen_test.py -> /tmp/tmp1ubyc3ot/.\ncopying build/lib/ingest_movie_lens_beam_pa_test.py -> /tmp/tmp1ubyc3ot/.\ncopying build/lib/CustomUTF8Coder.py -> /tmp/tmp1ubyc3ot/.\ncopying build/lib/transform_movie_lens_test.py -> /tmp/tmp1ubyc3ot/.\ncopying build/lib/ingest_movie_lens_beam_pa.py -> /tmp/tmp1ubyc3ot/.\ncopying build/lib/dataset_tfxio_example.py -> /tmp/tmp1ubyc3ot/.\ncopying build/lib/transform_movie_lens.py -> /tmp/tmp1ubyc3ot/.\ncopying build/lib/ingest_movie_lens_custom_component.py -> /tmp/tmp1ubyc3ot/.\ncopying build/lib/ingest_movie_lens_component.py -> /tmp/tmp1ubyc3ot/.\ncopying build/lib/movie_lens_utils.py -> /tmp/tmp1ubyc3ot/.\ncopying build/lib/ingest_movie_lens_beam.py -> /tmp/tmp1ubyc3ot/.\nrunning install_egg_info\nrunning egg_info\ncreating tfx_user_code_Transform.egg-info\nwriting tfx_user_code_Transform.egg-info/PKG-INFO\nwriting dependency_links to tfx_user_code_Transform.egg-info/dependency_links.txt\nwriting top-level names to tfx_user_code_Transform.egg-info/top_level.txt\nwriting manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\nreading manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\nwriting manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\nCopying tfx_user_code_Transform.egg-info to /tmp/tmp1ubyc3ot/./tfx_user_code_Transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3.10.egg-info\nrunning install_scripts\ncreating /tmp/tmp1ubyc3ot/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696.dist-info/WHEEL\ncreating '/tmp/tmpv1q_5vn4/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl' and adding '/tmp/tmp1ubyc3ot' to it\nadding 'CustomUTF8Coder.py'\nadding 'csv_example_gen_test.py'\nadding 'dataset_tfxio_example.py'\nadding 'helper.py'\nadding 'ingest_movie_lens_beam.py'\nadding 'ingest_movie_lens_beam_pa.py'\nadding 'ingest_movie_lens_beam_pa_test.py'\nadding 'ingest_movie_lens_beam_test.py'\nadding 'ingest_movie_lens_component.py'\nadding 'ingest_movie_lens_component_test.py'\nadding 'ingest_movie_lens_custom_component.py'\nadding 'ingest_movie_lens_custom_component_test.py'\nadding 'movie_lens_utils.py'\nadding 'movie_lens_utils_test.py'\nadding 'transform_movie_lens.py'\nadding 'transform_movie_lens_test.py'\nadding 'tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696.dist-info/METADATA'\nadding 'tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696.dist-info/WHEEL'\nadding 'tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696.dist-info/top_level.txt'\nadding 'tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696.dist-info/RECORD'\nremoving /tmp/tmp1ubyc3ot\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\nProcessing ./bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl\nInstalling collected packages: tfx-user-code-transform\nSuccessfully installed tfx-user-code-transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696\nProcessing ./bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl\nInstalling collected packages: tfx-user-code-transform\nSuccessfully installed tfx-user-code-transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696\nProcessing ./bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl\nInstalling collected packages: tfx-user-code-transform\nSuccessfully installed tfx-user-code-transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\n67.649800939 seconds\nThu Oct 16 12:34:45 AM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"INFO:absl:Excluding no splits because exclude_splits is not set.\nINFO:absl:Excluding no splits because exclude_splits is not set.\nINFO:absl:Generating ephemeral wheel package for '/kaggle/working/transform_movie_lens.py' (including modules: ['transform_movie_lens_test', 'csv_example_gen_test', 'helper', 'dataset_tfxio_example', 'ingest_movie_lens_beam_pa', 'CustomUTF8Coder', 'ingest_movie_lens_beam_pa_test', 'ingest_movie_lens_component_test', 'movie_lens_utils_test', 'ingest_movie_lens_component', 'movie_lens_utils', 'ingest_movie_lens_beam_test', 'ingest_movie_lens_custom_component', 'ingest_movie_lens_custom_component_test', 'transform_movie_lens', 'ingest_movie_lens_beam']).\nINFO:absl:User module package has hash fingerprint version a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696.\nINFO:absl:Executing: ['/usr/local/envs/my_tfx_env/bin/python', '/tmp/tmpt77dyv1n/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmp1ubyc3ot', '--dist-dir', '/tmp/tmpv1q_5vn4']\n/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:90: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n!!\n\n        ********************************************************************************\n        Please avoid running ``setup.py`` directly.\n        Instead, use pypa/build, pypa/installer or other\n        standards-based tools.\n\n        By 2025-Oct-31, you need to update your project and remove deprecated calls\n        or your builds will no longer be supported.\n\n        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n        ********************************************************************************\n\n!!\n  self.initialize_options()\nINFO:absl:Successfully built user code wheel distribution at '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl'; target user module is 'transform_movie_lens'.\nINFO:absl:Full user module path is 'transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl'\nINFO:absl:Using deployment config:\n executor_specs {\n  key: \"MovieLensExampleGen\"\n  value {\n    beam_executable_spec {\n      python_executor_spec {\n        class_path: \"ingest_movie_lens_component.MovieLensExampleGen_Executor\"\n      }\n      beam_pipeline_args: \"--direct_running_mode=multi_processing\"\n      beam_pipeline_args: \"--direct_num_workers=0\"\n      beam_pipeline_args_placeholders {\n        value {\n          string_value: \"--direct_running_mode=multi_processing\"\n        }\n      }\n      beam_pipeline_args_placeholders {\n        value {\n          string_value: \"--direct_num_workers=0\"\n        }\n      }\n    }\n  }\n}\nexecutor_specs {\n  key: \"SchemaGen\"\n  value {\n    python_class_executable_spec {\n      class_path: \"tfx.components.schema_gen.executor.Executor\"\n    }\n  }\n}\nexecutor_specs {\n  key: \"StatisticsGen\"\n  value {\n    beam_executable_spec {\n      python_executor_spec {\n        class_path: \"tfx.components.statistics_gen.executor.Executor\"\n      }\n      beam_pipeline_args: \"--direct_running_mode=multi_processing\"\n      beam_pipeline_args: \"--direct_num_workers=0\"\n      beam_pipeline_args_placeholders {\n        value {\n          string_value: \"--direct_running_mode=multi_processing\"\n        }\n      }\n      beam_pipeline_args_placeholders {\n        value {\n          string_value: \"--direct_num_workers=0\"\n        }\n      }\n    }\n  }\n}\nexecutor_specs {\n  key: \"Transform\"\n  value {\n    beam_executable_spec {\n      python_executor_spec {\n        class_path: \"tfx.components.transform.executor.Executor\"\n      }\n      beam_pipeline_args: \"--direct_running_mode=multi_processing\"\n      beam_pipeline_args: \"--direct_num_workers=0\"\n      beam_pipeline_args_placeholders {\n        value {\n          string_value: \"--direct_running_mode=multi_processing\"\n        }\n      }\n      beam_pipeline_args_placeholders {\n        value {\n          string_value: \"--direct_num_workers=0\"\n        }\n      }\n    }\n  }\n}\nmetadata_connection_config {\n  database_connection_config {\n    sqlite {\n      filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n      connection_mode: READWRITE_OPENCREATE\n    }\n  }\n}\n\nINFO:absl:Using connection config:\n sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component MovieLensExampleGen is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"ingest_movie_lens_component.MovieLensExampleGen\"\n  }\n  id: \"MovieLensExampleGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-16T00:33:47.173771\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline.MovieLensExampleGen\"\n      }\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"output_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"infiles_dict_ser\"\n    value {\n      field_value {\n        string_value: \"gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n      }\n    }\n  }\n  parameters {\n    key: \"output_config_ser\"\n    value {\n      field_value {\n        string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n      }\n    }\n  }\n}\ndownstream_nodes: \"StatisticsGen\"\ndownstream_nodes: \"Transform\"\nexecution_options {\n  caching_options {\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type pipeline and name TestPythonTransformPipeline\nDEBUG:absl:ID of context type {\n  name: \"pipeline\"\n}\nname {\n  field_value {\n    string_value: \"TestPythonTransformPipeline\"\n  }\n}\n is 1.\nDEBUG:absl:Failed to get context of type pipeline_run and name 2025-10-16T00:33:47.173771\nDEBUG:absl:ID of context type {\n  name: \"pipeline_run\"\n}\nname {\n  field_value {\n    string_value: \"2025-10-16T00:33:47.173771\"\n  }\n}\n is 2.\nDEBUG:absl:Failed to get context of type node and name TestPythonTransformPipeline.MovieLensExampleGen\nDEBUG:absl:ID of context type {\n  name: \"node\"\n}\nname {\n  field_value {\n    string_value: \"TestPythonTransformPipeline.MovieLensExampleGen\"\n  }\n}\n is 3.\nDEBUG:absl:Before conditional:\n{}\nDEBUG:absl:After conditional:\n{}\nINFO:absl:[MovieLensExampleGen] Resolved inputs: ({},)\nDEBUG:absl:Prepared EXECUTION:\n type_id: 13\nlast_known_state: RUNNING\ncustom_properties {\n  key: \"infiles_dict_ser\"\n  value {\n    string_value: \"gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n  }\n}\ncustom_properties {\n  key: \"output_config_ser\"\n  value {\n    string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n  }\n}\nname: \"d36a2e32-a700-44a1-9096-d1299c378cff\"\n\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type execution_cache and name 9c8ee902c018e9e330485b35a8dcba812ad906560ec1fa358c345cfb41f487bf\nDEBUG:absl:ID of context type {\n  name: \"execution_cache\"\n}\nname {\n  field_value {\n    string_value: \"9c8ee902c018e9e330485b35a8dcba812ad906560ec1fa358c345cfb41f487bf\"\n  }\n}\n is 4.\nINFO:absl:Going to run a new execution 1\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1760574827.350593    4358 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=1, input_dict={}, output_dict=defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}), exec_properties={'infiles_dict_ser': 'gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==', 'output_config_ser': 'Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK'}, execution_output_uri='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/.system/executor_execution/1/executor_output.pb', stateful_working_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/.system/stateful_working_dir/b2b3695b-58cc-4c09-b6d7-5645ae7bf067', tmp_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/.system/executor_execution/1/.temp/', pipeline_node=node_info {\n  type {\n    name: \"ingest_movie_lens_component.MovieLensExampleGen\"\n  }\n  id: \"MovieLensExampleGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-16T00:33:47.173771\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline.MovieLensExampleGen\"\n      }\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"output_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"infiles_dict_ser\"\n    value {\n      field_value {\n        string_value: \"gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n      }\n    }\n  }\n  parameters {\n    key: \"output_config_ser\"\n    value {\n      field_value {\n        string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n      }\n    }\n  }\n}\ndownstream_nodes: \"StatisticsGen\"\ndownstream_nodes: \"Transform\"\nexecution_options {\n  caching_options {\n  }\n}\n, pipeline_info=id: \"TestPythonTransformPipeline\"\n, pipeline_run_id='2025-10-16T00:33:47.173771', top_level_pipeline_run_id=None, frontend_url=None)\nINFO:absl:Attempting to infer TFX Python dependency for beam\nINFO:absl:Copying all content from install dir /usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx to temp dir /tmp/tmp4y3zflxv/build/tfx\nINFO:absl:Generating a temp setup file at /tmp/tmp4y3zflxv/build/tfx/setup.py\nINFO:absl:Creating temporary sdist package, logs available at /tmp/tmp4y3zflxv/build/tfx/setup.log\nINFO:absl:Added --extra_package=/tmp/tmp4y3zflxv/build/tfx/dist/tfx_ephemeral-1.16.0.tar.gz to beam args\nINFO:absl:MovieLensExampleGen\nDEBUG:absl:output_examples was passed in to component\nDEBUG:absl:output_examples TYPE=<class 'tfx.types.standard_artifacts.Examples'>\nDEBUG:absl:output_examples=Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    int_value: 1\n  }\n}\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)\nDEBUG:absl:split_names=['train', 'eval', 'test']\nDEBUG:absl:columns=[('user_id', <class 'int'>), ('movie_id', <class 'int'>), ('rating', <class 'int'>), ('timestamp', <class 'int'>), ('gender', <class 'str'>), ('age', <class 'int'>), ('occupation', <class 'int'>), ('genres', <class 'str'>)]\nDEBUG:absl:cumulative_buckets=[80, 90, 100]\nDEBUG:absl:have ratings_tuple.  type=<class 'apache_beam.pvalue.DoOutputsTuple'>\nDEBUG:absl:prefix_path=/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord\nDEBUG:absl:prefix_path=/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord\nDEBUG:absl:prefix_path=/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord\nINFO:absl:output_examples written as TFRecords\nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574833   nanos: 724752902 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574833   nanos: 733474016 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574833   nanos: 744346857 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574833   nanos: 754575729 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574833   nanos: 759337902 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574833   nanos: 768690347 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574833   nanos: 760879516 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574833   nanos: 769032001 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574846   nanos: 333968639 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_50\" transform_id: \"write_to_tfrecord_421920178746/Write/WriteImpl/WriteBundles\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-13\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574846   nanos: 382814407 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_51\" transform_id: \"write_to_tfrecord_341158322707/Write/WriteImpl/WriteBundles\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-14\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574846   nanos: 520995378 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_52\" transform_id: \"write_to_tfrecord_341158322707/Write/WriteImpl/WriteBundles\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574846   nanos: 525022506 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_49\" transform_id: \"write_to_tfrecord_421920178746/Write/WriteImpl/WriteBundles\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-13\" \nINFO:absl:Cleaning up stateless execution info.\nINFO:absl:Execution 1 succeeded.\nINFO:absl:Cleaning up stateful execution info.\nINFO:absl:Deleted stateful_working_dir /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/.system/stateful_working_dir/b2b3695b-58cc-4c09-b6d7-5645ae7bf067\nINFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}) for execution 1\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component MovieLensExampleGen is finished.\nINFO:absl:Component StatisticsGen is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n    base_type: PROCESS\n  }\n  id: \"StatisticsGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-16T00:33:47.173771\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline.StatisticsGen\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"examples\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"MovieLensExampleGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-16T00:33:47.173771\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline.MovieLensExampleGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"Examples\"\n            base_type: DATASET\n          }\n        }\n        output_key: \"output_examples\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"statistics\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleStatistics\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          base_type: STATISTICS\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"exclude_splits\"\n    value {\n      field_value {\n        string_value: \"[]\"\n      }\n    }\n  }\n}\nupstream_nodes: \"MovieLensExampleGen\"\ndownstream_nodes: \"SchemaGen\"\nexecution_options {\n  caching_options {\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type node and name TestPythonTransformPipeline.StatisticsGen\nDEBUG:absl:ID of context type {\n  name: \"node\"\n}\nname {\n  field_value {\n    string_value: \"TestPythonTransformPipeline.StatisticsGen\"\n  }\n}\n is 5.\nWARNING:absl:ArtifactQuery.property_predicate is not supported.\nDEBUG:absl:examples <- [\n  [NO_PARTITION]: [Examples(id=1, span=0, version=1)]\n]\nDEBUG:absl:Before conditional:\n{examples: [Examples(id=1, span=0, version=1)]}\nDEBUG:absl:After conditional:\n{examples: [Examples(id=1, span=0, version=1)]}\nINFO:absl:[StatisticsGen] Resolved inputs: ({'examples': [Artifact(artifact: id: 1\ntype_id: 15\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    int_value: 1\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Examples\"\ncreate_time_since_epoch: 1760574854913\nlast_update_time_since_epoch: 1760574854913\n, artifact_type: id: 15\nname: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]},)\nDEBUG:absl:Prepared EXECUTION:\n type_id: 16\nlast_known_state: RUNNING\ncustom_properties {\n  key: \"exclude_splits\"\n  value {\n    string_value: \"[]\"\n  }\n}\nname: \"a8f98694-edbb-4928-ba87-7f0d3596da8a\"\n\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type execution_cache and name 71f80bcedae1fa7a58b4cdc439302bd3eb90c60133a07a1945f945521a999cd2\nDEBUG:absl:ID of context type {\n  name: \"execution_cache\"\n}\nname {\n  field_value {\n    string_value: \"71f80bcedae1fa7a58b4cdc439302bd3eb90c60133a07a1945f945521a999cd2\"\n  }\n}\n is 6.\nINFO:absl:Going to run a new execution 2\nI0000 00:00:1760574854.989128    4358 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=2, input_dict={'examples': [Artifact(artifact: id: 1\ntype_id: 15\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    int_value: 1\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Examples\"\ncreate_time_since_epoch: 1760574854913\nlast_update_time_since_epoch: 1760574854913\n, artifact_type: id: 15\nname: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2\"\n, artifact_type: name: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/.system/executor_execution/2/executor_output.pb', stateful_working_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/.system/stateful_working_dir/27f0db77-ab0c-453f-a483-905e6c94ed5b', tmp_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/.system/executor_execution/2/.temp/', pipeline_node=node_info {\n  type {\n    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n    base_type: PROCESS\n  }\n  id: \"StatisticsGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-16T00:33:47.173771\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline.StatisticsGen\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"examples\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"MovieLensExampleGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-16T00:33:47.173771\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline.MovieLensExampleGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"Examples\"\n            base_type: DATASET\n          }\n        }\n        output_key: \"output_examples\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"statistics\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleStatistics\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          base_type: STATISTICS\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"exclude_splits\"\n    value {\n      field_value {\n        string_value: \"[]\"\n      }\n    }\n  }\n}\nupstream_nodes: \"MovieLensExampleGen\"\ndownstream_nodes: \"SchemaGen\"\nexecution_options {\n  caching_options {\n  }\n}\n, pipeline_info=id: \"TestPythonTransformPipeline\"\n, pipeline_run_id='2025-10-16T00:33:47.173771', top_level_pipeline_run_id=None, frontend_url=None)\nINFO:absl:Attempting to infer TFX Python dependency for beam\nINFO:absl:Copying all content from install dir /usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx to temp dir /tmp/tmp5i5sa29g/build/tfx\nINFO:absl:Generating a temp setup file at /tmp/tmp5i5sa29g/build/tfx/setup.py\nINFO:absl:Creating temporary sdist package, logs available at /tmp/tmp5i5sa29g/build/tfx/setup.log\nINFO:absl:Added --extra_package=/tmp/tmp5i5sa29g/build/tfx/dist/tfx_ephemeral-1.16.0.tar.gz to beam args\nDEBUG:absl:Starting Executor execution.\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nINFO:absl:Generating statistics for split train.\nINFO:absl:Statistics for split train written to /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-train.\nINFO:absl:Generating statistics for split eval.\nINFO:absl:Statistics for split eval written to /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-eval.\nINFO:absl:Generating statistics for split test.\nINFO:absl:Statistics for split test written to /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-test.\nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574863   nanos: 336041450 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574863   nanos: 341884851 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574863   nanos: 354985713 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574863   nanos: 361048460 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574863   nanos: 387482166 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574863   nanos: 396040439 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574863   nanos: 400759458 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574863   nanos: 410478830 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574868   nanos: 587151288 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_137\" transform_id: \"TFXIORead[eval]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-13\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574868   nanos: 589231729 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_139\" transform_id: \"TFXIORead[eval]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-14\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574868   nanos: 595603227 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_140\" transform_id: \"TFXIORead[eval]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-14\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760574868   nanos: 595603466 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_138\" transform_id: \"TFXIORead[eval]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \nINFO:absl:Cleaning up stateless execution info.\nINFO:absl:Execution 2 succeeded.\nINFO:absl:Cleaning up stateful execution info.\nINFO:absl:Deleted stateful_working_dir /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/.system/stateful_working_dir/27f0db77-ab0c-453f-a483-905e6c94ed5b\nINFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2\"\n, artifact_type: name: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)]}) for execution 2\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component StatisticsGen is finished.\nINFO:absl:Component SchemaGen is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"tfx.components.schema_gen.component.SchemaGen\"\n    base_type: PROCESS\n  }\n  id: \"SchemaGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-16T00:33:47.173771\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline.SchemaGen\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"statistics\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"StatisticsGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-16T00:33:47.173771\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline.StatisticsGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"ExampleStatistics\"\n            base_type: STATISTICS\n          }\n        }\n        output_key: \"statistics\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"schema\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Schema\"\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"exclude_splits\"\n    value {\n      field_value {\n        string_value: \"[]\"\n      }\n    }\n  }\n  parameters {\n    key: \"infer_feature_shape\"\n    value {\n      field_value {\n        int_value: 1\n      }\n    }\n  }\n}\nupstream_nodes: \"StatisticsGen\"\ndownstream_nodes: \"Transform\"\nexecution_options {\n  caching_options {\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type node and name TestPythonTransformPipeline.SchemaGen\nDEBUG:absl:ID of context type {\n  name: \"node\"\n}\nname {\n  field_value {\n    string_value: \"TestPythonTransformPipeline.SchemaGen\"\n  }\n}\n is 7.\nWARNING:absl:ArtifactQuery.property_predicate is not supported.\nDEBUG:absl:statistics <- [\n  [NO_PARTITION]: [ExampleStatistics(id=2, span=0)]\n]\nDEBUG:absl:Before conditional:\n{statistics: [ExampleStatistics(id=2, span=0)]}\nDEBUG:absl:After conditional:\n{statistics: [ExampleStatistics(id=2, span=0)]}\nINFO:absl:[SchemaGen] Resolved inputs: ({'statistics': [Artifact(artifact: id: 2\ntype_id: 17\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"sample_rate_by_split\"\n  value {\n    struct_value {\n      fields {\n        key: \"__value__\"\n        value {\n          string_value: \"{\\\"eval\\\": 1.0, \\\"test\\\": 1.0, \\\"train\\\": 1.0}\"\n        }\n      }\n    }\n  }\n}\ncustom_properties {\n  key: \"stats_dashboard_link\"\n  value {\n    string_value: \"\"\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"ExampleStatistics\"\ncreate_time_since_epoch: 1760574876831\nlast_update_time_since_epoch: 1760574876831\n, artifact_type: id: 17\nname: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)]},)\nDEBUG:absl:Prepared EXECUTION:\n type_id: 18\nlast_known_state: RUNNING\ncustom_properties {\n  key: \"exclude_splits\"\n  value {\n    string_value: \"[]\"\n  }\n}\ncustom_properties {\n  key: \"infer_feature_shape\"\n  value {\n    int_value: 1\n  }\n}\nname: \"7ded09fd-47cf-43f0-9b10-19a109a27da0\"\n\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type execution_cache and name 6ce3f922bbb82a304bf150db62cf8f1aef48d450ef1ba172f7fa4e855a8bac69\nDEBUG:absl:ID of context type {\n  name: \"execution_cache\"\n}\nname {\n  field_value {\n    string_value: \"6ce3f922bbb82a304bf150db62cf8f1aef48d450ef1ba172f7fa4e855a8bac69\"\n  }\n}\n is 8.\nINFO:absl:Going to run a new execution 3\nI0000 00:00:1760574876.901238    4358 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=3, input_dict={'statistics': [Artifact(artifact: id: 2\ntype_id: 17\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"sample_rate_by_split\"\n  value {\n    struct_value {\n      fields {\n        key: \"__value__\"\n        value {\n          string_value: \"{\\\"eval\\\": 1.0, \\\"test\\\": 1.0, \\\"train\\\": 1.0}\"\n        }\n      }\n    }\n  }\n}\ncustom_properties {\n  key: \"stats_dashboard_link\"\n  value {\n    string_value: \"\"\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"ExampleStatistics\"\ncreate_time_since_epoch: 1760574876831\nlast_update_time_since_epoch: 1760574876831\n, artifact_type: id: 17\nname: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)]}, output_dict=defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3\"\n, artifact_type: name: \"Schema\"\n)]}), exec_properties={'infer_feature_shape': 1, 'exclude_splits': '[]'}, execution_output_uri='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/.system/executor_execution/3/executor_output.pb', stateful_working_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/.system/stateful_working_dir/f8907f8a-7e9b-4c14-98c8-307411cfc5b5', tmp_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/.system/executor_execution/3/.temp/', pipeline_node=node_info {\n  type {\n    name: \"tfx.components.schema_gen.component.SchemaGen\"\n    base_type: PROCESS\n  }\n  id: \"SchemaGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-16T00:33:47.173771\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline.SchemaGen\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"statistics\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"StatisticsGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-16T00:33:47.173771\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline.StatisticsGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"ExampleStatistics\"\n            base_type: STATISTICS\n          }\n        }\n        output_key: \"statistics\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"schema\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Schema\"\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"exclude_splits\"\n    value {\n      field_value {\n        string_value: \"[]\"\n      }\n    }\n  }\n  parameters {\n    key: \"infer_feature_shape\"\n    value {\n      field_value {\n        int_value: 1\n      }\n    }\n  }\n}\nupstream_nodes: \"StatisticsGen\"\ndownstream_nodes: \"Transform\"\nexecution_options {\n  caching_options {\n  }\n}\n, pipeline_info=id: \"TestPythonTransformPipeline\"\n, pipeline_run_id='2025-10-16T00:33:47.173771', top_level_pipeline_run_id=None, frontend_url=None)\nINFO:absl:Processing schema from statistics for split train.\nINFO:absl:Processing schema from statistics for split eval.\nINFO:absl:Processing schema from statistics for split test.\nINFO:absl:Schema written to /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3/schema.pbtxt.\nINFO:absl:Cleaning up stateless execution info.\nINFO:absl:Execution 3 succeeded.\nINFO:absl:Cleaning up stateful execution info.\nINFO:absl:Deleted stateful_working_dir /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/.system/stateful_working_dir/f8907f8a-7e9b-4c14-98c8-307411cfc5b5\nINFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3\"\n, artifact_type: name: \"Schema\"\n)]}) for execution 3\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component SchemaGen is finished.\nINFO:absl:Component Transform is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"tfx.components.transform.component.Transform\"\n    base_type: TRANSFORM\n  }\n  id: \"Transform\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-16T00:33:47.173771\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline.Transform\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"examples\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"MovieLensExampleGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-16T00:33:47.173771\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline.MovieLensExampleGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"Examples\"\n            base_type: DATASET\n          }\n        }\n        output_key: \"output_examples\"\n      }\n      min_count: 1\n    }\n  }\n  inputs {\n    key: \"schema\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"SchemaGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-16T00:33:47.173771\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline.SchemaGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"Schema\"\n          }\n        }\n        output_key: \"schema\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"post_transform_anomalies\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleAnomalies\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"post_transform_schema\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Schema\"\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"post_transform_stats\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleStatistics\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          base_type: STATISTICS\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"pre_transform_schema\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Schema\"\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"pre_transform_stats\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleStatistics\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          base_type: STATISTICS\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"transform_graph\"\n    value {\n      artifact_spec {\n        type {\n          name: \"TransformGraph\"\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"transformed_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"updated_analyzer_cache\"\n    value {\n      artifact_spec {\n        type {\n          name: \"TransformCache\"\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"custom_config\"\n    value {\n      field_value {\n        string_value: \"null\"\n      }\n    }\n  }\n  parameters {\n    key: \"disable_statistics\"\n    value {\n      field_value {\n        int_value: 0\n      }\n    }\n  }\n  parameters {\n    key: \"force_tf_compat_v1\"\n    value {\n      field_value {\n        int_value: 0\n      }\n    }\n  }\n  parameters {\n    key: \"module_path\"\n    value {\n      field_value {\n        string_value: \"transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl\"\n      }\n    }\n  }\n}\nupstream_nodes: \"MovieLensExampleGen\"\nupstream_nodes: \"SchemaGen\"\nexecution_options {\n  caching_options {\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type node and name TestPythonTransformPipeline.Transform\nDEBUG:absl:ID of context type {\n  name: \"node\"\n}\nname {\n  field_value {\n    string_value: \"TestPythonTransformPipeline.Transform\"\n  }\n}\n is 9.\nWARNING:absl:ArtifactQuery.property_predicate is not supported.\nDEBUG:absl:examples <- [\n  [NO_PARTITION]: [Examples(id=1, span=0, version=1)]\n]\nWARNING:absl:ArtifactQuery.property_predicate is not supported.\nDEBUG:absl:schema <- [\n  [NO_PARTITION]: [Schema(id=3)]\n]\nDEBUG:absl:Before conditional:\n{schema: [Schema(id=3)], examples: [Examples(id=1, span=0, version=1)]}\nDEBUG:absl:After conditional:\n{schema: [Schema(id=3)], examples: [Examples(id=1, span=0, version=1)]}\nINFO:absl:[Transform] Resolved inputs: ({'schema': [Artifact(artifact: id: 3\ntype_id: 19\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3\"\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Schema\"\ncreate_time_since_epoch: 1760574876925\nlast_update_time_since_epoch: 1760574876925\n, artifact_type: id: 19\nname: \"Schema\"\n)], 'examples': [Artifact(artifact: id: 1\ntype_id: 15\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    int_value: 1\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Examples\"\ncreate_time_since_epoch: 1760574854913\nlast_update_time_since_epoch: 1760574854913\n, artifact_type: id: 15\nname: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]},)\nDEBUG:absl:Prepared EXECUTION:\n type_id: 20\nlast_known_state: RUNNING\ncustom_properties {\n  key: \"custom_config\"\n  value {\n    string_value: \"null\"\n  }\n}\ncustom_properties {\n  key: \"disable_statistics\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"force_tf_compat_v1\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"module_path\"\n  value {\n    string_value: \"transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl\"\n  }\n}\nname: \"8696a383-e1d0-444b-9902-7dff06336284\"\n\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_stats/4\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/updated_analyzer_cache/4\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_stats/4\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_schema/4\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_schema/4\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_anomalies/4\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type execution_cache and name 6eadeffd762eca90e4bc81dbf18831153ea0dbf21a5de601f0c9ca64f9230721\nDEBUG:absl:ID of context type {\n  name: \"execution_cache\"\n}\nname {\n  field_value {\n    string_value: \"6eadeffd762eca90e4bc81dbf18831153ea0dbf21a5de601f0c9ca64f9230721\"\n  }\n}\n is 10.\nINFO:absl:Going to run a new execution 4\nI0000 00:00:1760574876.998676    4358 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=4, input_dict={'schema': [Artifact(artifact: id: 3\ntype_id: 19\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3\"\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Schema\"\ncreate_time_since_epoch: 1760574876925\nlast_update_time_since_epoch: 1760574876925\n, artifact_type: id: 19\nname: \"Schema\"\n)], 'examples': [Artifact(artifact: id: 1\ntype_id: 15\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    int_value: 1\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Examples\"\ncreate_time_since_epoch: 1760574854913\nlast_update_time_since_epoch: 1760574854913\n, artifact_type: id: 15\nname: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}, output_dict=defaultdict(<class 'list'>, {'transform_graph': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4\"\n, artifact_type: name: \"TransformGraph\"\n)], 'pre_transform_stats': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_stats/4\"\n, artifact_type: name: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)], 'updated_analyzer_cache': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/updated_analyzer_cache/4\"\n, artifact_type: name: \"TransformCache\"\n)], 'transformed_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)], 'post_transform_stats': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_stats/4\"\n, artifact_type: name: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)], 'post_transform_schema': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_schema/4\"\n, artifact_type: name: \"Schema\"\n)], 'pre_transform_schema': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_schema/4\"\n, artifact_type: name: \"Schema\"\n)], 'post_transform_anomalies': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_anomalies/4\"\n, artifact_type: name: \"ExampleAnomalies\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\n)]}), exec_properties={'disable_statistics': 0, 'module_path': 'transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl', 'force_tf_compat_v1': 0, 'custom_config': 'null'}, execution_output_uri='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/.system/executor_execution/4/executor_output.pb', stateful_working_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/.system/stateful_working_dir/eaade918-600f-4a85-969e-c9fd41520bd3', tmp_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/.system/executor_execution/4/.temp/', pipeline_node=node_info {\n  type {\n    name: \"tfx.components.transform.component.Transform\"\n    base_type: TRANSFORM\n  }\n  id: \"Transform\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-16T00:33:47.173771\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline.Transform\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"examples\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"MovieLensExampleGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-16T00:33:47.173771\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline.MovieLensExampleGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"Examples\"\n            base_type: DATASET\n          }\n        }\n        output_key: \"output_examples\"\n      }\n      min_count: 1\n    }\n  }\n  inputs {\n    key: \"schema\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"SchemaGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-16T00:33:47.173771\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline.SchemaGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"Schema\"\n          }\n        }\n        output_key: \"schema\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"post_transform_anomalies\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleAnomalies\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"post_transform_schema\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Schema\"\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"post_transform_stats\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleStatistics\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          base_type: STATISTICS\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"pre_transform_schema\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Schema\"\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"pre_transform_stats\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleStatistics\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          base_type: STATISTICS\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"transform_graph\"\n    value {\n      artifact_spec {\n        type {\n          name: \"TransformGraph\"\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"transformed_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"updated_analyzer_cache\"\n    value {\n      artifact_spec {\n        type {\n          name: \"TransformCache\"\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"custom_config\"\n    value {\n      field_value {\n        string_value: \"null\"\n      }\n    }\n  }\n  parameters {\n    key: \"disable_statistics\"\n    value {\n      field_value {\n        int_value: 0\n      }\n    }\n  }\n  parameters {\n    key: \"force_tf_compat_v1\"\n    value {\n      field_value {\n        int_value: 0\n      }\n    }\n  }\n  parameters {\n    key: \"module_path\"\n    value {\n      field_value {\n        string_value: \"transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl\"\n      }\n    }\n  }\n}\nupstream_nodes: \"MovieLensExampleGen\"\nupstream_nodes: \"SchemaGen\"\nexecution_options {\n  caching_options {\n  }\n}\n, pipeline_info=id: \"TestPythonTransformPipeline\"\n, pipeline_run_id='2025-10-16T00:33:47.173771', top_level_pipeline_run_id=None, frontend_url=None)\nINFO:absl:Attempting to infer TFX Python dependency for beam\nINFO:absl:Copying all content from install dir /usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx to temp dir /tmp/tmpyz06u795/build/tfx\nINFO:absl:Generating a temp setup file at /tmp/tmpyz06u795/build/tfx/setup.py\nINFO:absl:Creating temporary sdist package, logs available at /tmp/tmpyz06u795/build/tfx/setup.log\nINFO:absl:Added --extra_package=/tmp/tmpyz06u795/build/tfx/dist/tfx_ephemeral-1.16.0.tar.gz to beam args\nDEBUG:absl:Starting Executor execution.\nINFO:absl:Analyze the 'train' split and transform all splits when splits_config is not set.\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nDEBUG:absl:Using temp path /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4/.temp_path for tft.beam\nINFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl', 'preprocessing_fn': None} 'preprocessing_fn'\nINFO:absl:Installing '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl' to a temporary directory.\nINFO:absl:Executing: ['/usr/local/envs/my_tfx_env/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmpdojj_d0n', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl']\nINFO:absl:Successfully installed '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl'.\nINFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl', 'stats_options_updater_fn': None} 'stats_options_updater_fn'\nINFO:absl:Installing '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl' to a temporary directory.\nINFO:absl:Executing: ['/usr/local/envs/my_tfx_env/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmp5xfdprfo', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl']\nINFO:absl:Successfully installed '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl'.\nINFO:absl:Installing '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl' to a temporary directory.\nINFO:absl:Executing: ['/usr/local/envs/my_tfx_env/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmp_m_inslq', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl']\nINFO:absl:Successfully installed '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl'.\nDEBUG:absl:Inputs to executor.Transform function: {'disable_statistics': False, 'schema_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3/schema.pbtxt', 'examples_data_format': 6, 'data_view_uri': None, 'analyze_data_paths': ['/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/*'], 'analyze_paths_file_formats': ['tfrecords_gzip'], 'transform_data_paths': ['/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/*', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/*', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/*'], 'transform_paths_file_formats': ['tfrecords_gzip', 'tfrecords_gzip', 'tfrecords_gzip'], 'preprocessing_fn': <function preprocessing_fn at 0x7bbc8c0c80d0>, 'stats_options_updater_fn': None, 'make_beam_pipeline_fn': <bound method BaseBeamExecutor._make_beam_pipeline of <tfx.components.transform.executor.Executor object at 0x7bbc6f71c220>>, 'force_tf_compat_v1': False, 'save_options': None}\nDEBUG:absl:Outputs to executor.Transform function: {'transform_output_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4', 'transform_materialize_output_paths': ['/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-test/transformed_examples', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-train/transformed_examples', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-eval/transformed_examples'], 'temp_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4/.temp_path', 'pre_transform_output_stats_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_stats/4', 'pre_transform_output_schema_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_schema/4', 'post_transform_output_anomalies_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_anomalies/4', 'post_transform_output_stats_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_stats/4', 'post_transform_output_schema_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_schema/4', 'cache_output_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/updated_analyzer_cache/4'}\nDEBUG:absl:Force tf.compat.v1: False\nDEBUG:absl:SaveOptions: None\nDEBUG:absl:Analyze data patterns: [(0, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/*')]\nDEBUG:absl:Transform data patterns: [(0, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/*'), (1, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/*'), (2, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/*')]\nDEBUG:absl:Transform materialization output paths: [(0, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-test/transformed_examples'), (1, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-train/transformed_examples'), (2, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-eval/transformed_examples')]\nDEBUG:absl:Transform output path: /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4\nINFO:absl:Feature gender has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature genres has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature age has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature movie_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature occupation has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature rating has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature timestamp has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature user_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nDEBUG:absl:inputs={'gender': <tf.Tensor 'inputs_copy:0' shape=(None, 1) dtype=string>, 'genres': <tf.Tensor 'inputs_1_copy:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'inputs_2_copy:0' shape=(None, 1) dtype=int64>, 'movie_id': <tf.Tensor 'inputs_3_copy:0' shape=(None, 1) dtype=int64>, 'occupation': <tf.Tensor 'inputs_4_copy:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'inputs_5_copy:0' shape=(None, 1) dtype=int64>, 'timestamp': <tf.Tensor 'inputs_6_copy:0' shape=(None, 1) dtype=int64>, 'user_id': <tf.Tensor 'inputs_7_copy:0' shape=(None, 1) dtype=int64>}\nDEBUG:absl:inputs['genres']=Tensor(\"inputs_1_copy:0\", shape=(None, 1), dtype=string)\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nERROR:absl:Execution 4 failed.\nINFO:absl:Cleaning up stateless execution info.\nEs\n======================================================================\nERROR: test_MovieLensExampleGen (transform_movie_lens_test.IngestMovieLensComponentTest)\ntransform_movie_lens_test.IngestMovieLensComponentTest.test_MovieLensExampleGen\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/tensor_util.py\", line 611, in make_tensor_proto\n    str_values = [compat.as_bytes(x) for x in proto_values]\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/tensor_util.py\", line 611, in <listcomp>\n    str_values = [compat.as_bytes(x) for x in proto_values]\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/util/compat.py\", line 81, in as_bytes\n    raise TypeError('Expected binary or unicode string, got %r' %\nTypeError: Expected binary or unicode string, got tf.RaggedTensor(values=Tensor(\"StringSplit/StringSplit/StringSplit/StringSplitV2:1\", shape=(None,), dtype=string), row_splits=Tensor(\"StringSplit/StringSplit/StringSplit/RaggedFromValueRowIds/RowPartitionFromValueRowIds/concat:0\", shape=(None,), dtype=int64))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/kaggle/working/transform_movie_lens_test.py\", line 115, in test_MovieLensExampleGen\n    tfx.orchestration.LocalDagRunner().run(my_pipeline)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/tfx_runner.py\", line 124, in run\n    return self.run_with_ir(pipeline_pb, run_options=run_options_pb, **kwargs)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/local/local_dag_runner.py\", line 109, in run_with_ir\n    component_launcher.launch()\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/launcher.py\", line 613, in launch\n    executor_output = self._run_executor(execution_info)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/launcher.py\", line 487, in _run_executor\n    executor_output = self._executor_operator.run_executor(execution_info)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/beam_executor_operator.py\", line 112, in run_executor\n    return python_executor_operator.run_with_executor(execution_info, executor)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/python_executor_operator.py\", line 84, in run_with_executor\n    result = executor.Do(\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/components/transform/executor.py\", line 641, in Do\n    TransformProcessor().Transform(label_inputs, label_outputs, status_file)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/components/transform/executor.py\", line 1216, in Transform\n    analyze_input_columns = tft.get_analyze_input_columns(\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow_transform/inspect_preprocessing_fn.py\", line 49, in get_analyze_input_columns\n    impl_helper.trace_preprocessing_function(\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow_transform/impl_helper.py\", line 441, in trace_preprocessing_function\n    return _trace_preprocessing_fn_v2(\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow_transform/impl_helper.py\", line 409, in _trace_preprocessing_fn_v2\n    preprocessing_fn, specs, tf_graph_context).get_concrete_function()\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 1251, in get_concrete_function\n    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 1221, in _get_concrete_function_garbage_collected\n    self._initialize(args, kwargs, add_initializers_to=initializers)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 696, in _initialize\n    self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 178, in trace_function\n    concrete_function = _maybe_define_function(\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 283, in _maybe_define_function\n    concrete_function = _create_concrete_function(\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 310, in _create_concrete_function\n    traced_func_graph = func_graph_module.func_graph_from_py_func(\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py\", line 1059, in func_graph_from_py_func\n    func_outputs = python_func(*func_args, **func_kwargs)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 599, in wrapped_fn\n    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow_transform/impl_helper.py\", line 365, in transform_fn\n    transformed_features = preprocessing_fn(inputs_copy)\n  File \"/kaggle/working/transform_movie_lens.py\", line 86, in preprocessing_fn\n    outputs['genres'] = transform_genres(inputs['genres'])\n  File \"/kaggle/working/transform_movie_lens.py\", line 76, in transform_genres\n    idx = genres_table.lookup(out)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/ops/lookup_ops.py\", line 259, in lookup\n    values = gen_lookup_ops.lookup_table_find_v2(self.resource_handle,\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/ops/gen_lookup_ops.py\", line 1004, in lookup_table_find_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py\", line 778, in _apply_op_helper\n    _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py\", line 559, in _ExtractInputsAndAttrs\n    raise err\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py\", line 551, in _ExtractInputsAndAttrs\n    values = ops.convert_to_tensor(\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n    return func(*args, **kwargs)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 713, in convert_to_tensor\n    return tensor_conversion_registry.convert(\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 234, in convert\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/constant_tensor_conversion.py\", line 29, in _constant_tensor_conversion_function\n    return constant_op.constant(v, dtype=dtype, name=name)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py\", line 142, in wrapper\n    return op(*args, **kwargs)\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\", line 276, in constant\n    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\", line 291, in _constant_impl\n    const_tensor = ops._create_graph_constant(  # pylint: disable=protected-access\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 276, in _create_graph_constant\n    tensor_util.make_tensor_proto(\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/tensor_util.py\", line 613, in make_tensor_proto\n    raise TypeError(f\"Failed to convert elements of {values} to Tensor. \"\nTypeError: Failed to convert elements of tf.RaggedTensor(values=Tensor(\"StringSplit/StringSplit/StringSplit/StringSplitV2:1\", shape=(None,), dtype=string), row_splits=Tensor(\"StringSplit/StringSplit/StringSplit/RaggedFromValueRowIds/RowPartitionFromValueRowIds/concat:0\", shape=(None,), dtype=int64)) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n\n----------------------------------------------------------------------\nRan 2 tests in 57.105s\n\nFAILED (errors=1, skipped=1)\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"!find /kaggle/working -type f","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T00:34:45.920803Z","iopub.execute_input":"2025-10-16T00:34:45.921134Z","iopub.status.idle":"2025-10-16T00:34:46.211424Z","shell.execute_reply.started":"2025-10-16T00:34:45.921104Z","shell.execute_reply":"2025-10-16T00:34:46.210196Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/transform_movie_lens_test.py\n/kaggle/working/ml-1m/ratings_1000.dat\n/kaggle/working/ml-1m/README\n/kaggle/working/ml-1m/users.dat\n/kaggle/working/ml-1m/movies.dat\n/kaggle/working/ml-1m/tmp/users2.dat\n/kaggle/working/ml-1m/ratings.dat\n/kaggle/working/ml-1m/users_100.dat\n/kaggle/working/csv_example_gen_test.py\n/kaggle/working/helper.py\n/kaggle/working/dataset_tfxio_example.py\n/kaggle/working/ingest_movie_lens_beam_pa.py\n/kaggle/working/CustomUTF8Coder.py\n/kaggle/working/ingest_movie_lens_beam_pa_test.py\n/kaggle/working/ingest_movie_lens_component_test.py\n/kaggle/working/movie_lens_utils_test.py\n/kaggle/working/ingest_movie_lens_component.py\n/kaggle/working/movie_lens_utils.py\n/kaggle/working/ingest_movie_lens_beam_test.py\n/kaggle/working/ingest_movie_lens_custom_component.py\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/statistics/2/Split-eval/FeatureStats.pb\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/statistics/2/Split-train/FeatureStats.pb\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/statistics/2/Split-test/FeatureStats.pb\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/SchemaGen/schema/3/schema.pbtxt\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00001-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00003-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00000-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00002-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00001-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00003-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00000-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00002-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00001-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00003-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00000-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00002-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-eval/FeatureStats.pb\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-train/FeatureStats.pb\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-test/FeatureStats.pb\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3/schema.pbtxt\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-eval/FeatureStats.pb\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-train/FeatureStats.pb\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-test/FeatureStats.pb\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/SchemaGen/schema/3/schema.pbtxt\n/kaggle/working/ingest_movie_lens_custom_component_test.py\n/kaggle/working/__pycache__/helper.cpython-310.pyc\n/kaggle/working/__pycache__/CustomUTF8Coder.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils_test.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_custom_component_test.cpython-310.pyc\n/kaggle/working/__pycache__/transform_movie_lens.cpython-310.pyc\n/kaggle/working/__pycache__/transform_movie_lens_test.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_beam.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_custom_component.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_beam_test.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_component_test.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_component.cpython-310.pyc\n/kaggle/working/__pycache__/csv_example_gen_test.cpython-310.pyc\n/kaggle/working/transform_movie_lens.py\n/kaggle/working/ingest_movie_lens_beam.py\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"!find /kaggle/working -type f","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T00:34:46.212608Z","iopub.execute_input":"2025-10-16T00:34:46.212873Z","iopub.status.idle":"2025-10-16T00:34:46.480181Z","shell.execute_reply.started":"2025-10-16T00:34:46.212846Z","shell.execute_reply":"2025-10-16T00:34:46.478947Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/transform_movie_lens_test.py\n/kaggle/working/ml-1m/ratings_1000.dat\n/kaggle/working/ml-1m/README\n/kaggle/working/ml-1m/users.dat\n/kaggle/working/ml-1m/movies.dat\n/kaggle/working/ml-1m/tmp/users2.dat\n/kaggle/working/ml-1m/ratings.dat\n/kaggle/working/ml-1m/users_100.dat\n/kaggle/working/csv_example_gen_test.py\n/kaggle/working/helper.py\n/kaggle/working/dataset_tfxio_example.py\n/kaggle/working/ingest_movie_lens_beam_pa.py\n/kaggle/working/CustomUTF8Coder.py\n/kaggle/working/ingest_movie_lens_beam_pa_test.py\n/kaggle/working/ingest_movie_lens_component_test.py\n/kaggle/working/movie_lens_utils_test.py\n/kaggle/working/ingest_movie_lens_component.py\n/kaggle/working/movie_lens_utils.py\n/kaggle/working/ingest_movie_lens_beam_test.py\n/kaggle/working/ingest_movie_lens_custom_component.py\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/statistics/2/Split-eval/FeatureStats.pb\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/statistics/2/Split-train/FeatureStats.pb\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/statistics/2/Split-test/FeatureStats.pb\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/SchemaGen/schema/3/schema.pbtxt\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+a2c8d6e721879d960c85e79ad78c0e02901eea150379add921abb39e97566696-py3-none-any.whl\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00001-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00003-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00000-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00002-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00001-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00003-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00000-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00002-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00001-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00003-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00000-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00002-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-eval/FeatureStats.pb\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-train/FeatureStats.pb\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-test/FeatureStats.pb\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3/schema.pbtxt\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-eval/FeatureStats.pb\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-train/FeatureStats.pb\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-test/FeatureStats.pb\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/SchemaGen/schema/3/schema.pbtxt\n/kaggle/working/ingest_movie_lens_custom_component_test.py\n/kaggle/working/__pycache__/helper.cpython-310.pyc\n/kaggle/working/__pycache__/CustomUTF8Coder.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils_test.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_custom_component_test.cpython-310.pyc\n/kaggle/working/__pycache__/transform_movie_lens.cpython-310.pyc\n/kaggle/working/__pycache__/transform_movie_lens_test.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_beam.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_custom_component.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_beam_test.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_component_test.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_component.cpython-310.pyc\n/kaggle/working/__pycache__/csv_example_gen_test.cpython-310.pyc\n/kaggle/working/transform_movie_lens.py\n/kaggle/working/ingest_movie_lens_beam.py\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"!pip install -q tensorflow\n!pip install -q polars[all]\n!pip install -q seaborn\n!pip install -q matplotlib\nimport tensorflow as tf\nimport polars as pl\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T00:34:46.482953Z","iopub.execute_input":"2025-10-16T00:34:46.483246Z","iopub.status.idle":"2025-10-16T00:34:51.891005Z","shell.execute_reply.started":"2025-10-16T00:34:46.483219Z","shell.execute_reply":"2025-10-16T00:34:51.889836Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"#enable/disable by toggling from Markdown to Code\n#\"\"\"\n\nprint(f\"tf.executing_eagerly()={tf.executing_eagerly()}\")\n\ntfrecord_path = \"/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00000-of-00001.tfrecord\"\n\ndef get_expected_col_name_feature_types():\n  return {\"user_id\": tf.io.FixedLenFeature([], tf.int64),\n    \"movie_id\":tf.io.FixedLenFeature([], tf.int64),\n    \"rating\" : tf.io.FixedLenFeature([], tf.int64),\n    \"timestamp\" : tf.io.FixedLenFeature([], tf.int64),\n    \"gender\" : tf.io.FixedLenFeature([], tf.string),\n    \"age\" : tf.io.FixedLenFeature([], tf.int64), \n    \"occupation\" : tf.io.FixedLenFeature([], tf.int64),\n    \"genres\" : tf.io.FixedLenFeature([], tf.string)}\n\ncol_name_feature_types = get_expected_col_name_feature_types()\n\ndef _parse_function(example_proto):\n  return tf.io.parse_single_example(example_proto, col_name_feature_types)\n\ndataset = tf.data.TFRecordDataset(tfrecord_path)\nparsed_dataset = dataset.map(_parse_function)\n\ntry:\n  for parsed_example in parsed_dataset.take(1):\n    pass\nexcept Exception as e:\n  print(e)\n\ntry:\n  for tfrecord in dataset.take(1):\n    example = tf.train.Example()\n    example.ParseFromString(tfrecord.numpy())\n    #print(f\"EXAMPLE={example}\")\nexcept Exception as e:\n  print(e)     \n\ndata_list = []\nfor record in parsed_dataset:\n    row = {\n        'user_id': record['user_id'].numpy(),\n        'movie_id': record['movie_id'].numpy(),\n        'rating': record['rating'].numpy(),\n        'age': record['age'].numpy(),\n        'occupation': record['occupation'].numpy(),\n        'genres': record['genres'].numpy().decode('utf-8'),\n        'gender': record['gender'].numpy().decode('utf-8'),\n    }\n    data_list.append(row)\n\n# Create the Polars DataFrame from the list of dictionaries\ndf = pl.from_records(data_list)\n\ngender_enum = pl.Enum(['M', 'F'])\ngenres_enum = pl.Enum([\"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n          \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\",\n          \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\",\n          \"Thriller\", \"War\", \"Western\"])\n\n#enums have to be strings\n#age_enum = pl.Enum([1, 18, 25, 35, 45, 50, 56])\n#df['age'].dtype = age_enum\n\ndf['gender'].cast(gender_enum)\n\n# after splits, can use:\n#df['genres'].cast(genres_enum)\n\ndf.null_count()\n\ndf.describe()\ndf.head()\n#\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T00:34:51.892653Z","iopub.execute_input":"2025-10-16T00:34:51.893048Z","iopub.status.idle":"2025-10-16T00:34:52.354622Z","shell.execute_reply.started":"2025-10-16T00:34:51.893006Z","shell.execute_reply":"2025-10-16T00:34:52.353827Z"}},"outputs":[{"name":"stdout","text":"tf.executing_eagerly()=True\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"shape: (5, 7)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ user_id â”† movie_id â”† rating â”† age â”† occupation â”† genres                       â”† gender â”‚\nâ”‚ ---     â”† ---      â”† ---    â”† --- â”† ---        â”† ---                          â”† ---    â”‚\nâ”‚ i64     â”† i64      â”† i64    â”† i64 â”† i64        â”† str                          â”† str    â”‚\nâ•žâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡\nâ”‚ 6       â”† 1        â”† 4      â”† 50  â”† 9          â”† Animation|Children's|Comedy  â”† F      â”‚\nâ”‚ 8       â”† 1        â”† 4      â”† 25  â”† 12         â”† Animation|Children's|Comedy  â”† M      â”‚\nâ”‚ 9       â”† 1        â”† 5      â”† 25  â”† 17         â”† Animation|Children's|Comedy  â”† M      â”‚\nâ”‚ 10      â”† 2        â”† 5      â”† 35  â”† 1          â”† Adventure|Children's|Fantasy â”† F      â”‚\nâ”‚ 8       â”† 4        â”† 3      â”† 25  â”† 12         â”† Comedy|Drama                 â”† M      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>movie_id</th><th>rating</th><th>age</th><th>occupation</th><th>genres</th><th>gender</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>6</td><td>1</td><td>4</td><td>50</td><td>9</td><td>&quot;Animation|Children&#x27;s|Comedy&quot;</td><td>&quot;F&quot;</td></tr><tr><td>8</td><td>1</td><td>4</td><td>25</td><td>12</td><td>&quot;Animation|Children&#x27;s|Comedy&quot;</td><td>&quot;M&quot;</td></tr><tr><td>9</td><td>1</td><td>5</td><td>25</td><td>17</td><td>&quot;Animation|Children&#x27;s|Comedy&quot;</td><td>&quot;M&quot;</td></tr><tr><td>10</td><td>2</td><td>5</td><td>35</td><td>1</td><td>&quot;Adventure|Children&#x27;s|Fantasy&quot;</td><td>&quot;F&quot;</td></tr><tr><td>8</td><td>4</td><td>3</td><td>25</td><td>12</td><td>&quot;Comedy|Drama&quot;</td><td>&quot;M&quot;</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":41},{"cell_type":"markdown","source":"#EDA for raw data\nfrom collections import OrderedDict\nimport re\nimport io\nfrom datetime import datetime\nimport pytz\n\nCTZ = pytz.timezone(\"America/Chicago\")\ngenres = [\"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n          \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\",\n          \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\",\n          \"Thriller\", \"War\", \"Western\"]\n\nschemas = {\n  'ratings' : pl.Schema(OrderedDict({'user_id': pl.Int64, \n    'movie_id': pl.Int64, 'rating': pl.Int64,\n    'timestamp' : pl.Int64})),\n  'users' : pl.Schema(OrderedDict({'user_id': pl.Int64, \n    'gender': pl.String, 'age': pl.Int64,\n    'occupation' : pl.Int64, \n    'zipcode' : pl.String})),\n  'movies' : pl.Schema(OrderedDict({'movie_id': pl.Int64, \n    'title': pl.String, 'genres': pl.String}))}\n\nfile_paths = {\n  'ratings':'/kaggle/working/ml-1m/ratings.dat',\n  'users':'/kaggle/working/ml-1m/users.dat',\n  'movies':'/kaggle/working/ml-1m/movies.dat'\n}\n\n#polars.read_csv( source=\n#  encoding='iso-8859-1', \n#  has_header=False, skip_rows=0, try_parse_dates=True, \n#  use_pyarrow=True\n\nlabels_dict = {}\nlabels_dict['age_group'] = {0:'1', 1:'18', 2:'25', 3:'35', 4:'45', 5:'50', 6:'56'} \nlabels_dict['gender'] = {0:'F', 1:'M'}\nlabels_dict['occupation'] = {0:  \"other\", 1:  \"academic/educator\", 2:  \"artist\", 3:  \"clerical/admin\", 4:  \"college/grad student\", 5:  \"customer service\", \\\n    6:  \"doctor/health care\", 7:  \"executive/managerial\", 8:  \"farmer\", 9:  \"homemaker\", 10:  \"K-12 student\", 11:  \"lawyer\", 12:  \"programmer\", \\\n    13:  \"retired\", 14:  \"sales/marketing\", 15:  \"scientist\", 16:  \"self-employed\", 17:  \"technician/engineer\", 18:  \"tradesman/craftsman\", \\\n    19:  \"unemployed\", 20:  \"writer\"}\nlabels_dict_arrays = {}\nfor k in labels_dict:\n    labels_dict_arrays[k]=[labels_dict[k][k2] for k2 in labels_dict[k]]\n\ndfs = {}\nfor key in file_paths:\n    processed_buffer = io.StringIO()\n    file_path = file_paths[key]\n    schema = schemas[key]\n    print(f\"key={key}, file_path={file_path}\")\n    with open(file_path, \"r\") as file:\n        for line in file:\n            line2 = line.replace('::', '\\t')\n            processed_buffer.write(line2)\n    \n    dfs[key] = df\n    processed_buffer.seek(0)\n    df = pl.read_csv(processed_buffer,\\\n        encoding='iso-8859-1', has_header=False, \\\n        skip_rows=0, separator='\\t', schema=schema,\\\n        try_parse_dates=True, \\\n        new_columns=schema.names(), \\\n        use_pyarrow=True)\n\n    if key==\"movies\":\n        df = df.with_columns(\n          pl.col(\"genres\").str.replace(\"Children's\", \"Children\")\n        )\n        df = df.with_columns(\n          pl.col(\"genres\").str.split(\"|\")\n        )\n        movie_genres = df.explode('genres')\n        ordered = movie_genres['genres'].value_counts().index\n        sns.catplot(data=movie_genres, y=\"genres\",  \n          kind=\"count\", order=ordered).set(title='Movie genres')\n        plt.show()\n                  \n    if key==\"ratings\":\n        #user_id, movie_id, rating, timestamp\n        g = sns.catplot(data=df, x='rating',  kind=\"count\").set(title='rating')\n        local_time = datetime.fromtimestamp(df[\"timestamp\"], tz=CTZ)\n        df[\"hr\"] = int(round(local_time.hour + (local_time.minute / 60.)))\n        df[\"weekday\"] = local_time.weekday()\n        df[\"hr_wk\"] = df[\"hr\"] * 7 + df[\"weekday\"]\n        g = sns.catplot(data=df, x='hr',  kind=\"count\").set(title='hr of day')\n        g = sns.catplot(data=df, x='weekday',  kind=\"count\").set(title='weekday')\n        g = sns.catplot(data=df, x='hr_wk',  kind=\"count\").set(title='hr of weekday')\n        plt.show()\n\n    if key==\"users\":\n        #user_id, gender, age, occupation, zipcode\n        g = sns.catplot(data=df, x='gender',  kind=\"count\").set(title='gender')\n        g = sns.catplot(data=df, x='age',  kind=\"count\").set(title='age')\n        g = sns.catplot(data=df, x='occupation',  kind=\"count\").set(title='occupation')\n        plt.show()\n        \n\n\n#TODO then plot joined ratings\n#  then plot transformed joined ratings\n","metadata":{"execution":{"iopub.status.busy":"2025-10-16T00:34:52.355651Z","iopub.execute_input":"2025-10-16T00:34:52.356002Z","iopub.status.idle":"2025-10-16T00:34:53.010588Z","shell.execute_reply.started":"2025-10-16T00:34:52.355974Z","shell.execute_reply":"2025-10-16T00:34:53.009302Z"}}}]}