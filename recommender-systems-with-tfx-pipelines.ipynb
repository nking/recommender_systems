{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here're several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:36:11.298500Z","iopub.execute_input":"2025-10-16T21:36:11.299173Z","iopub.status.idle":"2025-10-16T21:36:11.318231Z","shell.execute_reply.started":"2025-10-16T21:36:11.299138Z","shell.execute_reply":"2025-10-16T21:36:11.316914Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Recommender System with TFX pipelines\nThe notebook builds MLOps components and pipelines using TFX for the recommender system [here.](https://www.kaggle.com/code/nicholeasuniquename/recommender-systems/)\n\n1. Create a virtual environment for TFX compatability\n2. Build the TFX components and upload to the public repository.\n3. Download the components and test them in the virtual environment here.\n4. EDA plots of raw data, joined data, and transformed data\n5. Build the MLOps pipelines, upload to public repository.\n6. Download the pipelines and test in the virtual environment here.\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Creating the TFX compatible virtual environment\n\ntfx version 1.16.0 is latest stable as of Sep 28, 2025\n\nIt is compatible with python 3.9 and 3.10 only.\n\nThe current kaggle python docker image uses python 3.11.13.\n\nTo use an earlier version of python on Kaggle, one can install conda and create a virtual environment that is based on an earlier version of python. \n\nOnce conda is installed and a virtual environment is created for the earlier version of python, the virtual environment can be activated by activating conda and then activating the virtual environment.\n\nA bash shell in the notebook that is invoked from the magic command %%bash is a bash session for the extent of that specific cell.\nFor each new session invoked by the cell %%bash, the 2 activation commands need to be invoked before using the virtual environment.\n\nAside from running scripts in the magic bash shell cells, we can also run scripts using the python subprocess library as long as we prepend commands with the 2 conda activation statements (see details in the definition for the run_command below).\n\nWe have 2 ways to run commands within the virtual environment.\n\nThe notebook itself is still using the kaggle docker image environment without the newly built virtual environment.\nEven if we install and use ipykernel to register a kernel for the new virtual environment, I don't see a way to open the notebook to use the new kernel.  (In the Kaggle window, we have Session options, persistence option to persist files and variables, so it might be possible to restart the notebook with kernel selected as long as the kernel has Kaggle specific notebook support...)\n\nIn summary, the notebook as is can be used for intermediate steps of EDA where the EDA uses libraries that don't require an earlier version of python.  For MLOps steps that need an earlier version of python, the virtual environment is available.\n","metadata":{}},{"cell_type":"code","source":"!pwd\n!echo $HOME","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:36:11.320926Z","iopub.execute_input":"2025-10-16T21:36:11.321439Z","iopub.status.idle":"2025-10-16T21:36:11.623885Z","shell.execute_reply.started":"2025-10-16T21:36:11.321396Z","shell.execute_reply":"2025-10-16T21:36:11.622088Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n/root\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"%%bash: Executes the entire cell as a shell script. ","metadata":{}},{"cell_type":"code","source":"%%bash\nt0=$(date +%s%N)\nmkdir -p ~/miniconda3\nwget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n#install conda and activate to /usr/local\nbash ~/miniconda3/miniconda.sh -b -u -p /usr/local\nrm ~/miniconda3/miniconda.sh\nconda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\nconda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n\n. /usr/local/bin/activate\necho \"**$SHELL**\"\necho \"**$BASH**\"\nconda init --all\n\n. /root/.bashrc\nconda create -q --name my_tfx_env python=3.10 -y\nconda activate my_tfx_env\npython --version\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:36:11.627709Z","iopub.execute_input":"2025-10-16T21:36:11.628074Z","iopub.status.idle":"2025-10-16T21:37:00.773297Z","shell.execute_reply.started":"2025-10-16T21:36:11.628039Z","shell.execute_reply":"2025-10-16T21:37:00.771442Z"}},"outputs":[{"name":"stdout","text":"PREFIX=/usr/local\nUnpacking bootstrapper...\nUnpacking payload...\n\nInstalling base environment...\n\nPreparing transaction: ...working... done\nExecuting transaction: ...working... done\ninstallation finished.\nWARNING:\n    You currently have a PYTHONPATH environment variable set. This may cause\n    unexpected behavior when running the Python interpreter in Miniconda3.\n    For best results, please verify that your PYTHONPATH only points to\n    directories of packages that are compatible with the Python interpreter\n    in Miniconda3: /usr/local\naccepted Terms of Service for https://repo.anaconda.com/pkgs/main\naccepted Terms of Service for https://repo.anaconda.com/pkgs/r\n**/bin/bash**\n**/usr/bin/bash**\nno change     /usr/local/condabin/conda\nno change     /usr/local/bin/conda\nno change     /usr/local/bin/conda-env\nno change     /usr/local/bin/activate\nno change     /usr/local/bin/deactivate\nno change     /usr/local/etc/profile.d/conda.sh\nno change     /usr/local/etc/fish/conf.d/conda.fish\nno change     /usr/local/shell/condabin/Conda.psm1\nno change     /usr/local/shell/condabin/conda-hook.ps1\nno change     /usr/local/lib/python3.13/site-packages/xontrib/conda.xsh\nno change     /usr/local/etc/profile.d/conda.csh\nmodified      /root/.bashrc\nmodified      /root/.zshrc\nmodified      /root/.config/fish/config.fish\nmodified      /root/.xonshrc\nmodified      /root/.tcshrc\n\n==> For changes to take effect, close and re-open your current shell. <==\n\n2 channel Terms of Service accepted\nRetrieving notices: ...working... done\nChannels:\n - defaults\nPlatform: linux-64\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\n## Package Plan ##\n\n  environment location: /usr/local/envs/my_tfx_env\n\n  added / updated specs:\n    - python=3.10\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2025.9.9   |       h06a4308_0         127 KB\n    ld_impl_linux-64-2.44      |       h153f514_2         672 KB\n    libzlib-1.3.1              |       hb25bd0a_0          59 KB\n    openssl-3.0.18             |       hd6dcaed_0         4.5 MB\n    pip-25.2                   |     pyhc872135_1         1.1 MB\n    python-3.10.18             |       h1a3bd86_0        26.5 MB\n    setuptools-80.9.0          |  py310h06a4308_0         1.4 MB\n    wheel-0.45.1               |  py310h06a4308_0         115 KB\n    zlib-1.3.1                 |       hb25bd0a_0          96 KB\n    ------------------------------------------------------------\n                                           Total:        34.6 MB\n\nThe following NEW packages will be INSTALLED:\n\n  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 \n  ca-certificates    pkgs/main/linux-64::ca-certificates-2025.9.9-h06a4308_0 \n  expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 \n  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.44-h153f514_2 \n  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n  libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 \n  libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 \n  libzlib            pkgs/main/linux-64::libzlib-1.3.1-hb25bd0a_0 \n  ncurses            pkgs/main/linux-64::ncurses-6.5-h7934f7d_0 \n  openssl            pkgs/main/linux-64::openssl-3.0.18-hd6dcaed_0 \n  pip                pkgs/main/noarch::pip-25.2-pyhc872135_1 \n  pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 \n  python             pkgs/main/linux-64::python-3.10.18-h1a3bd86_0 \n  readline           pkgs/main/linux-64::readline-8.3-hc2a1206_0 \n  setuptools         pkgs/main/linux-64::setuptools-80.9.0-py310h06a4308_0 \n  sqlite             pkgs/main/linux-64::sqlite-3.50.2-hb25bd0a_1 \n  tk                 pkgs/main/linux-64::tk-8.6.15-h54e0aa7_0 \n  tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 \n  wheel              pkgs/main/linux-64::wheel-0.45.1-py310h06a4308_0 \n  xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 \n  xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 \n  xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 \n  xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 \n  xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n  zlib               pkgs/main/linux-64::zlib-1.3.1-hb25bd0a_0 \n\n\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\nPython 3.10.18\n49.104224522 seconds\nThu Oct 16 09:37:00 PM UTC 2025\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"to activate the conda environment, need to source from conda's activate (which I installed in /usr/local/bin above), then activate the conda virtual environment.\n\nthis has to be done for each magic shell cell","metadata":{}},{"cell_type":"code","source":"%%bash\nt0=$(date +%s%N)\n. /usr/local/bin/activate\nconda activate my_tfx_env\npython --version\n\n#consider conda install ipykernel\nconda install pip\n\n#conda config --add channels conda-forge\n#conda config --set channel_priority strict\n#conda install python-snappy\n# or:\n#conda install anaconda::python-snappy\n\n#see dependencies https://github.com/tensorflow/transform\npip -q install pyarrow==10.0.1\npip -q install apache-beam==2.59.0\npip -q install tensorflow==2.16.1\npip -q install tensorflow-transform==1.16.0\npip -q install tfx==1.16.0\npip -q install tensorflow-data-validation==1.16.1\npip -q install pytest\n# installs:\n#tf metadata 1.16.1\n#tfx-bsl 1.16.1\n#arrow 1.3.0\n#keeps protobuf 3.20.3\n\n#The Spark runner currently supports Sparkâ€™s 3.2.x branch.\n#Apache Beam Prism Runner. \n\n\npip list\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 60000000000\" | bc)\necho \"$t2 minutes\"\ndate\n#about 6-7 minutes for this cell.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:37:00.774656Z","iopub.execute_input":"2025-10-16T21:37:00.775042Z","iopub.status.idle":"2025-10-16T21:45:01.469574Z","shell.execute_reply.started":"2025-10-16T21:37:00.774980Z","shell.execute_reply":"2025-10-16T21:45:01.467687Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\n2 channel Terms of Service accepted\nChannels:\n - defaults\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n# All requested packages already installed.\n\nPackage                            Version\n---------------------------------- --------------\nabsl-py                            1.4.0\nannotated-types                    0.7.0\nanyio                              4.11.0\napache-beam                        2.59.0\nargon2-cffi                        25.1.0\nargon2-cffi-bindings               25.1.0\narrow                              1.3.0\nastunparse                         1.6.3\nasync-lru                          2.0.5\nasync-timeout                      5.0.1\nattrs                              23.2.0\nbabel                              2.17.0\nbackcall                           0.2.0\nbeautifulsoup4                     4.14.2\nbleach                             6.2.0\ncachetools                         5.5.2\ncertifi                            2025.10.5\ncffi                               2.0.0\ncharset-normalizer                 3.4.4\nclick                              8.3.0\ncloudpickle                        2.2.1\ncolorama                           0.4.6\ncomm                               0.2.3\ncrcmod                             1.7\ndebugpy                            1.8.17\ndecorator                          5.2.1\ndefusedxml                         0.7.1\ndill                               0.3.1.1\ndnspython                          2.8.0\ndocker                             7.1.0\ndocopt                             0.6.2\ndocstring_parser                   0.17.0\nexceptiongroup                     1.3.0\nfastavro                           1.12.1\nfasteners                          0.20\nfastjsonschema                     2.21.2\nflatbuffers                        25.9.23\nfqdn                               1.5.1\ngast                               0.6.0\ngoogle-api-core                    2.26.0\ngoogle-api-python-client           1.12.11\ngoogle-apitools                    0.5.31\ngoogle-auth                        2.41.1\ngoogle-auth-httplib2               0.2.0\ngoogle-cloud-aiplatform            1.121.0\ngoogle-cloud-bigquery              3.38.0\ngoogle-cloud-bigquery-storage      2.33.1\ngoogle-cloud-bigtable              2.33.0\ngoogle-cloud-core                  2.4.3\ngoogle-cloud-datastore             2.21.0\ngoogle-cloud-dlp                   3.32.0\ngoogle-cloud-language              2.17.2\ngoogle-cloud-pubsub                2.31.1\ngoogle-cloud-pubsublite            1.12.0\ngoogle-cloud-recommendations-ai    0.10.18\ngoogle-cloud-resource-manager      1.14.2\ngoogle-cloud-spanner               3.58.0\ngoogle-cloud-storage               2.19.0\ngoogle-cloud-videointelligence     2.16.2\ngoogle-cloud-vision                3.10.2\ngoogle-crc32c                      1.7.1\ngoogle-genai                       1.45.0\ngoogle-pasta                       0.2.0\ngoogle-resumable-media             2.7.2\ngoogleapis-common-protos           1.70.0\ngrpc-google-iam-v1                 0.14.3\ngrpc-interceptor                   0.15.4\ngrpcio                             1.75.1\ngrpcio-status                      1.49.0rc1\nh11                                0.16.0\nh5py                               3.15.1\nhdfs                               2.7.3\nhttpcore                           1.0.9\nhttplib2                           0.22.0\nhttpx                              0.28.1\nidna                               3.11\nimportlib_metadata                 8.7.0\niniconfig                          2.1.0\nipykernel                          7.0.1\nipython                            7.34.0\nipython-genutils                   0.2.0\nipywidgets                         7.8.5\nisoduration                        20.11.0\njedi                               0.19.2\nJinja2                             3.1.6\njoblib                             1.5.2\nJs2Py                              0.74\njson5                              0.12.1\njsonpickle                         3.4.2\njsonpointer                        3.0.0\njsonschema                         4.25.1\njsonschema-specifications          2025.9.1\njupyter_client                     8.6.3\njupyter_core                       5.9.1\njupyter-events                     0.12.0\njupyter-lsp                        2.3.0\njupyter_server                     2.17.0\njupyter_server_terminals           0.5.3\njupyterlab                         4.4.9\njupyterlab_pygments                0.3.0\njupyterlab_server                  2.27.3\njupyterlab_widgets                 1.1.11\nkeras                              3.11.3\nkeras-tuner                        1.4.7\nkt-legacy                          1.0.5\nkubernetes                         26.1.0\nlark                               1.3.0\nlibclang                           18.1.1\nlxml                               6.0.2\nMarkdown                           3.9\nmarkdown-it-py                     4.0.0\nMarkupSafe                         3.0.3\nmatplotlib-inline                  0.1.7\nmdurl                              0.1.2\nmistune                            3.1.4\nml-dtypes                          0.3.2\nml-metadata                        1.16.0\nml-pipelines-sdk                   1.16.0\nnamex                              0.1.0\nnbclient                           0.10.2\nnbconvert                          7.16.6\nnbformat                           5.10.4\nnest-asyncio                       1.6.0\nnltk                               3.9.2\nnotebook                           7.4.7\nnotebook_shim                      0.2.4\nnumpy                              1.26.4\noauth2client                       4.1.3\noauthlib                           3.3.1\nobjsize                            0.7.1\nopentelemetry-api                  1.38.0\nopentelemetry-sdk                  1.38.0\nopentelemetry-semantic-conventions 0.59b0\nopt_einsum                         3.4.0\noptree                             0.17.0\norjson                             3.11.3\noverrides                          7.7.0\npackaging                          25.0\npandas                             1.5.3\npandocfilters                      1.5.1\nparso                              0.8.5\npexpect                            4.9.0\npickleshare                        0.7.5\npillow                             12.0.0\npip                                25.2\nplatformdirs                       4.5.0\npluggy                             1.6.0\nportalocker                        3.2.0\nportpicker                         1.6.0\nprometheus_client                  0.23.1\nprompt_toolkit                     3.0.52\nproto-plus                         1.26.1\nprotobuf                           3.20.3\npsutil                             7.1.0\nptyprocess                         0.7.0\npyarrow                            10.0.1\npyarrow-hotfix                     0.7\npyasn1                             0.6.1\npyasn1_modules                     0.4.2\npycparser                          2.23\npydantic                           2.12.2\npydantic_core                      2.41.4\npydot                              1.4.2\npyfarmhash                         0.3.2\nPygments                           2.19.2\npyjsparser                         2.7.1\nPyJWT                              2.10.1\npymongo                            4.15.3\npyparsing                          3.2.5\npytest                             8.4.2\npython-dateutil                    2.9.0.post0\npython-json-logger                 4.0.0\npytz                               2025.2\nPyYAML                             6.0.3\npyzmq                              27.1.0\nredis                              5.3.1\nreferencing                        0.37.0\nregex                              2025.9.18\nrequests                           2.32.5\nrequests-oauthlib                  2.0.0\nrfc3339-validator                  0.1.4\nrfc3986-validator                  0.1.1\nrfc3987-syntax                     1.1.0\nrich                               14.2.0\nrouge_score                        0.1.2\nrpds-py                            0.27.1\nrsa                                4.9.1\nsacrebleu                          2.5.1\nscikit-learn                       1.5.1\nscipy                              1.12.0\nSend2Trash                         1.8.3\nsetuptools                         80.9.0\nshapely                            2.1.2\nsix                                1.17.0\nsniffio                            1.3.1\nsoupsieve                          2.8\nsqlparse                           0.5.3\ntabulate                           0.9.0\ntenacity                           9.1.2\ntensorboard                        2.16.2\ntensorboard-data-server            0.7.2\ntensorflow                         2.16.1\ntensorflow-data-validation         1.16.1\ntensorflow-estimator               2.15.0\ntensorflow-hub                     0.15.0\ntensorflow-io-gcs-filesystem       0.37.1\ntensorflow-metadata                1.16.1\ntensorflow_model_analysis          0.47.1\ntensorflow-serving-api             2.16.1\ntensorflow-transform               1.16.0\ntermcolor                          3.1.0\nterminado                          0.18.1\ntf_keras                           2.16.0\ntfx                                1.16.0\ntfx-bsl                            1.16.1\nthreadpoolctl                      3.6.0\ntinycss2                           1.4.0\ntomli                              2.3.0\ntornado                            6.5.2\ntqdm                               4.67.1\ntraitlets                          5.14.3\ntypes-python-dateutil              2.9.0.20251008\ntyping_extensions                  4.15.0\ntyping-inspection                  0.4.2\ntzlocal                            5.3.1\nuri-template                       1.3.0\nuritemplate                        3.0.1\nurllib3                            2.5.0\nwcwidth                            0.2.14\nwebcolors                          24.11.1\nwebencodings                       0.5.1\nwebsocket-client                   1.9.0\nwebsockets                         15.0.1\nWerkzeug                           3.1.3\nwheel                              0.45.1\nwidgetsnbextension                 3.6.10\nwrapt                              1.17.3\nzipp                               3.23.0\nzstandard                          0.25.0\n8.010859041 minutes\nThu Oct 16 09:45:01 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"\n\n==> WARNING: A newer version of conda exists. <==\n    current version: 25.7.0\n    latest version: 25.9.1\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n  DEPRECATION: Building 'crcmod' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'crcmod'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'dill' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'dill'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'hdfs' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'hdfs'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'pyjsparser' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pyjsparser'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'docopt' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'docopt'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'google-apitools' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'google-apitools'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'pyfarmhash' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pyfarmhash'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n  DEPRECATION: Building 'rouge-score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge-score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!java --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:45:01.475766Z","iopub.execute_input":"2025-10-16T21:45:01.476232Z","iopub.status.idle":"2025-10-16T21:45:02.108065Z","shell.execute_reply.started":"2025-10-16T21:45:01.476183Z","shell.execute_reply":"2025-10-16T21:45:02.105224Z"}},"outputs":[{"name":"stdout","text":"openjdk 11.0.27 2025-04-15\nOpenJDK Runtime Environment (build 11.0.27+6-post-Ubuntu-0ubuntu122.04)\nOpenJDK 64-Bit Server VM (build 11.0.27+6-post-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"%%bash\n. /usr/local/bin/activate\nconda activate my_tfx_env\npython --version\npip show apache-beam\n\n#refresh the test dirs\nrm -rf /kaggle/working/bin/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:45:02.109306Z","iopub.execute_input":"2025-10-16T21:45:02.109820Z","iopub.status.idle":"2025-10-16T21:45:05.212153Z","shell.execute_reply.started":"2025-10-16T21:45:02.109785Z","shell.execute_reply":"2025-10-16T21:45:05.211125Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nName: apache-beam\nVersion: 2.59.0\nSummary: Apache Beam SDK for Python\nHome-page: https://beam.apache.org\nAuthor: Apache Software Foundation\nAuthor-email: dev@beam.apache.org\nLicense: Apache License, Version 2.0\nLocation: /usr/local/envs/my_tfx_env/lib/python3.10/site-packages\nRequires: cloudpickle, crcmod, dill, fastavro, fasteners, grpcio, hdfs, httplib2, js2py, jsonpickle, jsonschema, numpy, objsize, orjson, packaging, proto-plus, protobuf, pyarrow, pyarrow-hotfix, pydot, pymongo, python-dateutil, pytz, redis, regex, requests, typing-extensions, zstandard\nRequired-by: tensorflow-data-validation, tensorflow-transform, tensorflow_model_analysis, tfx, tfx-bsl\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"The run_command is from\nhttps://www.kaggle.com/code/taylorsamarel/change-python-version-kaggle-v2-taylor-amarel","metadata":{}},{"cell_type":"code","source":"import subprocess\ndef run_command(cmd, capture=True, check=False):\n    cmds = f\". /usr/local/bin/activate; conda activate my_tfx_env; {cmd}\"\n    try:\n        result = subprocess.run(cmds, shell=True, capture_output=capture, text=True, check=check)\n        if capture:\n            return result.stdout.strip() if result.stdout else result.stderr.strip()\n        return result.returncode == 0\n    except Exception as e:\n        return str(e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:45:05.213379Z","iopub.execute_input":"2025-10-16T21:45:05.213717Z","iopub.status.idle":"2025-10-16T21:45:05.221856Z","shell.execute_reply.started":"2025-10-16T21:45:05.213687Z","shell.execute_reply":"2025-10-16T21:45:05.220604Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(run_command(\"python --version\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:45:05.223115Z","iopub.execute_input":"2025-10-16T21:45:05.223410Z","iopub.status.idle":"2025-10-16T21:45:07.114512Z","shell.execute_reply.started":"2025-10-16T21:45:05.223385Z","shell.execute_reply":"2025-10-16T21:45:07.113211Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### 1.a. Download a TFX test script and test that the library versions are compatible","metadata":{}},{"cell_type":"code","source":"%%bash\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\n#it can take a couple of minutes to get current version of recently uploaded file to github\n#wget -q -c --no-cache https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/main/src/test/python/test_tft.py -O /kaggle/working/test_tft.py\n#curl --header \"Cache-Control: no-cache\" \"https://api.github.com/repos/nking/recommender_systems/content/src/test/python/test_tft.py\" -o /kaggle/working/test_tft.py\n\nrm -f /kaggle/working/dataset_tfxio_example.py\nwget -q -c --no-cache https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/main/src/test/python/dataset_tfxio_example.py -O /kaggle/working/dataset_tfxio_example.py\n\nls -l /kaggle/working\n\n#run a test example from Google's TFX codebase:\npython3 /kaggle/working/dataset_tfxio_example.py\n\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:45:07.115975Z","iopub.execute_input":"2025-10-16T21:45:07.116808Z","iopub.status.idle":"2025-10-16T21:45:21.770203Z","shell.execute_reply.started":"2025-10-16T21:45:07.116771Z","shell.execute_reply":"2025-10-16T21:45:21.768835Z"}},"outputs":[{"name":"stdout","text":"total 4\n-rw-r--r-- 1 root root 2392 Oct 16 21:45 dataset_tfxio_example.py\n{'x_centered': [[-4.0], [-3.0], [-2.0], [-1.0], [0.0]],\n 'x_scaled': [[0.0], [0.125], [0.25], [0.375], [0.5]]}\n{'x_centered': [[1.0], [2.0], [3.0], [4.0]],\n 'x_scaled': [[0.625], [0.75], [0.875], [1.0]]}\nThu Oct 16 09:45:21 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"I1016 21:45:16.418321 138325445830464 pipeline.py:197] Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\nI1016 21:45:18.620950 138325445830464 statecache.py:214] Creating state cache with size 104857600\nI1016 21:45:18.850756 138325445830464 functional_saver.py:438] Sharding callback duration: 8\nI1016 21:45:18.890327 138325445830464 functional_saver.py:438] Sharding callback duration: 8\nINFO:tensorflow:Assets written to: /tmp/tmp3t77yz6b/tftransform_tmp/3d4d747a263e4a678bd82bda78b38685/assets\nI1016 21:45:18.924497 138325445830464 builder_impl.py:829] Assets written to: /tmp/tmp3t77yz6b/tftransform_tmp/3d4d747a263e4a678bd82bda78b38685/assets\nI1016 21:45:18.926936 138325445830464 fingerprinting_utils.py:49] Writing fingerprint to /tmp/tmp3t77yz6b/tftransform_tmp/3d4d747a263e4a678bd82bda78b38685/fingerprint.pb\nINFO:tensorflow:struct2tensor is not available.\nI1016 21:45:19.316430 138325445830464 saved_transform_io.py:166] struct2tensor is not available.\nINFO:tensorflow:tensorflow_decision_forests is not available.\nI1016 21:45:19.316861 138325445830464 saved_transform_io.py:166] tensorflow_decision_forests is not available.\nINFO:tensorflow:tensorflow_text is not available.\nI1016 21:45:19.317180 138325445830464 saved_transform_io.py:166] tensorflow_text is not available.\nI1016 21:45:19.867407 138325445830464 functional_saver.py:438] Sharding callback duration: 8\nI1016 21:45:19.902832 138325445830464 functional_saver.py:438] Sharding callback duration: 7\nINFO:tensorflow:Assets written to: /tmp/tmp3t77yz6b/tftransform_tmp/30585c6ebcc048bf9223c2c56d8f354f/assets\nI1016 21:45:19.926483 138325445830464 builder_impl.py:829] Assets written to: /tmp/tmp3t77yz6b/tftransform_tmp/30585c6ebcc048bf9223c2c56d8f354f/assets\nI1016 21:45:19.928676 138325445830464 fingerprinting_utils.py:49] Writing fingerprint to /tmp/tmp3t77yz6b/tftransform_tmp/30585c6ebcc048bf9223c2c56d8f354f/fingerprint.pb\nI1016 21:45:20.000531 138325445830464 tensor_representation_util.py:450] Feature x_centered has a shape . Setting to DenseTensor.\nI1016 21:45:20.000822 138325445830464 tensor_representation_util.py:450] Feature x_scaled has a shape . Setting to DenseTensor.\nINFO:tensorflow:struct2tensor is not available.\nI1016 21:45:20.168965 138325445830464 saved_transform_io.py:166] struct2tensor is not available.\nINFO:tensorflow:tensorflow_decision_forests is not available.\nI1016 21:45:20.169418 138325445830464 saved_transform_io.py:166] tensorflow_decision_forests is not available.\nINFO:tensorflow:tensorflow_text is not available.\nI1016 21:45:20.169669 138325445830464 saved_transform_io.py:166] tensorflow_text is not available.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## 1.b. Download a MovieLens dataset","metadata":{}},{"cell_type":"code","source":"%%bash\nwget -q http://files.grouplens.org/datasets/movielens/ml-1m.zip -O /kaggle/working/ml-1m.zip\nunzip -o /kaggle/working/ml-1m.zip\nls /kaggle/working/ml-1m/\nrm /kaggle/working/ml-1m.zip\n\nhead -n 5 /kaggle/working/ml-1m/ratings.dat\nhead -n 5 /kaggle/working/ml-1m/users.dat\nhead -n 5 /kaggle/working/ml-1m/movies.dat\n\n#making small subsets for tests\nhead -n 1000 /kaggle/working/ml-1m/ratings.dat > /kaggle/working/ml-1m/ratings_1000.dat\nhead -n 100 /kaggle/working/ml-1m/users.dat > /kaggle/working/ml-1m/users_100.dat\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:45:21.771543Z","iopub.execute_input":"2025-10-16T21:45:21.772444Z","iopub.status.idle":"2025-10-16T21:45:22.915533Z","shell.execute_reply.started":"2025-10-16T21:45:21.772399Z","shell.execute_reply":"2025-10-16T21:45:22.914387Z"}},"outputs":[{"name":"stdout","text":"Archive:  /kaggle/working/ml-1m.zip\n   creating: ml-1m/\n  inflating: ml-1m/movies.dat        \n  inflating: ml-1m/ratings.dat       \n  inflating: ml-1m/README            \n  inflating: ml-1m/users.dat         \nmovies.dat\nratings.dat\nREADME\nusers.dat\n1::1193::5::978300760\n1::661::3::978302109\n1::914::3::978301968\n1::3408::4::978300275\n1::2355::5::978824291\n1::F::1::10::48067\n2::M::56::16::70072\n3::M::25::15::55117\n4::M::45::7::02460\n5::M::25::20::55455\n1::Toy Story (1995)::Animation|Children's|Comedy\n2::Jumanji (1995)::Adventure|Children's|Fantasy\n3::Grumpier Old Men (1995)::Comedy|Romance\n4::Waiting to Exhale (1995)::Comedy|Drama\n5::Father of the Bride Part II (1995)::Comedy\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## 2. Write the TFX components, Beam PTransforms and unit tests\nand upload them to a reachable repository.  \nIf the repository is private, you can use Kaggle secrets to hold API keys, etc for use in download below.","metadata":{}},{"cell_type":"markdown","source":"## 3. Download the components and transforms","metadata":{}},{"cell_type":"markdown","source":"### 3.a. Ingestion\n\nThe first component is the ingestion.  One version of the component was implemented with a python custom function as a decorated component and another component was written as a fully custom component.  Both use mostly the same custom apache beam PTransforms.\nThe python custom component is the preferred to use in the pipeline, though both produce similar results.\n\nCustomization was needed to ingest the 3 files (\"ratings.dat\", \"movies.dat\", \"users.dat\"), left join them on ratings, and then split them.\nThe components are called IngestMovieLensComponent and ingest_movie_lens_component for the fully customized  and the python function customized versions, respectively.\n\nThe code base also contains ingestion to pyarrow data-structures and reads and writes of Parquet files for other uses.\n\nThe code base is at github, user nking, repository recommender_systems and the next cell downloads the code and unit tests.","metadata":{}},{"cell_type":"code","source":"%%bash\n#it can take a couple of minutes to get current version of recently uploaded file to github\n#wget -q -c --no-cache https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/main/src/test/python/test_tft.py -O /kaggle/working/test_tft.py\n#curl --header \"Cache-Control: no-cache\" \"https://api.github.com/repos/nking/recommender_systems/content/src/test/python/test_tft.py\" -o /kaggle/working/test_tft.py\n\nrepo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/main/python'\ndeclare -a my_files=(\"ingest_movie_lens_beam.py\" \"ingest_movie_lens_beam_pa.py\"\n  \"CustomUTF8Coder.py\" \"ingest_movie_lens_component.py\" \n  \"movie_lens_utils.py\" \"ingest_movie_lens_custom_component.py\"\n  \"transform_movie_lens.py\"\n)\nfor item in \"${my_files[@]}\"\ndo\n  rm -f \"/kaggle/working/$item\"\n  echo \"$item\"\n  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\ndone\n\n#repo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/drafts/python'\n#declare -a my_files=()\n#for item in \"${my_files[@]}\"\n#do\n#  rm -f \"/kaggle/working/$item\"\n#  echo \"$item\"\n#  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\n#done\n\nrepo_uri='https://raw.githubusercontent.com/nking/recommender_systems/refs/heads/development/src/test/python'\ndeclare -a my_files=(\"ingest_movie_lens_beam_test.py\" \"ingest_movie_lens_beam_pa_test.py\"\n  \"ingest_movie_lens_component_test.py\" \"ingest_movie_lens_custom_component_test.py\" \n  \"movie_lens_utils_test.py\" \"csv_example_gen_test.py\" \n  \"helper.py\" \"transform_movie_lens_test.py\"\n)\nfor item in \"${my_files[@]}\"\ndo\n  rm -f \"/kaggle/working/$item\"\n  echo \"$item\"\n  wget -q -c --no-cache \"$repo_uri/$item\" -O /kaggle/working/$item\ndone\n\nls -l /kaggle/working/\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T23:21:37.226556Z","iopub.execute_input":"2025-10-16T23:21:37.227887Z","iopub.status.idle":"2025-10-16T23:21:39.928636Z","shell.execute_reply.started":"2025-10-16T23:21:37.227847Z","shell.execute_reply":"2025-10-16T23:21:39.927594Z"}},"outputs":[{"name":"stdout","text":"ingest_movie_lens_beam.py\ningest_movie_lens_beam_pa.py\nCustomUTF8Coder.py\ningest_movie_lens_component.py\nmovie_lens_utils.py\ningest_movie_lens_custom_component.py\ntransform_movie_lens.py\ningest_movie_lens_beam_test.py\ningest_movie_lens_beam_pa_test.py\ningest_movie_lens_component_test.py\ningest_movie_lens_custom_component_test.py\nmovie_lens_utils_test.py\ncsv_example_gen_test.py\nhelper.py\ntransform_movie_lens_test.py\ntotal 164\ndrwxr-xr-x 7 root root  4096 Oct 16 21:48 bin\n-rw-r--r-- 1 root root  7373 Oct 16 23:21 csv_example_gen_test.py\n-rw-r--r-- 1 root root   777 Oct 16 23:21 CustomUTF8Coder.py\n-rw-r--r-- 1 root root  2392 Oct 16 21:45 dataset_tfxio_example.py\n-rw-r--r-- 1 root root  3633 Oct 16 23:21 helper.py\n-rw-r--r-- 1 root root 10031 Oct 16 23:21 ingest_movie_lens_beam_pa.py\n-rw-r--r-- 1 root root  4581 Oct 16 23:21 ingest_movie_lens_beam_pa_test.py\n-rw-r--r-- 1 root root  7942 Oct 16 23:21 ingest_movie_lens_beam.py\n-rw-r--r-- 1 root root  5111 Oct 16 23:21 ingest_movie_lens_beam_test.py\n-rw-r--r-- 1 root root  6255 Oct 16 23:21 ingest_movie_lens_component.py\n-rw-r--r-- 1 root root 11250 Oct 16 23:21 ingest_movie_lens_component_test.py\n-rw-r--r-- 1 root root 13217 Oct 16 23:21 ingest_movie_lens_custom_component.py\n-rw-r--r-- 1 root root 12623 Oct 16 23:21 ingest_movie_lens_custom_component_test.py\ndrwxr-x--- 3 root root  4096 Oct 16 21:45 ml-1m\n-rw-r--r-- 1 root root 13816 Oct 16 23:21 movie_lens_utils.py\n-rw-r--r-- 1 root root  4414 Oct 16 23:21 movie_lens_utils_test.py\ndrwxr-xr-x 2 root root  4096 Oct 16 23:16 __pycache__\n-rw-r--r-- 1 root root  6187 Oct 16 23:21 transform_movie_lens.py\n-rw-r--r-- 1 root root  8792 Oct 16 23:21 transform_movie_lens_test.py\nThu Oct 16 11:21:39 PM UTC 2025\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"### Run the unit tests","metadata":{}},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for CSVExampleGen\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/csv_example_gen_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:45:25.564115Z","iopub.execute_input":"2025-10-16T21:45:25.564470Z","iopub.status.idle":"2025-10-16T21:45:42.899688Z","shell.execute_reply.started":"2025-10-16T21:45:25.564435Z","shell.execute_reply":"2025-10-16T21:45:42.898526Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for CSVExampleGen\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\nkey=examples, value=OutputChannel(artifact_type=Examples, producer_component_id=CsvExampleGen, output_key=examples, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False)\nlisting files in output_data_dir /kaggle/working/bin/csv_comp_1/testRun:\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n15.427272856 seconds\nThu Oct 16 09:45:42 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n.s\n----------------------------------------------------------------------\nRan 2 tests in 3.362s\n\nOK (skipped=1)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"%%bash\nhead -n 5 /kaggle/working/ml-1m/ratings.dat\nhead -n 5 /kaggle/working/ml-1m/users.dat\nhead -n 5 /kaggle/working/ml-1m/movies.dat","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:45:42.900889Z","iopub.execute_input":"2025-10-16T21:45:42.901427Z","iopub.status.idle":"2025-10-16T21:45:42.919051Z","shell.execute_reply.started":"2025-10-16T21:45:42.901398Z","shell.execute_reply":"2025-10-16T21:45:42.917998Z"}},"outputs":[{"name":"stdout","text":"1::1193::5::978300760\n1::661::3::978302109\n1::914::3::978301968\n1::3408::4::978300275\n1::2355::5::978824291\n1::F::1::10::48067\n2::M::56::16::70072\n3::M::25::15::55117\n4::M::45::7::02460\n5::M::25::20::55455\n1::Toy Story (1995)::Animation|Children's|Comedy\n2::Jumanji (1995)::Adventure|Children's|Fantasy\n3::Grumpier Old Men (1995)::Comedy|Romance\n4::Waiting to Exhale (1995)::Comedy|Drama\n5::Father of the Bride Part II (1995)::Comedy\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!find /kaggle/working -type f\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:45:42.923366Z","iopub.execute_input":"2025-10-16T21:45:42.924977Z","iopub.status.idle":"2025-10-16T21:45:43.056807Z","shell.execute_reply.started":"2025-10-16T21:45:42.924931Z","shell.execute_reply":"2025-10-16T21:45:43.055594Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ingest_movie_lens_custom_component_test.py\n/kaggle/working/ingest_movie_lens_component_test.py\n/kaggle/working/__pycache__/CustomUTF8Coder.cpython-310.pyc\n/kaggle/working/__pycache__/csv_example_gen_test.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_custom_component.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_beam.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils.cpython-310.pyc\n/kaggle/working/ingest_movie_lens_beam_test.py\n/kaggle/working/ml-1m/users.dat\n/kaggle/working/ml-1m/users_100.dat\n/kaggle/working/ml-1m/README\n/kaggle/working/ml-1m/tmp/users2.dat\n/kaggle/working/ml-1m/movies.dat\n/kaggle/working/ml-1m/ratings_1000.dat\n/kaggle/working/ml-1m/ratings.dat\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/ingest_movie_lens_beam.py\n/kaggle/working/transform_movie_lens_test.py\n/kaggle/working/transform_movie_lens.py\n/kaggle/working/helper.py\n/kaggle/working/ingest_movie_lens_beam_pa_test.py\n/kaggle/working/csv_example_gen_test.py\n/kaggle/working/CustomUTF8Coder.py\n/kaggle/working/ingest_movie_lens_beam_pa.py\n/kaggle/working/ingest_movie_lens_custom_component.py\n/kaggle/working/ingest_movie_lens_component.py\n/kaggle/working/dataset_tfxio_example.py\n/kaggle/working/movie_lens_utils_test.py\n/kaggle/working/movie_lens_utils.py\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for utils methods\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/movie_lens_utils_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:45:43.058320Z","iopub.execute_input":"2025-10-16T21:45:43.058604Z","iopub.status.idle":"2025-10-16T21:45:50.328655Z","shell.execute_reply.started":"2025-10-16T21:45:43.058574Z","shell.execute_reply":"2025-10-16T21:45:50.326528Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for utils methods\n5.496156890 seconds\nThu Oct 16 09:45:50 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"...\n----------------------------------------------------------------------\nRan 3 tests in 0.001s\n\nOK\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for beam transforms\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/ingest_movie_lens_beam_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:45:50.330325Z","iopub.execute_input":"2025-10-16T21:45:50.330649Z","iopub.status.idle":"2025-10-16T21:47:20.550457Z","shell.execute_reply.started":"2025-10-16T21:45:50.330624Z","shell.execute_reply":"2025-10-16T21:47:20.548903Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for beam transforms\n88.289876538 seconds\nThu Oct 16 09:47:20 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['/kaggle/working/ingest_movie_lens_beam_test.py']\nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760651162   nanos: 630374431 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760651162   nanos: 639155149 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760651162   nanos: 635562658 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760651162   nanos: 644566059 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760651162   nanos: 665055990 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760651162   nanos: 673450231 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760651162   nanos: 678673744 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760651162   nanos: 690187931 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n.s\n----------------------------------------------------------------------\nRan 2 tests in 81.314s\n\nOK (skipped=1)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for tfx python function custom component\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/ingest_movie_lens_component_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:47:20.551971Z","iopub.execute_input":"2025-10-16T21:47:20.552277Z","iopub.status.idle":"2025-10-16T21:47:45.988481Z","shell.execute_reply.started":"2025-10-16T21:47:20.552254Z","shell.execute_reply":"2025-10-16T21:47:45.986788Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for tfx python function custom component\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\n23.616623388 seconds\nThu Oct 16 09:47:45 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1760651252.998533    1119 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nWARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\nWARNING:absl:ArtifactQuery.property_predicate is not supported.\nI0000 00:00:1760651255.819090    1119 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nWARNING:absl:ArtifactQuery.property_predicate is not supported.\nI0000 00:00:1760651262.849859    1119 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\n.s\n----------------------------------------------------------------------\nRan 2 tests in 11.335s\n\nOK (skipped=1)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"!find /kaggle/working -type f\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:47:45.989753Z","iopub.execute_input":"2025-10-16T21:47:45.990028Z","iopub.status.idle":"2025-10-16T21:47:46.120239Z","shell.execute_reply.started":"2025-10-16T21:47:45.989986Z","shell.execute_reply":"2025-10-16T21:47:46.118987Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ingest_movie_lens_custom_component_test.py\n/kaggle/working/ingest_movie_lens_component_test.py\n/kaggle/working/__pycache__/ingest_movie_lens_component_test.cpython-310.pyc\n/kaggle/working/__pycache__/CustomUTF8Coder.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_component.cpython-310.pyc\n/kaggle/working/__pycache__/csv_example_gen_test.cpython-310.pyc\n/kaggle/working/__pycache__/helper.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils_test.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_beam_test.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_custom_component.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_beam.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils.cpython-310.pyc\n/kaggle/working/ingest_movie_lens_beam_test.py\n/kaggle/working/ml-1m/users.dat\n/kaggle/working/ml-1m/users_100.dat\n/kaggle/working/ml-1m/README\n/kaggle/working/ml-1m/tmp/users2.dat\n/kaggle/working/ml-1m/movies.dat\n/kaggle/working/ml-1m/ratings_1000.dat\n/kaggle/working/ml-1m/ratings.dat\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-train/FeatureStats.pb\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-eval/FeatureStats.pb\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-test/FeatureStats.pb\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/SchemaGen/schema/3/schema.pbtxt\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/ingest_movie_lens_beam.py\n/kaggle/working/transform_movie_lens_test.py\n/kaggle/working/transform_movie_lens.py\n/kaggle/working/helper.py\n/kaggle/working/ingest_movie_lens_beam_pa_test.py\n/kaggle/working/csv_example_gen_test.py\n/kaggle/working/CustomUTF8Coder.py\n/kaggle/working/ingest_movie_lens_beam_pa.py\n/kaggle/working/ingest_movie_lens_custom_component.py\n/kaggle/working/ingest_movie_lens_component.py\n/kaggle/working/dataset_tfxio_example.py\n/kaggle/working/movie_lens_utils_test.py\n/kaggle/working/movie_lens_utils.py\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for TFX fully custom component\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/ingest_movie_lens_custom_component_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:47:46.122122Z","iopub.execute_input":"2025-10-16T21:47:46.122521Z","iopub.status.idle":"2025-10-16T21:48:14.500754Z","shell.execute_reply.started":"2025-10-16T21:47:46.122476Z","shell.execute_reply":"2025-10-16T21:48:14.498967Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for TFX fully custom component\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\n26.208010227 seconds\nThu Oct 16 09:48:14 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n.WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1760651281.605394    1348 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nWARNING:absl:ArtifactQuery.property_predicate is not supported.\nI0000 00:00:1760651284.022659    1348 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nWARNING:absl:ArtifactQuery.property_predicate is not supported.\nI0000 00:00:1760651291.601471    1348 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\n.s\n----------------------------------------------------------------------\nRan 3 tests in 14.161s\n\nOK (skipped=1)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"%%bash\n\n. /usr/local/bin/activate\nconda activate my_tfx_env\n\npython --version\n\necho \"run test for preprocessing Transform\"\n\nt0=$(date +%s%N)\n\npython -m unittest /kaggle/working/transform_movie_lens_test.py\n\nt1=$(date +%s%N)\nt2=$(echo \"scale=9;($t1-$t0) / 1000000000\" | bc)\necho $t2 seconds\ndate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T23:21:49.043735Z","iopub.execute_input":"2025-10-16T23:21:49.044110Z","iopub.status.idle":"2025-10-16T23:23:49.361110Z","shell.execute_reply.started":"2025-10-16T23:21:49.044082Z","shell.execute_reply":"2025-10-16T23:23:49.359777Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.18\nrun test for preprocessing Transform\nrunning bdist_wheel\nrunning build\nrunning build_py\ncreating build/lib\ncopying ingest_movie_lens_custom_component_test.py -> build/lib\ncopying ingest_movie_lens_component_test.py -> build/lib\ncopying ingest_movie_lens_beam_test.py -> build/lib\ncopying ingest_movie_lens_beam.py -> build/lib\ncopying transform_movie_lens_test.py -> build/lib\ncopying transform_movie_lens.py -> build/lib\ncopying helper.py -> build/lib\ncopying ingest_movie_lens_beam_pa_test.py -> build/lib\ncopying csv_example_gen_test.py -> build/lib\ncopying CustomUTF8Coder.py -> build/lib\ncopying ingest_movie_lens_beam_pa.py -> build/lib\ncopying ingest_movie_lens_custom_component.py -> build/lib\ncopying ingest_movie_lens_component.py -> build/lib\ncopying dataset_tfxio_example.py -> build/lib\ncopying movie_lens_utils_test.py -> build/lib\ncopying movie_lens_utils.py -> build/lib\ninstalling to /tmp/tmprhlikoh2\nrunning install\nrunning install_lib\ncopying build/lib/helper.py -> /tmp/tmprhlikoh2/.\ncopying build/lib/ingest_movie_lens_beam_test.py -> /tmp/tmprhlikoh2/.\ncopying build/lib/movie_lens_utils_test.py -> /tmp/tmprhlikoh2/.\ncopying build/lib/ingest_movie_lens_component_test.py -> /tmp/tmprhlikoh2/.\ncopying build/lib/ingest_movie_lens_custom_component_test.py -> /tmp/tmprhlikoh2/.\ncopying build/lib/csv_example_gen_test.py -> /tmp/tmprhlikoh2/.\ncopying build/lib/ingest_movie_lens_beam_pa_test.py -> /tmp/tmprhlikoh2/.\ncopying build/lib/CustomUTF8Coder.py -> /tmp/tmprhlikoh2/.\ncopying build/lib/transform_movie_lens_test.py -> /tmp/tmprhlikoh2/.\ncopying build/lib/ingest_movie_lens_beam_pa.py -> /tmp/tmprhlikoh2/.\ncopying build/lib/dataset_tfxio_example.py -> /tmp/tmprhlikoh2/.\ncopying build/lib/transform_movie_lens.py -> /tmp/tmprhlikoh2/.\ncopying build/lib/ingest_movie_lens_custom_component.py -> /tmp/tmprhlikoh2/.\ncopying build/lib/ingest_movie_lens_component.py -> /tmp/tmprhlikoh2/.\ncopying build/lib/movie_lens_utils.py -> /tmp/tmprhlikoh2/.\ncopying build/lib/ingest_movie_lens_beam.py -> /tmp/tmprhlikoh2/.\nrunning install_egg_info\nrunning egg_info\ncreating tfx_user_code_Transform.egg-info\nwriting tfx_user_code_Transform.egg-info/PKG-INFO\nwriting dependency_links to tfx_user_code_Transform.egg-info/dependency_links.txt\nwriting top-level names to tfx_user_code_Transform.egg-info/top_level.txt\nwriting manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\nreading manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\nwriting manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\nCopying tfx_user_code_Transform.egg-info to /tmp/tmprhlikoh2/./tfx_user_code_Transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3.10.egg-info\nrunning install_scripts\ncreating /tmp/tmprhlikoh2/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162.dist-info/WHEEL\ncreating '/tmp/tmpg0y6ti92/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl' and adding '/tmp/tmprhlikoh2' to it\nadding 'CustomUTF8Coder.py'\nadding 'csv_example_gen_test.py'\nadding 'dataset_tfxio_example.py'\nadding 'helper.py'\nadding 'ingest_movie_lens_beam.py'\nadding 'ingest_movie_lens_beam_pa.py'\nadding 'ingest_movie_lens_beam_pa_test.py'\nadding 'ingest_movie_lens_beam_test.py'\nadding 'ingest_movie_lens_component.py'\nadding 'ingest_movie_lens_component_test.py'\nadding 'ingest_movie_lens_custom_component.py'\nadding 'ingest_movie_lens_custom_component_test.py'\nadding 'movie_lens_utils.py'\nadding 'movie_lens_utils_test.py'\nadding 'transform_movie_lens.py'\nadding 'transform_movie_lens_test.py'\nadding 'tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162.dist-info/METADATA'\nadding 'tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162.dist-info/WHEEL'\nadding 'tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162.dist-info/top_level.txt'\nadding 'tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162.dist-info/RECORD'\nremoving /tmp/tmprhlikoh2\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\nProcessing ./bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl\nInstalling collected packages: tfx-user-code-transform\nSuccessfully installed tfx-user-code-transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162\nProcessing ./bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl\nInstalling collected packages: tfx-user-code-transform\nSuccessfully installed tfx-user-code-transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162\nProcessing ./bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl\nInstalling collected packages: tfx-user-code-transform\nSuccessfully installed tfx-user-code-transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162\nTensorFlow version: 2.16.1\nTFX version: 1.16.0\n118.340377717 seconds\nThu Oct 16 11:23:49 PM UTC 2025\n","output_type":"stream"},{"name":"stderr","text":"INFO:absl:Excluding no splits because exclude_splits is not set.\nINFO:absl:Excluding no splits because exclude_splits is not set.\nINFO:absl:Generating ephemeral wheel package for '/kaggle/working/transform_movie_lens.py' (including modules: ['ingest_movie_lens_custom_component_test', 'ingest_movie_lens_component_test', 'ingest_movie_lens_beam_test', 'ingest_movie_lens_beam', 'transform_movie_lens_test', 'transform_movie_lens', 'helper', 'ingest_movie_lens_beam_pa_test', 'csv_example_gen_test', 'CustomUTF8Coder', 'ingest_movie_lens_beam_pa', 'ingest_movie_lens_custom_component', 'ingest_movie_lens_component', 'dataset_tfxio_example', 'movie_lens_utils_test', 'movie_lens_utils']).\nINFO:absl:User module package has hash fingerprint version 0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162.\nINFO:absl:Executing: ['/usr/local/envs/my_tfx_env/bin/python', '/tmp/tmpxqph3v13/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmprhlikoh2', '--dist-dir', '/tmp/tmpg0y6ti92']\n/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:90: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n!!\n\n        ********************************************************************************\n        Please avoid running ``setup.py`` directly.\n        Instead, use pypa/build, pypa/installer or other\n        standards-based tools.\n\n        By 2025-Oct-31, you need to update your project and remove deprecated calls\n        or your builds will no longer be supported.\n\n        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n        ********************************************************************************\n\n!!\n  self.initialize_options()\nINFO:absl:Successfully built user code wheel distribution at '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl'; target user module is 'transform_movie_lens'.\nINFO:absl:Full user module path is 'transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl'\nINFO:absl:Using deployment config:\n executor_specs {\n  key: \"MovieLensExampleGen\"\n  value {\n    beam_executable_spec {\n      python_executor_spec {\n        class_path: \"ingest_movie_lens_component.MovieLensExampleGen_Executor\"\n      }\n      beam_pipeline_args: \"--direct_running_mode=multi_processing\"\n      beam_pipeline_args: \"--direct_num_workers=0\"\n      beam_pipeline_args_placeholders {\n        value {\n          string_value: \"--direct_running_mode=multi_processing\"\n        }\n      }\n      beam_pipeline_args_placeholders {\n        value {\n          string_value: \"--direct_num_workers=0\"\n        }\n      }\n    }\n  }\n}\nexecutor_specs {\n  key: \"SchemaGen\"\n  value {\n    python_class_executable_spec {\n      class_path: \"tfx.components.schema_gen.executor.Executor\"\n    }\n  }\n}\nexecutor_specs {\n  key: \"StatisticsGen\"\n  value {\n    beam_executable_spec {\n      python_executor_spec {\n        class_path: \"tfx.components.statistics_gen.executor.Executor\"\n      }\n      beam_pipeline_args: \"--direct_running_mode=multi_processing\"\n      beam_pipeline_args: \"--direct_num_workers=0\"\n      beam_pipeline_args_placeholders {\n        value {\n          string_value: \"--direct_running_mode=multi_processing\"\n        }\n      }\n      beam_pipeline_args_placeholders {\n        value {\n          string_value: \"--direct_num_workers=0\"\n        }\n      }\n    }\n  }\n}\nexecutor_specs {\n  key: \"Transform\"\n  value {\n    beam_executable_spec {\n      python_executor_spec {\n        class_path: \"tfx.components.transform.executor.Executor\"\n      }\n      beam_pipeline_args: \"--direct_running_mode=multi_processing\"\n      beam_pipeline_args: \"--direct_num_workers=0\"\n      beam_pipeline_args_placeholders {\n        value {\n          string_value: \"--direct_running_mode=multi_processing\"\n        }\n      }\n      beam_pipeline_args_placeholders {\n        value {\n          string_value: \"--direct_num_workers=0\"\n        }\n      }\n    }\n  }\n}\nmetadata_connection_config {\n  database_connection_config {\n    sqlite {\n      filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n      connection_mode: READWRITE_OPENCREATE\n    }\n  }\n}\n\nINFO:absl:Using connection config:\n sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component MovieLensExampleGen is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"ingest_movie_lens_component.MovieLensExampleGen\"\n  }\n  id: \"MovieLensExampleGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-16T23:22:01.346067\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline.MovieLensExampleGen\"\n      }\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"output_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"infiles_dict_ser\"\n    value {\n      field_value {\n        string_value: \"gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n      }\n    }\n  }\n  parameters {\n    key: \"output_config_ser\"\n    value {\n      field_value {\n        string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n      }\n    }\n  }\n}\ndownstream_nodes: \"StatisticsGen\"\ndownstream_nodes: \"Transform\"\nexecution_options {\n  caching_options {\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type pipeline and name TestPythonTransformPipeline\nDEBUG:absl:ID of context type {\n  name: \"pipeline\"\n}\nname {\n  field_value {\n    string_value: \"TestPythonTransformPipeline\"\n  }\n}\n is 1.\nDEBUG:absl:Failed to get context of type pipeline_run and name 2025-10-16T23:22:01.346067\nDEBUG:absl:ID of context type {\n  name: \"pipeline_run\"\n}\nname {\n  field_value {\n    string_value: \"2025-10-16T23:22:01.346067\"\n  }\n}\n is 2.\nDEBUG:absl:Failed to get context of type node and name TestPythonTransformPipeline.MovieLensExampleGen\nDEBUG:absl:ID of context type {\n  name: \"node\"\n}\nname {\n  field_value {\n    string_value: \"TestPythonTransformPipeline.MovieLensExampleGen\"\n  }\n}\n is 3.\nDEBUG:absl:Before conditional:\n{}\nDEBUG:absl:After conditional:\n{}\nINFO:absl:[MovieLensExampleGen] Resolved inputs: ({},)\nDEBUG:absl:Prepared EXECUTION:\n type_id: 13\nlast_known_state: RUNNING\ncustom_properties {\n  key: \"infiles_dict_ser\"\n  value {\n    string_value: \"gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n  }\n}\ncustom_properties {\n  key: \"output_config_ser\"\n  value {\n    string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n  }\n}\nname: \"21bd8a35-1f7e-462d-8056-23ab4525f9f6\"\n\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type execution_cache and name 9c8ee902c018e9e330485b35a8dcba812ad906560ec1fa358c345cfb41f487bf\nDEBUG:absl:ID of context type {\n  name: \"execution_cache\"\n}\nname {\n  field_value {\n    string_value: \"9c8ee902c018e9e330485b35a8dcba812ad906560ec1fa358c345cfb41f487bf\"\n  }\n}\n is 4.\nINFO:absl:Going to run a new execution 1\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1760656921.539945   15420 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=1, input_dict={}, output_dict=defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}), exec_properties={'output_config_ser': 'Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK', 'infiles_dict_ser': 'gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg=='}, execution_output_uri='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/.system/executor_execution/1/executor_output.pb', stateful_working_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/.system/stateful_working_dir/925f4cf0-3c92-4a72-abf8-9967b983ff6a', tmp_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/.system/executor_execution/1/.temp/', pipeline_node=node_info {\n  type {\n    name: \"ingest_movie_lens_component.MovieLensExampleGen\"\n  }\n  id: \"MovieLensExampleGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-16T23:22:01.346067\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline.MovieLensExampleGen\"\n      }\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"output_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"infiles_dict_ser\"\n    value {\n      field_value {\n        string_value: \"gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n      }\n    }\n  }\n  parameters {\n    key: \"output_config_ser\"\n    value {\n      field_value {\n        string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n      }\n    }\n  }\n}\ndownstream_nodes: \"StatisticsGen\"\ndownstream_nodes: \"Transform\"\nexecution_options {\n  caching_options {\n  }\n}\n, pipeline_info=id: \"TestPythonTransformPipeline\"\n, pipeline_run_id='2025-10-16T23:22:01.346067', top_level_pipeline_run_id=None, frontend_url=None)\nINFO:absl:Attempting to infer TFX Python dependency for beam\nINFO:absl:Copying all content from install dir /usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx to temp dir /tmp/tmp5xyqbken/build/tfx\nINFO:absl:Generating a temp setup file at /tmp/tmp5xyqbken/build/tfx/setup.py\nINFO:absl:Creating temporary sdist package, logs available at /tmp/tmp5xyqbken/build/tfx/setup.log\nINFO:absl:Added --extra_package=/tmp/tmp5xyqbken/build/tfx/dist/tfx_ephemeral-1.16.0.tar.gz to beam args\nINFO:absl:MovieLensExampleGen\nDEBUG:absl:output_examples was passed in to component\nDEBUG:absl:output_examples TYPE=<class 'tfx.types.standard_artifacts.Examples'>\nDEBUG:absl:output_examples=Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    int_value: 1\n  }\n}\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)\nDEBUG:absl:split_names=['train', 'eval', 'test']\nDEBUG:absl:columns=[('user_id', <class 'int'>), ('movie_id', <class 'int'>), ('rating', <class 'int'>), ('timestamp', <class 'int'>), ('gender', <class 'str'>), ('age', <class 'int'>), ('occupation', <class 'int'>), ('genres', <class 'str'>)]\nDEBUG:absl:cumulative_buckets=[80, 90, 100]\nDEBUG:absl:have ratings_tuple.  type=<class 'apache_beam.pvalue.DoOutputsTuple'>\nDEBUG:absl:prefix_path=/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord\nDEBUG:absl:prefix_path=/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord\nDEBUG:absl:prefix_path=/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord\nINFO:absl:output_examples written as TFRecords\nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656928   nanos: 839086771 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656928   nanos: 833858728 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656928   nanos: 843075990 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656928   nanos: 849287509 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656928   nanos: 927549839 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656928   nanos: 935417890 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656928   nanos: 948828220 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656928   nanos: 959426403 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656942   nanos: 587741374 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_49\" transform_id: \"write_to_tfrecord_341158322707/Write/WriteImpl/WriteBundles\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-14\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656942   nanos: 592767477 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_52\" transform_id: \"write_to_tfrecord_421920178746/Write/WriteImpl/WriteBundles\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-13\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656942   nanos: 644308805 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_51\" transform_id: \"write_to_tfrecord_421920178746/Write/WriteImpl/WriteBundles\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-14\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656942   nanos: 684188842 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_50\" transform_id: \"write_to_tfrecord_281587505522/Write/WriteImpl/WriteBundles\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-14\" \nINFO:absl:Cleaning up stateless execution info.\nINFO:absl:Execution 1 succeeded.\nINFO:absl:Cleaning up stateful execution info.\nINFO:absl:Deleted stateful_working_dir /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/.system/stateful_working_dir/925f4cf0-3c92-4a72-abf8-9967b983ff6a\nINFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}) for execution 1\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component MovieLensExampleGen is finished.\nINFO:absl:Component StatisticsGen is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n    base_type: PROCESS\n  }\n  id: \"StatisticsGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-16T23:22:01.346067\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline.StatisticsGen\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"examples\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"MovieLensExampleGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-16T23:22:01.346067\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline.MovieLensExampleGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"Examples\"\n            base_type: DATASET\n          }\n        }\n        output_key: \"output_examples\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"statistics\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleStatistics\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          base_type: STATISTICS\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"exclude_splits\"\n    value {\n      field_value {\n        string_value: \"[]\"\n      }\n    }\n  }\n}\nupstream_nodes: \"MovieLensExampleGen\"\ndownstream_nodes: \"SchemaGen\"\nexecution_options {\n  caching_options {\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type node and name TestPythonTransformPipeline.StatisticsGen\nDEBUG:absl:ID of context type {\n  name: \"node\"\n}\nname {\n  field_value {\n    string_value: \"TestPythonTransformPipeline.StatisticsGen\"\n  }\n}\n is 5.\nWARNING:absl:ArtifactQuery.property_predicate is not supported.\nDEBUG:absl:examples <- [\n  [NO_PARTITION]: [Examples(id=1, span=0, version=1)]\n]\nDEBUG:absl:Before conditional:\n{examples: [Examples(id=1, span=0, version=1)]}\nDEBUG:absl:After conditional:\n{examples: [Examples(id=1, span=0, version=1)]}\nINFO:absl:[StatisticsGen] Resolved inputs: ({'examples': [Artifact(artifact: id: 1\ntype_id: 15\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    int_value: 1\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Examples\"\ncreate_time_since_epoch: 1760656952744\nlast_update_time_since_epoch: 1760656952744\n, artifact_type: id: 15\nname: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]},)\nDEBUG:absl:Prepared EXECUTION:\n type_id: 16\nlast_known_state: RUNNING\ncustom_properties {\n  key: \"exclude_splits\"\n  value {\n    string_value: \"[]\"\n  }\n}\nname: \"48d2f50f-b755-4b07-ba33-44bc455bf000\"\n\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type execution_cache and name 2a1f719ef2710b4f2a1f59f6d4d4ab4c478ba240a38c45081dc3cc2ca3161418\nDEBUG:absl:ID of context type {\n  name: \"execution_cache\"\n}\nname {\n  field_value {\n    string_value: \"2a1f719ef2710b4f2a1f59f6d4d4ab4c478ba240a38c45081dc3cc2ca3161418\"\n  }\n}\n is 6.\nINFO:absl:Going to run a new execution 2\nI0000 00:00:1760656952.834596   15420 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=2, input_dict={'examples': [Artifact(artifact: id: 1\ntype_id: 15\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    int_value: 1\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Examples\"\ncreate_time_since_epoch: 1760656952744\nlast_update_time_since_epoch: 1760656952744\n, artifact_type: id: 15\nname: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2\"\n, artifact_type: name: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/.system/executor_execution/2/executor_output.pb', stateful_working_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/.system/stateful_working_dir/f47bba5a-c897-46e5-b4ed-454e1150a707', tmp_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/.system/executor_execution/2/.temp/', pipeline_node=node_info {\n  type {\n    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n    base_type: PROCESS\n  }\n  id: \"StatisticsGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-16T23:22:01.346067\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline.StatisticsGen\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"examples\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"MovieLensExampleGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-16T23:22:01.346067\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline.MovieLensExampleGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"Examples\"\n            base_type: DATASET\n          }\n        }\n        output_key: \"output_examples\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"statistics\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleStatistics\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          base_type: STATISTICS\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"exclude_splits\"\n    value {\n      field_value {\n        string_value: \"[]\"\n      }\n    }\n  }\n}\nupstream_nodes: \"MovieLensExampleGen\"\ndownstream_nodes: \"SchemaGen\"\nexecution_options {\n  caching_options {\n  }\n}\n, pipeline_info=id: \"TestPythonTransformPipeline\"\n, pipeline_run_id='2025-10-16T23:22:01.346067', top_level_pipeline_run_id=None, frontend_url=None)\nINFO:absl:Attempting to infer TFX Python dependency for beam\nINFO:absl:Copying all content from install dir /usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx to temp dir /tmp/tmphwkrq28_/build/tfx\nINFO:absl:Generating a temp setup file at /tmp/tmphwkrq28_/build/tfx/setup.py\nINFO:absl:Creating temporary sdist package, logs available at /tmp/tmphwkrq28_/build/tfx/setup.log\nINFO:absl:Added --extra_package=/tmp/tmphwkrq28_/build/tfx/dist/tfx_ephemeral-1.16.0.tar.gz to beam args\nDEBUG:absl:Starting Executor execution.\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nINFO:absl:Generating statistics for split train.\nINFO:absl:Statistics for split train written to /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-train.\nINFO:absl:Generating statistics for split eval.\nINFO:absl:Statistics for split eval written to /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-eval.\nINFO:absl:Generating statistics for split test.\nINFO:absl:Statistics for split test written to /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-test.\nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656962   nanos: 754337072 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656962   nanos: 765515327 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656962   nanos: 776278495 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656962   nanos: 785616397 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656962   nanos: 810692310 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656962   nanos: 822116851 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656962   nanos: 836971759 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656962   nanos: 846806764 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656968   nanos: 972515106 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_138\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-13\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656968   nanos: 974276065 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_139\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-14\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656968   nanos: 978885412 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_137\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-14\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656968   nanos: 985923051 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_140\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-13\" \nINFO:absl:Cleaning up stateless execution info.\nINFO:absl:Execution 2 succeeded.\nINFO:absl:Cleaning up stateful execution info.\nINFO:absl:Deleted stateful_working_dir /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/.system/stateful_working_dir/f47bba5a-c897-46e5-b4ed-454e1150a707\nINFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2\"\n, artifact_type: name: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)]}) for execution 2\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component StatisticsGen is finished.\nINFO:absl:Component SchemaGen is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"tfx.components.schema_gen.component.SchemaGen\"\n    base_type: PROCESS\n  }\n  id: \"SchemaGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-16T23:22:01.346067\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline.SchemaGen\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"statistics\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"StatisticsGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-16T23:22:01.346067\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline.StatisticsGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"ExampleStatistics\"\n            base_type: STATISTICS\n          }\n        }\n        output_key: \"statistics\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"schema\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Schema\"\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"exclude_splits\"\n    value {\n      field_value {\n        string_value: \"[]\"\n      }\n    }\n  }\n  parameters {\n    key: \"infer_feature_shape\"\n    value {\n      field_value {\n        int_value: 1\n      }\n    }\n  }\n}\nupstream_nodes: \"StatisticsGen\"\ndownstream_nodes: \"Transform\"\nexecution_options {\n  caching_options {\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type node and name TestPythonTransformPipeline.SchemaGen\nDEBUG:absl:ID of context type {\n  name: \"node\"\n}\nname {\n  field_value {\n    string_value: \"TestPythonTransformPipeline.SchemaGen\"\n  }\n}\n is 7.\nWARNING:absl:ArtifactQuery.property_predicate is not supported.\nDEBUG:absl:statistics <- [\n  [NO_PARTITION]: [ExampleStatistics(id=2, span=0)]\n]\nDEBUG:absl:Before conditional:\n{statistics: [ExampleStatistics(id=2, span=0)]}\nDEBUG:absl:After conditional:\n{statistics: [ExampleStatistics(id=2, span=0)]}\nINFO:absl:[SchemaGen] Resolved inputs: ({'statistics': [Artifact(artifact: id: 2\ntype_id: 17\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"sample_rate_by_split\"\n  value {\n    struct_value {\n      fields {\n        key: \"__value__\"\n        value {\n          string_value: \"{\\\"eval\\\": 1.0, \\\"test\\\": 1.0, \\\"train\\\": 1.0}\"\n        }\n      }\n    }\n  }\n}\ncustom_properties {\n  key: \"stats_dashboard_link\"\n  value {\n    string_value: \"\"\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"ExampleStatistics\"\ncreate_time_since_epoch: 1760656978732\nlast_update_time_since_epoch: 1760656978732\n, artifact_type: id: 17\nname: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)]},)\nDEBUG:absl:Prepared EXECUTION:\n type_id: 18\nlast_known_state: RUNNING\ncustom_properties {\n  key: \"exclude_splits\"\n  value {\n    string_value: \"[]\"\n  }\n}\ncustom_properties {\n  key: \"infer_feature_shape\"\n  value {\n    int_value: 1\n  }\n}\nname: \"a5075e9c-055f-4cf3-ae3f-cfa3295967f3\"\n\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type execution_cache and name c572d0cc6d60ff62981c293fa886db1cfaacce7865a18576b792c88dddba9389\nDEBUG:absl:ID of context type {\n  name: \"execution_cache\"\n}\nname {\n  field_value {\n    string_value: \"c572d0cc6d60ff62981c293fa886db1cfaacce7865a18576b792c88dddba9389\"\n  }\n}\n is 8.\nINFO:absl:Going to run a new execution 3\nI0000 00:00:1760656978.824253   15420 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=3, input_dict={'statistics': [Artifact(artifact: id: 2\ntype_id: 17\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"sample_rate_by_split\"\n  value {\n    struct_value {\n      fields {\n        key: \"__value__\"\n        value {\n          string_value: \"{\\\"eval\\\": 1.0, \\\"test\\\": 1.0, \\\"train\\\": 1.0}\"\n        }\n      }\n    }\n  }\n}\ncustom_properties {\n  key: \"stats_dashboard_link\"\n  value {\n    string_value: \"\"\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"ExampleStatistics\"\ncreate_time_since_epoch: 1760656978732\nlast_update_time_since_epoch: 1760656978732\n, artifact_type: id: 17\nname: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)]}, output_dict=defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3\"\n, artifact_type: name: \"Schema\"\n)]}), exec_properties={'infer_feature_shape': 1, 'exclude_splits': '[]'}, execution_output_uri='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/.system/executor_execution/3/executor_output.pb', stateful_working_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/.system/stateful_working_dir/283dae6c-5f7d-477a-9f8b-239fe67ea212', tmp_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/.system/executor_execution/3/.temp/', pipeline_node=node_info {\n  type {\n    name: \"tfx.components.schema_gen.component.SchemaGen\"\n    base_type: PROCESS\n  }\n  id: \"SchemaGen\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-16T23:22:01.346067\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline.SchemaGen\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"statistics\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"StatisticsGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-16T23:22:01.346067\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline.StatisticsGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"ExampleStatistics\"\n            base_type: STATISTICS\n          }\n        }\n        output_key: \"statistics\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"schema\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Schema\"\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"exclude_splits\"\n    value {\n      field_value {\n        string_value: \"[]\"\n      }\n    }\n  }\n  parameters {\n    key: \"infer_feature_shape\"\n    value {\n      field_value {\n        int_value: 1\n      }\n    }\n  }\n}\nupstream_nodes: \"StatisticsGen\"\ndownstream_nodes: \"Transform\"\nexecution_options {\n  caching_options {\n  }\n}\n, pipeline_info=id: \"TestPythonTransformPipeline\"\n, pipeline_run_id='2025-10-16T23:22:01.346067', top_level_pipeline_run_id=None, frontend_url=None)\nINFO:absl:Processing schema from statistics for split train.\nINFO:absl:Processing schema from statistics for split eval.\nINFO:absl:Processing schema from statistics for split test.\nINFO:absl:Schema written to /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3/schema.pbtxt.\nINFO:absl:Cleaning up stateless execution info.\nINFO:absl:Execution 3 succeeded.\nINFO:absl:Cleaning up stateful execution info.\nINFO:absl:Deleted stateful_working_dir /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/.system/stateful_working_dir/283dae6c-5f7d-477a-9f8b-239fe67ea212\nINFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3\"\n, artifact_type: name: \"Schema\"\n)]}) for execution 3\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component SchemaGen is finished.\nINFO:absl:Component Transform is running.\nINFO:absl:Running launcher for node_info {\n  type {\n    name: \"tfx.components.transform.component.Transform\"\n    base_type: TRANSFORM\n  }\n  id: \"Transform\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-16T23:22:01.346067\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline.Transform\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"examples\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"MovieLensExampleGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-16T23:22:01.346067\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline.MovieLensExampleGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"Examples\"\n            base_type: DATASET\n          }\n        }\n        output_key: \"output_examples\"\n      }\n      min_count: 1\n    }\n  }\n  inputs {\n    key: \"schema\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"SchemaGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-16T23:22:01.346067\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline.SchemaGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"Schema\"\n          }\n        }\n        output_key: \"schema\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"post_transform_anomalies\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleAnomalies\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"post_transform_schema\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Schema\"\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"post_transform_stats\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleStatistics\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          base_type: STATISTICS\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"pre_transform_schema\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Schema\"\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"pre_transform_stats\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleStatistics\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          base_type: STATISTICS\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"transform_graph\"\n    value {\n      artifact_spec {\n        type {\n          name: \"TransformGraph\"\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"transformed_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"updated_analyzer_cache\"\n    value {\n      artifact_spec {\n        type {\n          name: \"TransformCache\"\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"custom_config\"\n    value {\n      field_value {\n        string_value: \"null\"\n      }\n    }\n  }\n  parameters {\n    key: \"disable_statistics\"\n    value {\n      field_value {\n        int_value: 0\n      }\n    }\n  }\n  parameters {\n    key: \"force_tf_compat_v1\"\n    value {\n      field_value {\n        int_value: 0\n      }\n    }\n  }\n  parameters {\n    key: \"module_path\"\n    value {\n      field_value {\n        string_value: \"transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl\"\n      }\n    }\n  }\n}\nupstream_nodes: \"MovieLensExampleGen\"\nupstream_nodes: \"SchemaGen\"\nexecution_options {\n  caching_options {\n  }\n}\n\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type node and name TestPythonTransformPipeline.Transform\nDEBUG:absl:ID of context type {\n  name: \"node\"\n}\nname {\n  field_value {\n    string_value: \"TestPythonTransformPipeline.Transform\"\n  }\n}\n is 9.\nWARNING:absl:ArtifactQuery.property_predicate is not supported.\nDEBUG:absl:examples <- [\n  [NO_PARTITION]: [Examples(id=1, span=0, version=1)]\n]\nWARNING:absl:ArtifactQuery.property_predicate is not supported.\nDEBUG:absl:schema <- [\n  [NO_PARTITION]: [Schema(id=3)]\n]\nDEBUG:absl:Before conditional:\n{examples: [Examples(id=1, span=0, version=1)], schema: [Schema(id=3)]}\nDEBUG:absl:After conditional:\n{examples: [Examples(id=1, span=0, version=1)], schema: [Schema(id=3)]}\nINFO:absl:[Transform] Resolved inputs: ({'examples': [Artifact(artifact: id: 1\ntype_id: 15\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    int_value: 1\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Examples\"\ncreate_time_since_epoch: 1760656952744\nlast_update_time_since_epoch: 1760656952744\n, artifact_type: id: 15\nname: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)], 'schema': [Artifact(artifact: id: 3\ntype_id: 19\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3\"\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Schema\"\ncreate_time_since_epoch: 1760656978855\nlast_update_time_since_epoch: 1760656978855\n, artifact_type: id: 19\nname: \"Schema\"\n)]},)\nDEBUG:absl:Prepared EXECUTION:\n type_id: 20\nlast_known_state: RUNNING\ncustom_properties {\n  key: \"custom_config\"\n  value {\n    string_value: \"null\"\n  }\n}\ncustom_properties {\n  key: \"disable_statistics\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"force_tf_compat_v1\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"module_path\"\n  value {\n    string_value: \"transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl\"\n  }\n}\nname: \"87854c0a-c459-4fde-ac8e-d3fcef6b8fe4\"\n\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_schema/4\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_stats/4\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_anomalies/4\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_stats/4\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/updated_analyzer_cache/4\nDEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_schema/4\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:Failed to get context of type execution_cache and name 582fe7a8aa8cf4eed3a0c7f18c8be1999ddc77206a14f276d2e024e909ae74d2\nDEBUG:absl:ID of context type {\n  name: \"execution_cache\"\n}\nname {\n  field_value {\n    string_value: \"582fe7a8aa8cf4eed3a0c7f18c8be1999ddc77206a14f276d2e024e909ae74d2\"\n  }\n}\n is 10.\nINFO:absl:Going to run a new execution 4\nI0000 00:00:1760656978.955339   15420 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}\nINFO:absl:Going to run a new execution: ExecutionInfo(execution_id=4, input_dict={'examples': [Artifact(artifact: id: 1\ntype_id: 15\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    int_value: 1\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Examples\"\ncreate_time_since_epoch: 1760656952744\nlast_update_time_since_epoch: 1760656952744\n, artifact_type: id: 15\nname: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)], 'schema': [Artifact(artifact: id: 3\ntype_id: 19\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3\"\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Schema\"\ncreate_time_since_epoch: 1760656978855\nlast_update_time_since_epoch: 1760656978855\n, artifact_type: id: 19\nname: \"Schema\"\n)]}, output_dict=defaultdict(<class 'list'>, {'pre_transform_schema': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_schema/4\"\n, artifact_type: name: \"Schema\"\n)], 'post_transform_stats': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_stats/4\"\n, artifact_type: name: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)], 'transformed_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)], 'post_transform_anomalies': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_anomalies/4\"\n, artifact_type: name: \"ExampleAnomalies\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\n)], 'pre_transform_stats': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_stats/4\"\n, artifact_type: name: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)], 'transform_graph': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4\"\n, artifact_type: name: \"TransformGraph\"\n)], 'updated_analyzer_cache': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/updated_analyzer_cache/4\"\n, artifact_type: name: \"TransformCache\"\n)], 'post_transform_schema': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_schema/4\"\n, artifact_type: name: \"Schema\"\n)]}), exec_properties={'force_tf_compat_v1': 0, 'disable_statistics': 0, 'custom_config': 'null', 'module_path': 'transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl'}, execution_output_uri='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/.system/executor_execution/4/executor_output.pb', stateful_working_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/.system/stateful_working_dir/d834ed82-2114-42cb-ba02-1a365af0e104', tmp_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/.system/executor_execution/4/.temp/', pipeline_node=node_info {\n  type {\n    name: \"tfx.components.transform.component.Transform\"\n    base_type: TRANSFORM\n  }\n  id: \"Transform\"\n}\ncontexts {\n  contexts {\n    type {\n      name: \"pipeline\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"pipeline_run\"\n    }\n    name {\n      field_value {\n        string_value: \"2025-10-16T23:22:01.346067\"\n      }\n    }\n  }\n  contexts {\n    type {\n      name: \"node\"\n    }\n    name {\n      field_value {\n        string_value: \"TestPythonTransformPipeline.Transform\"\n      }\n    }\n  }\n}\ninputs {\n  inputs {\n    key: \"examples\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"MovieLensExampleGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-16T23:22:01.346067\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline.MovieLensExampleGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"Examples\"\n            base_type: DATASET\n          }\n        }\n        output_key: \"output_examples\"\n      }\n      min_count: 1\n    }\n  }\n  inputs {\n    key: \"schema\"\n    value {\n      channels {\n        producer_node_query {\n          id: \"SchemaGen\"\n        }\n        context_queries {\n          type {\n            name: \"pipeline\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"pipeline_run\"\n          }\n          name {\n            field_value {\n              string_value: \"2025-10-16T23:22:01.346067\"\n            }\n          }\n        }\n        context_queries {\n          type {\n            name: \"node\"\n          }\n          name {\n            field_value {\n              string_value: \"TestPythonTransformPipeline.SchemaGen\"\n            }\n          }\n        }\n        artifact_query {\n          type {\n            name: \"Schema\"\n          }\n        }\n        output_key: \"schema\"\n      }\n      min_count: 1\n    }\n  }\n}\noutputs {\n  outputs {\n    key: \"post_transform_anomalies\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleAnomalies\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"post_transform_schema\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Schema\"\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"post_transform_stats\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleStatistics\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          base_type: STATISTICS\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"pre_transform_schema\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Schema\"\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"pre_transform_stats\"\n    value {\n      artifact_spec {\n        type {\n          name: \"ExampleStatistics\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          base_type: STATISTICS\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"transform_graph\"\n    value {\n      artifact_spec {\n        type {\n          name: \"TransformGraph\"\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"transformed_examples\"\n    value {\n      artifact_spec {\n        type {\n          name: \"Examples\"\n          properties {\n            key: \"span\"\n            value: INT\n          }\n          properties {\n            key: \"split_names\"\n            value: STRING\n          }\n          properties {\n            key: \"version\"\n            value: INT\n          }\n          base_type: DATASET\n        }\n      }\n    }\n  }\n  outputs {\n    key: \"updated_analyzer_cache\"\n    value {\n      artifact_spec {\n        type {\n          name: \"TransformCache\"\n        }\n      }\n    }\n  }\n}\nparameters {\n  parameters {\n    key: \"custom_config\"\n    value {\n      field_value {\n        string_value: \"null\"\n      }\n    }\n  }\n  parameters {\n    key: \"disable_statistics\"\n    value {\n      field_value {\n        int_value: 0\n      }\n    }\n  }\n  parameters {\n    key: \"force_tf_compat_v1\"\n    value {\n      field_value {\n        int_value: 0\n      }\n    }\n  }\n  parameters {\n    key: \"module_path\"\n    value {\n      field_value {\n        string_value: \"transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl\"\n      }\n    }\n  }\n}\nupstream_nodes: \"MovieLensExampleGen\"\nupstream_nodes: \"SchemaGen\"\nexecution_options {\n  caching_options {\n  }\n}\n, pipeline_info=id: \"TestPythonTransformPipeline\"\n, pipeline_run_id='2025-10-16T23:22:01.346067', top_level_pipeline_run_id=None, frontend_url=None)\nINFO:absl:Attempting to infer TFX Python dependency for beam\nINFO:absl:Copying all content from install dir /usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx to temp dir /tmp/tmpivi6lwx9/build/tfx\nINFO:absl:Generating a temp setup file at /tmp/tmpivi6lwx9/build/tfx/setup.py\nINFO:absl:Creating temporary sdist package, logs available at /tmp/tmpivi6lwx9/build/tfx/setup.log\nINFO:absl:Added --extra_package=/tmp/tmpivi6lwx9/build/tfx/dist/tfx_ephemeral-1.16.0.tar.gz to beam args\nDEBUG:absl:Starting Executor execution.\nINFO:absl:Analyze the 'train' split and transform all splits when splits_config is not set.\nWARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\nDEBUG:absl:Using temp path /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4/.temp_path for tft.beam\nINFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl', 'preprocessing_fn': None} 'preprocessing_fn'\nINFO:absl:Installing '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl' to a temporary directory.\nINFO:absl:Executing: ['/usr/local/envs/my_tfx_env/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmp05r7g174', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl']\nINFO:absl:Successfully installed '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl'.\nINFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl', 'stats_options_updater_fn': None} 'stats_options_updater_fn'\nINFO:absl:Installing '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl' to a temporary directory.\nINFO:absl:Executing: ['/usr/local/envs/my_tfx_env/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmpeadrimhn', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl']\nINFO:absl:Successfully installed '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl'.\nINFO:absl:Installing '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl' to a temporary directory.\nINFO:absl:Executing: ['/usr/local/envs/my_tfx_env/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmpsmieis0v', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl']\nINFO:absl:Successfully installed '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl'.\nDEBUG:absl:Inputs to executor.Transform function: {'disable_statistics': False, 'schema_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3/schema.pbtxt', 'examples_data_format': 6, 'data_view_uri': None, 'analyze_data_paths': ['/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/*'], 'analyze_paths_file_formats': ['tfrecords_gzip'], 'transform_data_paths': ['/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/*', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/*', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/*'], 'transform_paths_file_formats': ['tfrecords_gzip', 'tfrecords_gzip', 'tfrecords_gzip'], 'preprocessing_fn': <function preprocessing_fn at 0x798580172b00>, 'stats_options_updater_fn': None, 'make_beam_pipeline_fn': <bound method BaseBeamExecutor._make_beam_pipeline of <tfx.components.transform.executor.Executor object at 0x798571e5f790>>, 'force_tf_compat_v1': False, 'save_options': None}\nDEBUG:absl:Outputs to executor.Transform function: {'transform_output_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4', 'transform_materialize_output_paths': ['/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-eval/transformed_examples', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-train/transformed_examples', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-test/transformed_examples'], 'temp_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4/.temp_path', 'pre_transform_output_stats_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_stats/4', 'pre_transform_output_schema_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_schema/4', 'post_transform_output_anomalies_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_anomalies/4', 'post_transform_output_stats_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_stats/4', 'post_transform_output_schema_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_schema/4', 'cache_output_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/updated_analyzer_cache/4'}\nDEBUG:absl:Force tf.compat.v1: False\nDEBUG:absl:SaveOptions: None\nDEBUG:absl:Analyze data patterns: [(0, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/*')]\nDEBUG:absl:Transform data patterns: [(0, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/*'), (1, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/*'), (2, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/*')]\nDEBUG:absl:Transform materialization output paths: [(0, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-eval/transformed_examples'), (1, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-train/transformed_examples'), (2, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-test/transformed_examples')]\nDEBUG:absl:Transform output path: /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4\nINFO:absl:Feature gender has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature age has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature genres has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature movie_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature occupation has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature rating has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature timestamp has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature user_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nDEBUG:absl:inputs={'gender': <tf.Tensor 'inputs_copy:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'inputs_1_copy:0' shape=(None, 1) dtype=int64>, 'genres': <tf.Tensor 'inputs_2_copy:0' shape=(None, 1) dtype=string>, 'movie_id': <tf.Tensor 'inputs_3_copy:0' shape=(None, 1) dtype=int64>, 'occupation': <tf.Tensor 'inputs_4_copy:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'inputs_5_copy:0' shape=(None, 1) dtype=int64>, 'timestamp': <tf.Tensor 'inputs_6_copy:0' shape=(None, 1) dtype=int64>, 'user_id': <tf.Tensor 'inputs_7_copy:0' shape=(None, 1) dtype=int64>}\nDEBUG:absl:inputs['genres']=Tensor(\"inputs_2_copy:0\", shape=(None, 1), dtype=string)\nDEBUG:absl:outputs={'user_id': <tf.Tensor 'inputs_7_copy:0' shape=(None, 1) dtype=int64>, 'movie_id': <tf.Tensor 'inputs_3_copy:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'truediv:0' shape=(None, 1) dtype=float32>, 'gender': <tf.Tensor 'one_hot:0' shape=(None, 1, 2) dtype=int64>, 'age': <tf.Tensor 'one_hot_1:0' shape=(None, 1, 7) dtype=int64>, 'occupation': <tf.Tensor 'one_hot_2:0' shape=(None, 1, 21) dtype=int64>, 'genres': tf.RaggedTensor(values=Tensor(\"truediv_1:0\", shape=(None, 18), dtype=float32), row_splits=Tensor(\"RaggedMask/mul:0\", shape=(None,), dtype=int64)), 'hr': <tf.Tensor 'FloorMod:0' shape=(None, 1) dtype=int64>, 'weekday': <tf.Tensor 'Add:0' shape=(None, 1) dtype=int64>, 'hr_wk': <tf.Tensor 'Add_1:0' shape=(None, 1) dtype=int64>, 'month': <tf.Tensor 'Cast_8:0' shape=(None, 1) dtype=int64>}\nINFO:absl:Feature gender has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature age has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature genres has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature movie_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature occupation has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature rating has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature timestamp has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature user_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nDEBUG:absl:inputs={'gender': <tf.Tensor 'inputs_copy:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'inputs_1_copy:0' shape=(None, 1) dtype=int64>, 'genres': <tf.Tensor 'inputs_2_copy:0' shape=(None, 1) dtype=string>, 'movie_id': <tf.Tensor 'inputs_3_copy:0' shape=(None, 1) dtype=int64>, 'occupation': <tf.Tensor 'inputs_4_copy:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'inputs_5_copy:0' shape=(None, 1) dtype=int64>, 'timestamp': <tf.Tensor 'inputs_6_copy:0' shape=(None, 1) dtype=int64>, 'user_id': <tf.Tensor 'inputs_7_copy:0' shape=(None, 1) dtype=int64>}\nDEBUG:absl:inputs['genres']=Tensor(\"inputs_2_copy:0\", shape=(None, 1), dtype=string)\nDEBUG:absl:outputs={'user_id': <tf.Tensor 'inputs_7_copy:0' shape=(None, 1) dtype=int64>, 'movie_id': <tf.Tensor 'inputs_3_copy:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'truediv:0' shape=(None, 1) dtype=float32>, 'gender': <tf.Tensor 'one_hot:0' shape=(None, 1, 2) dtype=int64>, 'age': <tf.Tensor 'one_hot_1:0' shape=(None, 1, 7) dtype=int64>, 'occupation': <tf.Tensor 'one_hot_2:0' shape=(None, 1, 21) dtype=int64>, 'genres': tf.RaggedTensor(values=Tensor(\"truediv_1:0\", shape=(None, 18), dtype=float32), row_splits=Tensor(\"RaggedMask/mul:0\", shape=(None,), dtype=int64)), 'hr': <tf.Tensor 'FloorMod:0' shape=(None, 1) dtype=int64>, 'weekday': <tf.Tensor 'Add:0' shape=(None, 1) dtype=int64>, 'hr_wk': <tf.Tensor 'Add_1:0' shape=(None, 1) dtype=int64>, 'month': <tf.Tensor 'Cast_8:0' shape=(None, 1) dtype=int64>}\nDEBUG:absl:inputs={'gender': <tf.Tensor 'inputs_copy:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'inputs_1_copy:0' shape=(None, 1) dtype=int64>, 'genres': <tf.Tensor 'inputs_2_copy:0' shape=(None, 1) dtype=string>, 'movie_id': <tf.Tensor 'inputs_3_copy:0' shape=(None, 1) dtype=int64>, 'occupation': <tf.Tensor 'inputs_4_copy:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'inputs_5_copy:0' shape=(None, 1) dtype=int64>, 'timestamp': <tf.Tensor 'inputs_6_copy:0' shape=(None, 1) dtype=int64>, 'user_id': <tf.Tensor 'inputs_7_copy:0' shape=(None, 1) dtype=int64>}\nDEBUG:absl:inputs['genres']=Tensor(\"inputs_2_copy:0\", shape=(None, 1), dtype=string)\nDEBUG:absl:outputs={'user_id': <tf.Tensor 'inputs_7_copy:0' shape=(None, 1) dtype=int64>, 'movie_id': <tf.Tensor 'inputs_3_copy:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'truediv:0' shape=(None, 1) dtype=float32>, 'gender': <tf.Tensor 'one_hot:0' shape=(None, 1, 2) dtype=int64>, 'age': <tf.Tensor 'one_hot_1:0' shape=(None, 1, 7) dtype=int64>, 'occupation': <tf.Tensor 'one_hot_2:0' shape=(None, 1, 21) dtype=int64>, 'genres': tf.RaggedTensor(values=Tensor(\"truediv_1:0\", shape=(None, 18), dtype=float32), row_splits=Tensor(\"RaggedMask/mul:0\", shape=(None,), dtype=int64)), 'hr': <tf.Tensor 'FloorMod:0' shape=(None, 1) dtype=int64>, 'weekday': <tf.Tensor 'Add:0' shape=(None, 1) dtype=int64>, 'hr_wk': <tf.Tensor 'Add_1:0' shape=(None, 1) dtype=int64>, 'month': <tf.Tensor 'Cast_8:0' shape=(None, 1) dtype=int64>}\nINFO:absl:Feature gender has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature age has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature genres has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature movie_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature occupation has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature rating has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature timestamp has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature user_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature gender has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature age has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature genres has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature movie_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature occupation has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature rating has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature timestamp has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature user_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature gender has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature age has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature genres has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature movie_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature occupation has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature rating has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature timestamp has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature user_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature gender has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature age has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature genres has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature movie_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature occupation has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature rating has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature timestamp has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature user_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature gender has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature age has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature genres has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature movie_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature occupation has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature rating has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature timestamp has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature user_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature gender has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature age has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature genres has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature movie_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature occupation has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature rating has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature timestamp has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature user_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nDEBUG:absl:inputs={'gender': <tf.Tensor 'inputs_copy:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'inputs_1_copy:0' shape=(None, 1) dtype=int64>, 'genres': <tf.Tensor 'inputs_2_copy:0' shape=(None, 1) dtype=string>, 'movie_id': <tf.Tensor 'inputs_3_copy:0' shape=(None, 1) dtype=int64>, 'occupation': <tf.Tensor 'inputs_4_copy:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'inputs_5_copy:0' shape=(None, 1) dtype=int64>, 'timestamp': <tf.Tensor 'inputs_6_copy:0' shape=(None, 1) dtype=int64>, 'user_id': <tf.Tensor 'inputs_7_copy:0' shape=(None, 1) dtype=int64>}\nDEBUG:absl:inputs['genres']=Tensor(\"inputs_2_copy:0\", shape=(None, 1), dtype=string)\nDEBUG:absl:outputs={'user_id': <tf.Tensor 'inputs_7_copy:0' shape=(None, 1) dtype=int64>, 'movie_id': <tf.Tensor 'inputs_3_copy:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'truediv:0' shape=(None, 1) dtype=float32>, 'gender': <tf.Tensor 'one_hot:0' shape=(None, 1, 2) dtype=int64>, 'age': <tf.Tensor 'one_hot_1:0' shape=(None, 1, 7) dtype=int64>, 'occupation': <tf.Tensor 'one_hot_2:0' shape=(None, 1, 21) dtype=int64>, 'genres': tf.RaggedTensor(values=Tensor(\"truediv_1:0\", shape=(None, 18), dtype=float32), row_splits=Tensor(\"RaggedMask/mul:0\", shape=(None,), dtype=int64)), 'hr': <tf.Tensor 'FloorMod:0' shape=(None, 1) dtype=int64>, 'weekday': <tf.Tensor 'Add:0' shape=(None, 1) dtype=int64>, 'hr_wk': <tf.Tensor 'Add_1:0' shape=(None, 1) dtype=int64>, 'month': <tf.Tensor 'Cast_8:0' shape=(None, 1) dtype=int64>}\nDEBUG:absl:inputs={'gender': <tf.Tensor 'inputs_copy:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'inputs_1_copy:0' shape=(None, 1) dtype=int64>, 'genres': <tf.Tensor 'inputs_2_copy:0' shape=(None, 1) dtype=string>, 'movie_id': <tf.Tensor 'inputs_3_copy:0' shape=(None, 1) dtype=int64>, 'occupation': <tf.Tensor 'inputs_4_copy:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'inputs_5_copy:0' shape=(None, 1) dtype=int64>, 'timestamp': <tf.Tensor 'inputs_6_copy:0' shape=(None, 1) dtype=int64>, 'user_id': <tf.Tensor 'inputs_7_copy:0' shape=(None, 1) dtype=int64>}\nDEBUG:absl:inputs['genres']=Tensor(\"inputs_2_copy:0\", shape=(None, 1), dtype=string)\nDEBUG:absl:outputs={'user_id': <tf.Tensor 'inputs_7_copy:0' shape=(None, 1) dtype=int64>, 'movie_id': <tf.Tensor 'inputs_3_copy:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'truediv:0' shape=(None, 1) dtype=float32>, 'gender': <tf.Tensor 'one_hot:0' shape=(None, 1, 2) dtype=int64>, 'age': <tf.Tensor 'one_hot_1:0' shape=(None, 1, 7) dtype=int64>, 'occupation': <tf.Tensor 'one_hot_2:0' shape=(None, 1, 21) dtype=int64>, 'genres': tf.RaggedTensor(values=Tensor(\"truediv_1:0\", shape=(None, 18), dtype=float32), row_splits=Tensor(\"RaggedMask/mul:0\", shape=(None,), dtype=int64)), 'hr': <tf.Tensor 'FloorMod:0' shape=(None, 1) dtype=int64>, 'weekday': <tf.Tensor 'Add:0' shape=(None, 1) dtype=int64>, 'hr_wk': <tf.Tensor 'Add_1:0' shape=(None, 1) dtype=int64>, 'month': <tf.Tensor 'Cast_8:0' shape=(None, 1) dtype=int64>}\nDEBUG:absl:inputs={'gender': <tf.Tensor 'inputs_copy:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'inputs_1_copy:0' shape=(None, 1) dtype=int64>, 'genres': <tf.Tensor 'inputs_2_copy:0' shape=(None, 1) dtype=string>, 'movie_id': <tf.Tensor 'inputs_3_copy:0' shape=(None, 1) dtype=int64>, 'occupation': <tf.Tensor 'inputs_4_copy:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'inputs_5_copy:0' shape=(None, 1) dtype=int64>, 'timestamp': <tf.Tensor 'inputs_6_copy:0' shape=(None, 1) dtype=int64>, 'user_id': <tf.Tensor 'inputs_7_copy:0' shape=(None, 1) dtype=int64>}\nDEBUG:absl:inputs['genres']=Tensor(\"inputs_2_copy:0\", shape=(None, 1), dtype=string)\nDEBUG:absl:outputs={'user_id': <tf.Tensor 'inputs_7_copy:0' shape=(None, 1) dtype=int64>, 'movie_id': <tf.Tensor 'inputs_3_copy:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'truediv:0' shape=(None, 1) dtype=float32>, 'gender': <tf.Tensor 'one_hot:0' shape=(None, 1, 2) dtype=int64>, 'age': <tf.Tensor 'one_hot_1:0' shape=(None, 1, 7) dtype=int64>, 'occupation': <tf.Tensor 'one_hot_2:0' shape=(None, 1, 21) dtype=int64>, 'genres': tf.RaggedTensor(values=Tensor(\"truediv_1:0\", shape=(None, 18), dtype=float32), row_splits=Tensor(\"RaggedMask/mul:0\", shape=(None,), dtype=int64)), 'hr': <tf.Tensor 'FloorMod:0' shape=(None, 1) dtype=int64>, 'weekday': <tf.Tensor 'Add:0' shape=(None, 1) dtype=int64>, 'hr_wk': <tf.Tensor 'Add_1:0' shape=(None, 1) dtype=int64>, 'month': <tf.Tensor 'Cast_8:0' shape=(None, 1) dtype=int64>}\nWARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: key_value_init/LookupTableImportV2\nWARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: key_value_init_1/LookupTableImportV2\nWARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: key_value_init_2/LookupTableImportV2\nDEBUG:absl:inputs={'gender': <tf.Tensor 'PlaceholderWithDefault:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'PlaceholderWithDefault_1:0' shape=(None, 1) dtype=int64>, 'genres': <tf.Tensor 'PlaceholderWithDefault_2:0' shape=(None, 1) dtype=string>, 'movie_id': <tf.Tensor 'PlaceholderWithDefault_3:0' shape=(None, 1) dtype=int64>, 'occupation': <tf.Tensor 'PlaceholderWithDefault_4:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'PlaceholderWithDefault_5:0' shape=(None, 1) dtype=int64>, 'timestamp': <tf.Tensor 'PlaceholderWithDefault_6:0' shape=(None, 1) dtype=int64>, 'user_id': <tf.Tensor 'PlaceholderWithDefault_7:0' shape=(None, 1) dtype=int64>}\nDEBUG:absl:inputs['genres']=Tensor(\"PlaceholderWithDefault_2:0\", shape=(None, 1), dtype=string)\nDEBUG:absl:outputs={'user_id': <tf.Tensor 'PlaceholderWithDefault_7:0' shape=(None, 1) dtype=int64>, 'movie_id': <tf.Tensor 'PlaceholderWithDefault_3:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'truediv:0' shape=(None, 1) dtype=float32>, 'gender': <tf.Tensor 'one_hot:0' shape=(None, 1, 2) dtype=int64>, 'age': <tf.Tensor 'one_hot_1:0' shape=(None, 1, 7) dtype=int64>, 'occupation': <tf.Tensor 'one_hot_2:0' shape=(None, 1, 21) dtype=int64>, 'genres': tf.RaggedTensor(values=Tensor(\"truediv_1:0\", shape=(None, 18), dtype=float32), row_splits=Tensor(\"RaggedMask/mul:0\", shape=(None,), dtype=int64)), 'hr': <tf.Tensor 'FloorMod:0' shape=(None, 1) dtype=int64>, 'weekday': <tf.Tensor 'Add:0' shape=(None, 1) dtype=int64>, 'hr_wk': <tf.Tensor 'Add_1:0' shape=(None, 1) dtype=int64>, 'month': <tf.Tensor 'Cast_8:0' shape=(None, 1) dtype=int64>}\nDEBUG:absl:Using existing cache in: None\nINFO:absl:Feature gender has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature age has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature genres has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature movie_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature occupation has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature rating has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature timestamp has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature user_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature gender has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature age has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature genres has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature movie_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature occupation has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature rating has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature timestamp has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature user_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature gender has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature age has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature genres has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature movie_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature occupation has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature rating has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature timestamp has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature user_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature gender has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature age has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature genres has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature movie_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature occupation has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature rating has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature timestamp has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature user_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature gender has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature age has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature genres has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature movie_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature occupation has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature rating has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature timestamp has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature user_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature gender has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature age has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature genres has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature movie_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature occupation has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature rating has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature timestamp has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nINFO:absl:Feature user_id has a shape dim {\n  size: 1\n}\n. Setting to DenseTensor.\nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656997   nanos: 400657653 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656997   nanos: 409518003 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656997   nanos: 446691036 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656997   nanos: 456473112 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656997   nanos: 526129484 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656997   nanos: 522743463 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656997   nanos: 532611131 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760656997   nanos: 534759759 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760657003   nanos: 613849639 } message: \"Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: key_value_init/LookupTableImportV2\" instruction_id: \"bundle_369\" transform_id: \"Analyze/CreateSavedModel[tf_v2_only]/CreateSavedModel\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow_transform/graph_tools.py:592\" thread: \"Thread-14\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760657003   nanos: 617060661 } message: \"Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: key_value_init_1/LookupTableImportV2\" instruction_id: \"bundle_369\" transform_id: \"Analyze/CreateSavedModel[tf_v2_only]/CreateSavedModel\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow_transform/graph_tools.py:592\" thread: \"Thread-14\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760657003   nanos: 617988109 } message: \"Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: key_value_init_2/LookupTableImportV2\" instruction_id: \"bundle_369\" transform_id: \"Analyze/CreateSavedModel[tf_v2_only]/CreateSavedModel\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow_transform/graph_tools.py:592\" thread: \"Thread-14\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760657009   nanos: 826362848 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_494\" transform_id: \"TFXIOReadAndDecode[TransformIndex1]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760657009   nanos: 830830812 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_495\" transform_id: \"TFXIOReadAndDecode[TransformIndex1]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-14\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760657009   nanos: 838033199 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_493\" transform_id: \"TFXIOReadAndDecode[TransformIndex1]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-14\" \nWARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760657009   nanos: 843804597 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_496\" transform_id: \"TFXIOReadAndDecode[TransformIndex1]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-14\" \nException ignored in: <function AtomicFunction.__del__ at 0x7dca2ce9c820>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7dca2ce9c820>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7dca2ce9c820>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7dca2ce9c820>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7dca2ce9c820>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7dca2ce9c820>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7dca2ce9c820>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7c5b49145360>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7c5b49145360>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7c5b49145360>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7c5b49145360>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7c5b49145360>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7c5b49145360>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7c5b49145360>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7f7d0a2a4700>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7f7d0a2a4700>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7f7d0a2a4700>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7f7d0a2a4700>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7f7d0a2a4700>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7f7d0a2a4700>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nException ignored in: <function AtomicFunction.__del__ at 0x7f7d0a2a4700>\nTraceback (most recent call last):\n  File \"/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\nTypeError: 'NoneType' object is not subscriptable\nDEBUG:absl:Cleaning up temp path /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4/.temp_path on executor success\nINFO:absl:Cleaning up stateless execution info.\nINFO:absl:Execution 4 succeeded.\nINFO:absl:Cleaning up stateful execution info.\nINFO:absl:Deleted stateful_working_dir /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/.system/stateful_working_dir/d834ed82-2114-42cb-ba02-1a365af0e104\nINFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'pre_transform_schema': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_schema/4\"\n, artifact_type: name: \"Schema\"\n)], 'post_transform_stats': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_stats/4\"\n, artifact_type: name: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)], 'transformed_examples': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4\"\n, artifact_type: name: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n)], 'post_transform_anomalies': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_anomalies/4\"\n, artifact_type: name: \"ExampleAnomalies\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\n)], 'pre_transform_stats': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_stats/4\"\n, artifact_type: name: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n)], 'transform_graph': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4\"\n, artifact_type: name: \"TransformGraph\"\n)], 'updated_analyzer_cache': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/updated_analyzer_cache/4\"\n, artifact_type: name: \"TransformCache\"\n)], 'post_transform_schema': [Artifact(artifact: uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_schema/4\"\n, artifact_type: name: \"Schema\"\n)]}) for execution 4\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nINFO:absl:Component Transform is finished.\nINFO:absl:MetadataStore with DB connection initialized\nDEBUG:absl:ConnectionConfig: sqlite {\n  filename_uri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\"\n  connection_mode: READWRITE_OPENCREATE\n}\n\nDEBUG:absl:MLMD store artifact_types=[id: 15\nname: \"Examples\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nproperties {\n  key: \"version\"\n  value: INT\n}\nbase_type: DATASET\n, id: 17\nname: \"ExampleStatistics\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\nbase_type: STATISTICS\n, id: 19\nname: \"Schema\"\n, id: 21\nname: \"ExampleAnomalies\"\nproperties {\n  key: \"span\"\n  value: INT\n}\nproperties {\n  key: \"split_names\"\n  value: STRING\n}\n, id: 22\nname: \"TransformGraph\"\n, id: 23\nname: \"TransformCache\"\n]\nDEBUG:absl:MLMD store artifacts=[id: 1\ntype_id: 15\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\nproperties {\n  key: \"version\"\n  value {\n    int_value: 1\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Examples\"\ncreate_time_since_epoch: 1760656952744\nlast_update_time_since_epoch: 1760656952744\n, id: 2\ntype_id: 17\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2\"\nproperties {\n  key: \"span\"\n  value {\n    int_value: 0\n  }\n}\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"sample_rate_by_split\"\n  value {\n    struct_value {\n      fields {\n        key: \"__value__\"\n        value {\n          string_value: \"{\\\"eval\\\": 1.0, \\\"test\\\": 1.0, \\\"train\\\": 1.0}\"\n        }\n      }\n    }\n  }\n}\ncustom_properties {\n  key: \"stats_dashboard_link\"\n  value {\n    string_value: \"\"\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"ExampleStatistics\"\ncreate_time_since_epoch: 1760656978732\nlast_update_time_since_epoch: 1760656978732\n, id: 3\ntype_id: 19\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3\"\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Schema\"\ncreate_time_since_epoch: 1760656978855\nlast_update_time_since_epoch: 1760656978855\n, id: 4\ntype_id: 19\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_schema/4\"\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Schema\"\ncreate_time_since_epoch: 1760657026298\nlast_update_time_since_epoch: 1760657026298\n, id: 5\ntype_id: 17\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_stats/4\"\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"ExampleStatistics\"\ncreate_time_since_epoch: 1760657026298\nlast_update_time_since_epoch: 1760657026298\n, id: 6\ntype_id: 15\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4\"\nproperties {\n  key: \"split_names\"\n  value {\n    string_value: \"[\\\"eval\\\", \\\"train\\\", \\\"test\\\"]\"\n  }\n}\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Examples\"\ncreate_time_since_epoch: 1760657026299\nlast_update_time_since_epoch: 1760657026299\n, id: 7\ntype_id: 21\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_anomalies/4\"\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"ExampleAnomalies\"\ncreate_time_since_epoch: 1760657026299\nlast_update_time_since_epoch: 1760657026299\n, id: 8\ntype_id: 17\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_stats/4\"\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"ExampleStatistics\"\ncreate_time_since_epoch: 1760657026299\nlast_update_time_since_epoch: 1760657026299\n, id: 9\ntype_id: 22\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4\"\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"TransformGraph\"\ncreate_time_since_epoch: 1760657026299\nlast_update_time_since_epoch: 1760657026299\n, id: 10\ntype_id: 23\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/updated_analyzer_cache/4\"\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"TransformCache\"\ncreate_time_since_epoch: 1760657026299\nlast_update_time_since_epoch: 1760657026299\n, id: 11\ntype_id: 19\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_schema/4\"\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"Schema\"\ncreate_time_since_epoch: 1760657026299\nlast_update_time_since_epoch: 1760657026299\n]\nDEBUG:absl:MLMD store executions=[id: 1\ntype_id: 13\nlast_known_state: COMPLETE\ncustom_properties {\n  key: \"infiles_dict_ser\"\n  value {\n    string_value: \"gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==\"\n  }\n}\ncustom_properties {\n  key: \"output_config_ser\"\n  value {\n    string_value: \"Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK\"\n  }\n}\nname: \"21bd8a35-1f7e-462d-8056-23ab4525f9f6\"\ntype: \"ingest_movie_lens_component.MovieLensExampleGen\"\ncreate_time_since_epoch: 1760656921488\nlast_update_time_since_epoch: 1760656952744\n, id: 2\ntype_id: 16\nlast_known_state: COMPLETE\ncustom_properties {\n  key: \"exclude_splits\"\n  value {\n    string_value: \"[]\"\n  }\n}\nname: \"48d2f50f-b755-4b07-ba33-44bc455bf000\"\ntype: \"tfx.components.statistics_gen.component.StatisticsGen\"\ncreate_time_since_epoch: 1760656952799\nlast_update_time_since_epoch: 1760656978732\n, id: 3\ntype_id: 18\nlast_known_state: COMPLETE\ncustom_properties {\n  key: \"exclude_splits\"\n  value {\n    string_value: \"[]\"\n  }\n}\ncustom_properties {\n  key: \"infer_feature_shape\"\n  value {\n    int_value: 1\n  }\n}\nname: \"a5075e9c-055f-4cf3-ae3f-cfa3295967f3\"\ntype: \"tfx.components.schema_gen.component.SchemaGen\"\ncreate_time_since_epoch: 1760656978790\nlast_update_time_since_epoch: 1760656978856\n, id: 4\ntype_id: 20\nlast_known_state: COMPLETE\ncustom_properties {\n  key: \"custom_config\"\n  value {\n    string_value: \"null\"\n  }\n}\ncustom_properties {\n  key: \"disable_statistics\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"force_tf_compat_v1\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"module_path\"\n  value {\n    string_value: \"transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+0b7b064cb9dcb4637476bc7cd0a8c78632c3ca089b039f2059496b531afa4162-py3-none-any.whl\"\n  }\n}\nname: \"87854c0a-c459-4fde-ac8e-d3fcef6b8fe4\"\ntype: \"tfx.components.transform.component.Transform\"\ncreate_time_since_epoch: 1760656978916\nlast_update_time_since_epoch: 1760657026299\n]\nDEBUG:absl:ratings_transform.id=Transform\nDEBUG:absl:ratings_transform=Transform(spec: <tfx.types.standard_component_specs.TransformSpec object at 0x7985825cf9d0>, executor_spec: <tfx.dsl.components.base.executor_spec.BeamExecutorSpec object at 0x7985825ced70>, driver_class: <class 'tfx.dsl.components.base.base_driver.BaseDriver'>, component_id: Transform, inputs: {'examples': OutputChannel(artifact_type=Examples, producer_component_id=MovieLensExampleGen, output_key=output_examples, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False), 'schema': OutputChannel(artifact_type=Schema, producer_component_id=SchemaGen, output_key=schema, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False)}, outputs: {'transform_graph': OutputChannel(artifact_type=TransformGraph, producer_component_id=Transform, output_key=transform_graph, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False), 'transformed_examples': OutputChannel(artifact_type=Examples, producer_component_id=Transform, output_key=transformed_examples, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False), 'updated_analyzer_cache': OutputChannel(artifact_type=TransformCache, producer_component_id=Transform, output_key=updated_analyzer_cache, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False), 'pre_transform_schema': OutputChannel(artifact_type=Schema, producer_component_id=Transform, output_key=pre_transform_schema, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False), 'pre_transform_stats': OutputChannel(artifact_type=ExampleStatistics, producer_component_id=Transform, output_key=pre_transform_stats, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False), 'post_transform_schema': OutputChannel(artifact_type=Schema, producer_component_id=Transform, output_key=post_transform_schema, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False), 'post_transform_stats': OutputChannel(artifact_type=ExampleStatistics, producer_component_id=Transform, output_key=post_transform_stats, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False), 'post_transform_anomalies': OutputChannel(artifact_type=ExampleAnomalies, producer_component_id=Transform, output_key=post_transform_anomalies, additional_properties={}, additional_custom_properties={}, _input_trigger=None, _is_async=False)})\nDEBUG:absl:transform_graph_list=[id: 9\ntype_id: 22\nuri: \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4\"\ncustom_properties {\n  key: \"is_external\"\n  value {\n    int_value: 0\n  }\n}\ncustom_properties {\n  key: \"tfx_version\"\n  value {\n    string_value: \"1.16.0\"\n  }\n}\nstate: LIVE\ntype: \"TransformGraph\"\ncreate_time_since_epoch: 1760657026299\nlast_update_time_since_epoch: 1760657026299\n]\nDEBUG:absl:transform_graph_uri=/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4\n.s\n----------------------------------------------------------------------\nRan 2 tests in 105.504s\n\nOK (skipped=1)\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"!find /kaggle/working -type f","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:49:48.683894Z","iopub.execute_input":"2025-10-16T21:49:48.684220Z","iopub.status.idle":"2025-10-16T21:49:48.819299Z","shell.execute_reply.started":"2025-10-16T21:49:48.684196Z","shell.execute_reply":"2025-10-16T21:49:48.817854Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ingest_movie_lens_custom_component_test.py\n/kaggle/working/ingest_movie_lens_component_test.py\n/kaggle/working/__pycache__/ingest_movie_lens_component_test.cpython-310.pyc\n/kaggle/working/__pycache__/CustomUTF8Coder.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_component.cpython-310.pyc\n/kaggle/working/__pycache__/csv_example_gen_test.cpython-310.pyc\n/kaggle/working/__pycache__/helper.cpython-310.pyc\n/kaggle/working/__pycache__/transform_movie_lens.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils_test.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_beam_test.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_custom_component.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_beam.cpython-310.pyc\n/kaggle/working/__pycache__/ingest_movie_lens_custom_component_test.cpython-310.pyc\n/kaggle/working/__pycache__/transform_movie_lens_test.cpython-310.pyc\n/kaggle/working/__pycache__/movie_lens_utils.cpython-310.pyc\n/kaggle/working/ingest_movie_lens_beam_test.py\n/kaggle/working/ml-1m/users.dat\n/kaggle/working/ml-1m/users_100.dat\n/kaggle/working/ml-1m/README\n/kaggle/working/ml-1m/tmp/users2.dat\n/kaggle/working/ml-1m/movies.dat\n/kaggle/working/ml-1m/ratings_1000.dat\n/kaggle/working/ml-1m/ratings.dat\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-train/FeatureStats.pb\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-eval/FeatureStats.pb\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-test/FeatureStats.pb\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3/schema.pbtxt\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+6c73c1a9104c899a385b9c64a995d4b4f4a5d49903e86d43348f0597fc43199f-py3-none-any.whl\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00002-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00000-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00003-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00001-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00002-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00000-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00003-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00001-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00002-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00000-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00003-of-00004.tfrecord\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00001-of-00004.tfrecord\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/statistics/2/Split-train/FeatureStats.pb\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/statistics/2/Split-eval/FeatureStats.pb\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/StatisticsGen/statistics/2/Split-test/FeatureStats.pb\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/SchemaGen/schema/3/schema.pbtxt\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_1/testRun2/TestFullyCustomCompPipeline/IngestMovieLensComponent/output_examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/fully_custom_comp_2/testDo/output_examples/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-train/FeatureStats.pb\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-eval/FeatureStats.pb\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/StatisticsGen/statistics/2/Split-test/FeatureStats.pb\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/tfx_metadata/metadata.db\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/SchemaGen/schema/3/schema.pbtxt\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord-00000-of-00001.tfrecord\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-train/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-eval/data_tfrecord-00000-of-00001.gz\n/kaggle/working/bin/csv_comp_1/testRun/test_csvgenexample/CsvExampleGen/examples/1/Split-test/data_tfrecord-00000-of-00001.gz\n/kaggle/working/ingest_movie_lens_beam.py\n/kaggle/working/transform_movie_lens_test.py\n/kaggle/working/transform_movie_lens.py\n/kaggle/working/helper.py\n/kaggle/working/ingest_movie_lens_beam_pa_test.py\n/kaggle/working/csv_example_gen_test.py\n/kaggle/working/CustomUTF8Coder.py\n/kaggle/working/ingest_movie_lens_beam_pa.py\n/kaggle/working/ingest_movie_lens_custom_component.py\n/kaggle/working/ingest_movie_lens_component.py\n/kaggle/working/dataset_tfxio_example.py\n/kaggle/working/movie_lens_utils_test.py\n/kaggle/working/movie_lens_utils.py\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## 4. EDA\n\ninstall and import polars, matplotlib, seaborn, dcor, scipystats, tensorflow","metadata":{}},{"cell_type":"code","source":"!pip install -q tensorflow\n!pip install -q polars[all]\n!pip install seaborn\n!pip install -q matplotlib\n!pip install dcor\n\n#restart the kernel\nfrom IPython import get_ipython\nipython = get_ipython()\nif ipython is not None:\n    ipython.kernel.do_shutdown(restart=True)\n    print(\"Jupyter kernel is restarting...\")\nelse:\n    print(\"Not running in an IPython/Jupyter environment.\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-16T23:31:39.217Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport polars as pl\nimport matplotlib.pyplot as plt\n#seaborn version installed is 0.12.2.  need>= 0.13.0 for polars\nimport seaborn as sns\nfrom scipy.stats.distributions import chi2\n\npl.Config.set_fmt_str_lengths(900)\n\nprint(sns.__version__)\n\n### 4.a. EDA on raw data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:49:48.821107Z","iopub.execute_input":"2025-10-16T21:49:48.821454Z","iopub.status.idle":"2025-10-16T21:52:31.600323Z","shell.execute_reply.started":"2025-10-16T21:49:48.821421Z","shell.execute_reply":"2025-10-16T21:52:31.599305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#https://pmc.ncbi.nlm.nih.gov/articles/PMC9191842/#:~:text=The%20chi%2Dsquare%20test%20is%20well%20behaved%20from%20the%20following,%E2%88%92%201%20(%201%20%E2%88%92%20%CE%B1%20)\n#The Chi-Square Test of Distance Correlation\n\n# a distance covariance-based chi-square test to test for independence \n# between two variables by calculating the bias-corrected sample \n# distance correlation and comparing it to a chi-square distribution. \n# handles both continuous and categorical data\n\nimport dcor\ndef can_reject_indep(x : np.array, y:np.array, alpha:float = 0.05, debug:bool=False):\n  \"\"\"\n  reject independe for \n    n*C >= inv(F{chi^2-1})(1-alpha)\n    where n = len(x)\n      C = fast distance covariance following 2019 Chaudhuri and Hu\n      inv(F{chi^2-1}) is the inverse of the CDF.\n  \"\"\"\n  with np.errstate(divide='ignore'):\n    C = dcor.distance_covariance(x, y, method='mergesort')\n  lhs = len(x)*C\n  rhs = chi2.ppf(1-alpha, df=x.shape[-1])\n  if debug:\n    print(f\"nC={lhs}\\nppf(1-{alpha}, dof={x.shape[-1]})={rhs}\")\n  return lhs >= rhs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:52:31.602384Z","iopub.execute_input":"2025-10-16T21:52:31.602914Z","iopub.status.idle":"2025-10-16T21:52:31.996646Z","shell.execute_reply.started":"2025-10-16T21:52:31.602884Z","shell.execute_reply":"2025-10-16T21:52:31.995052Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/4254598131.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# handles both continuous and categorical data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdcor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcan_reject_indep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \"\"\"\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dcor'"],"ename":"ModuleNotFoundError","evalue":"No module named 'dcor'","output_type":"error"}],"execution_count":23},{"cell_type":"code","source":"#EDA for raw data\nfrom collections import OrderedDict\nimport re\nimport io\nfrom datetime import datetime\nimport pytz\n\nprint(sns.__version__)\n\nCTZ = pytz.timezone(\"America/Chicago\")\ngenres = [\"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n          \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\",\n          \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\",\n          \"Thriller\", \"War\", \"Western\"]\n\nschemas = {\n  'ratings' : pl.Schema(OrderedDict({'user_id': pl.Int64, \n    'movie_id': pl.Int64, 'rating': pl.Int64,\n    'timestamp' : pl.Int64})),\n  'users' : pl.Schema(OrderedDict({'user_id': pl.Int64, \n    'gender': pl.String, 'age': pl.Int64,\n    'occupation' : pl.Int64, \n    'zipcode' : pl.String})),\n  'movies' : pl.Schema(OrderedDict({'movie_id': pl.Int64, \n    'title': pl.String, 'genres': pl.String}))}\n\nfile_paths = {\n  'ratings':'/kaggle/working/ml-1m/ratings.dat',\n  'users':'/kaggle/working/ml-1m/users.dat',\n  'movies':'/kaggle/working/ml-1m/movies.dat'\n}\n\n#polars.read_csv( source=\n#  encoding='iso-8859-1', \n#  has_header=False, skip_rows=0, try_parse_dates=True, \n#  use_pyarrow=True\n\nlabels_dict = {}\nlabels_dict['age_group'] = {0:'1', 1:'18', 2:'25', 3:'35', 4:'45', 5:'50', 6:'56'} \nlabels_dict['gender'] = {0:'F', 1:'M'}\nlabels_dict['occupation'] = {0:  \"other\", 1:  \"academic/educator\", 2:  \"artist\", 3:  \"clerical/admin\", 4:  \"college/grad student\", 5:  \"customer service\", \\\n    6:  \"doctor/health care\", 7:  \"executive/managerial\", 8:  \"farmer\", 9:  \"homemaker\", 10:  \"K-12 student\", 11:  \"lawyer\", 12:  \"programmer\", \\\n    13:  \"retired\", 14:  \"sales/marketing\", 15:  \"scientist\", 16:  \"self-employed\", 17:  \"technician/engineer\", 18:  \"tradesman/craftsman\", \\\n    19:  \"unemployed\", 20:  \"writer\"}\nlabels_dict_arrays = {}\nfor k in labels_dict:\n    labels_dict_arrays[k]=[labels_dict[k][k2] for k2 in labels_dict[k]]\n\nfor key in file_paths:\n    processed_buffer = io.StringIO()\n    file_path = file_paths[key]\n    schema = schemas[key]\n    print(f\"key={key}, file_path={file_path}\")\n    with open(file_path, \"r\", encoding='iso-8859-1') as file:\n        for line in file:\n            line2 = line.replace('::', '\\t')\n            processed_buffer.write(line2)\n    \n    processed_buffer.seek(0)\n    df = pl.read_csv(processed_buffer,\\\n        encoding='iso-8859-1', has_header=False, \\\n        skip_rows=0, separator='\\t', schema=schema,\\\n        try_parse_dates=True, \\\n        new_columns=schema.names(), \\\n        use_pyarrow=True)\n\n    if key==\"movies\":\n        df = df.with_columns(\n          pl.col(\"genres\").str.replace(\"Children's\", \"Children\")\n        )\n        df = df.with_columns(\n          pl.col(\"genres\").str.split(\"|\")\n        )\n        movie_genres = df.explode('genres')\n        ordered = movie_genres['genres'].value_counts().index\n        sns.catplot(data=movie_genres, y=\"genres\",  \n          kind=\"count\", order=ordered).set(title='Movie genres')\n        plt.show()\n                  \n    if key==\"ratings\":\n        #user_id, movie_id, rating, timestamp\n        g = sns.catplot(data=df, x='rating',  kind=\"count\").set(title='rating')\n        local_time = datetime.fromtimestamp(df[\"timestamp\"], tz=CTZ)\n        df[\"hr\"] = int(round(local_time.hour + (local_time.minute / 60.)))\n        df[\"weekday\"] = local_time.weekday()\n        df[\"hr_wk\"] = df[\"hr\"] * 7 + df[\"weekday\"]\n        g = sns.catplot(data=df, x='hr',  kind=\"count\").set(title='hr of day')\n        g = sns.catplot(data=df, x='weekday',  kind=\"count\").set(title='weekday')\n        g = sns.catplot(data=df, x='hr_wk',  kind=\"count\").set(title='hr of weekday')\n        plt.show()\n        x = df.select(pl.col(\"rating\")).to_numpy()\n        y = df.select(pl.col(\"hr_wk\")).to_numpy()\n        print(f\"rating, hr_wk are indep: {can_reject_indep(x,y,0.05,True)}\")\n\n    if key==\"users\":\n        #user_id, gender, age, occupation, zipcode\n        g = sns.catplot(data=df, x='gender',  kind=\"count\").set(title='gender')\n        g = sns.catplot(data=df, x='age',  kind=\"count\").set(title='age')\n        g = sns.catplot(data=df, x='occupation',  kind=\"count\").set(title='occupation')\n        plt.show()\n        \n","metadata":{"execution":{"iopub.status.busy":"2025-10-16T21:52:31.997587Z","iopub.status.idle":"2025-10-16T21:52:31.998071Z","shell.execute_reply.started":"2025-10-16T21:52:31.997824Z","shell.execute_reply":"2025-10-16T21:52:31.997847Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4.b. EDA on raw left-joined data, split into train, eval, test","metadata":{}},{"cell_type":"code","source":"#enable/disable by toggling from Markdown to Code\n#\"\"\"\n\n#TODO: finish here\n\nprint(f\"tf.executing_eagerly()={tf.executing_eagerly()}\")\n\ntfrecord_path = \"/kaggle/working/bin/py_custom_comp_1/test_MovieLensExampleGen/TestPythonFuncCustomCompPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord-00000-of-00001.tfrecord\"\n\ndef get_expected_col_name_feature_types():\n  return {\"user_id\": tf.io.FixedLenFeature([], tf.int64),\n    \"movie_id\":tf.io.FixedLenFeature([], tf.int64),\n    \"rating\" : tf.io.FixedLenFeature([], tf.int64),\n    \"timestamp\" : tf.io.FixedLenFeature([], tf.int64),\n    \"gender\" : tf.io.FixedLenFeature([], tf.string),\n    \"age\" : tf.io.FixedLenFeature([], tf.int64), \n    \"occupation\" : tf.io.FixedLenFeature([], tf.int64),\n    \"genres\" : tf.io.FixedLenFeature([], tf.string)}\n\ncol_name_feature_types = get_expected_col_name_feature_types()\n\ndef _parse_function(example_proto):\n  return tf.io.parse_single_example(example_proto, col_name_feature_types)\n\ndataset = tf.data.TFRecordDataset(tfrecord_path)\nparsed_dataset = dataset.map(_parse_function)\n\ntry:\n  for parsed_example in parsed_dataset.take(1):\n    pass\nexcept Exception as e:\n  print(e)\n\ntry:\n  for tfrecord in dataset.take(1):\n    example = tf.train.Example()\n    example.ParseFromString(tfrecord.numpy())\n    #print(f\"EXAMPLE={example}\")\nexcept Exception as e:\n  print(e)     \n\ndata_list = []\nfor record in parsed_dataset:\n    row = {\n        'user_id': record['user_id'].numpy(),\n        'movie_id': record['movie_id'].numpy(),\n        'rating': record['rating'].numpy(),\n        'age': record['age'].numpy(),\n        'occupation': record['occupation'].numpy(),\n        'genres': record['genres'].numpy().decode('utf-8'),\n        'gender': record['gender'].numpy().decode('utf-8'),\n    }\n    data_list.append(row)\n\n# Create the Polars DataFrame from the list of dictionaries\ndf = pl.from_records(data_list)\n\ngender_enum = pl.Enum(['M', 'F'])\ngenres_enum = pl.Enum([\"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n          \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\",\n          \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\",\n          \"Thriller\", \"War\", \"Western\"])\n\n#enums have to be strings\n#age_enum = pl.Enum([1, 18, 25, 35, 45, 50, 56])\n#df['age'].dtype = age_enum\n\ndf['gender'].cast(gender_enum)\n\n# after splits, can use:\n#df['genres'].cast(genres_enum)\n\ndf.null_count()\n\ndf.describe()\ndf.head()\n#\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T21:52:32.000219Z","iopub.status.idle":"2025-10-16T21:52:32.000669Z","shell.execute_reply.started":"2025-10-16T21:52:32.000512Z","shell.execute_reply":"2025-10-16T21:52:32.000530Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4.c. EDA on transformed train, eval, test","metadata":{}},{"cell_type":"code","source":"#/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/\n    #   MovieLensExampleGen/output_examples/1/\n    #   Split-<train, eval, or test>/data_tfrecord-0000?-of-00004.tfrecord\n\n# \"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/\n    #   Transform/transformed_examples/4\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(sns.__version__)\n!pip show seaborn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T22:19:03.081905Z","iopub.execute_input":"2025-10-16T22:19:03.082335Z","iopub.status.idle":"2025-10-16T22:19:03.876567Z","shell.execute_reply.started":"2025-10-16T22:19:03.082305Z","shell.execute_reply":"2025-10-16T22:19:03.874764Z"}},"outputs":[{"name":"stdout","text":"0.12.2\nName: seaborn\nVersion: 0.13.2\nSummary: Statistical data visualization\nHome-page: \nAuthor: \nAuthor-email: Michael Waskom <mwaskom@gmail.com>\nLicense: \nLocation: /usr/local/lib/python3.13/site-packages\nRequires: matplotlib, numpy, pandas\nRequired-by: \n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"#!find /kaggle/working/bin -type d -name \"transformed_examples\" | xargs ls -lR\n!find /kaggle/working/bin -type f -iname \"transformed_examples*.gz\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T23:04:09.975634Z","iopub.execute_input":"2025-10-16T23:04:09.976204Z","iopub.status.idle":"2025-10-16T23:04:10.131038Z","shell.execute_reply.started":"2025-10-16T23:04:09.976163Z","shell.execute_reply":"2025-10-16T23:04:10.128954Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-train/transformed_examples-00000-of-00004.gz\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-train/transformed_examples-00002-of-00004.gz\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-train/transformed_examples-00001-of-00004.gz\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-train/transformed_examples-00003-of-00004.gz\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-eval/transformed_examples-00000-of-00004.gz\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-eval/transformed_examples-00002-of-00004.gz\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-eval/transformed_examples-00001-of-00004.gz\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-eval/transformed_examples-00003-of-00004.gz\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-test/transformed_examples-00000-of-00004.gz\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-test/transformed_examples-00002-of-00004.gz\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-test/transformed_examples-00001-of-00004.gz\n/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-test/transformed_examples-00003-of-00004.gz\n","output_type":"stream"}],"execution_count":42}]}