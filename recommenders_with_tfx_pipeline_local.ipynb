{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "567a22b5-ead8-4cf5-9bcf-cc0984cfbaf7",
   "metadata": {},
   "source": [
    "# Movie Lens MLOps with TFX\n",
    "\n",
    "The goal of a recommender system for Movie Lens is to learn to accurately predict a user's ratings\n",
    "in order to be able to suggest movies to the user that they would like and have not seen.\n",
    "See also the section below called \"Linking to business value\".\n",
    "\n",
    "The Movie Lens data is extracted, analyzed, processed and stored and registered with an MLMetadata registry.  Regression models are trained and tuned\n",
    "to predict the ratings.  The best models are evaluated, validated, and deployed to storage, MLMD registry, and/or serving endpoints.  The deployed models are monitored for model degradation and anomalies.  The live \n",
    "incoming data is also monitored for shifts in distributions.\n",
    "The model validation involves testing, including A/B testing if possible and manual confirmation that the\n",
    "model aligns with business objectives.\n",
    "All of these steps are called machine learning operations (MLOps) and are automated when possible.\n",
    "There are iterative and continuous loops in segments of a total MLOps pipeline or pipelines.\n",
    "\n",
    "## Using Tensorflow's TFX for MLOps\n",
    "where MLOps is Continuous delivery and automation pipelines in machine learning.\n",
    "\n",
    "This is a local, non-Kaggle notebook in which TFX 1.16.0 and python 3.10 and the compatible versions of other libraries are installed in a virtual environment that this notebook is running in.  (The Kaggle notebook can run the pipelines in a virtual environment, but cannot display the results using the TFDV or TFMA libraries at this time due to python version conflicts.)\n",
    "\n",
    "The source code for this notebook is [at github, as recommender_systems](https://github.com/nking/recommender_systems)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50571b6d-4578-48a7-8864-cfa7565dfcbc",
   "metadata": {},
   "source": [
    "paths are relative to the github repository directory, \"recommender_systems\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed99ee786e13e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "from tfx.orchestration import metadata\n",
    "\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "from ml_metadata.metadata_store import metadata_store\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src/test/python/movie_lens_tfx\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src/main/python/movie_lens_tfx\"))\n",
    "\n",
    "from helper import *\n",
    "from movie_lens_tfx.PipelineComponentsFactory import *\n",
    "from movie_lens_tfx.tune_train_movie_lens import *\n",
    "\n",
    "from absl import logging\n",
    "tf.get_logger().propagate = False\n",
    "logging.set_verbosity(logging.WARNING)\n",
    "logging.set_stderrthreshold(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c98cdd-f021-49f6-af4a-aa571bf03b04",
   "metadata": {},
   "source": [
    "## EDA on the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad33acc-b994-420b-a0ad-ae1f178987e3",
   "metadata": {},
   "source": [
    "### w/ Polars and Plotly express\n",
    "output is written to bin/local_notebook/images/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95770000-3547-4541-8657-8b51fa0aa731",
   "metadata": {},
   "source": [
    "%run src/main/python/eda/eda_raw.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fec77f-0192-4d93-b922-5d5c3be21383",
   "metadata": {},
   "source": [
    "the generated images aren't plotted here, but similar plots are shown via TFDV below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a6b2d4-2479-4069-aee1-59ecd131e040",
   "metadata": {},
   "source": [
    "### Run data pre-processing on full dataset to get the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693174b-6f67-48b0-a227-85324cb3bf2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "infiles_dict_ser, output_config_ser, split_names = get_test_data(use_small=False)\n",
    "user_id_max = 6040\n",
    "movie_id_max = 3952\n",
    "n_genres = N_GENRES\n",
    "n_age_groups = N_AGE_GROUPS\n",
    "n_occupations = 21\n",
    "MIN_EVAL_SIZE = 50 #make this larger for production pipeline\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "test_num = \"1\"\n",
    "    \n",
    "PIPELINE_NAME = 'TestPipelines'\n",
    "output_data_dir = os.path.join(get_bin_dir(), \"local_notebook\", test_num)\n",
    "PIPELINE_ROOT = os.path.join(output_data_dir, PIPELINE_NAME)\n",
    "\n",
    "# remove results from previous test runs:\n",
    "try:\n",
    "  print(f\"removing: {PIPELINE_ROOT}\")\n",
    "  shutil.rmtree(PIPELINE_ROOT)\n",
    "except OSError as e:\n",
    "  pass\n",
    "METADATA_PATH = os.path.join(PIPELINE_ROOT, 'tfx_metadata',\n",
    "                             'metadata.db')\n",
    "os.makedirs(os.path.join(PIPELINE_ROOT, 'tfx_metadata'),\n",
    "            exist_ok=True)\n",
    "\n",
    "ENABLE_CACHE = True\n",
    "\n",
    "# metadata_connection_config = metadata_store_pb2.ConnectionConfig()\n",
    "# metadata_connection_config.sqlite.SetInParent()\n",
    "# metadata_connection = metadata.Metadata(metadata_connection_config)\n",
    "metadata_connection_config = metadata.sqlite_metadata_connection_config(\n",
    "  METADATA_PATH)\n",
    "\n",
    "store = metadata_store.MetadataStore(metadata_connection_config)\n",
    "\n",
    "if get_kaggle():\n",
    "  tr_dir = \"/kaggle/working/\"\n",
    "else:\n",
    "  tr_dir = os.path.join(get_project_dir(), \"src/main/python/movie_lens_tfx\")\n",
    "\n",
    "serving_model_dir = os.path.join(PIPELINE_ROOT, 'serving_model')\n",
    "output_parquet_path = os.path.join(PIPELINE_ROOT, \"transformed_parquet\")\n",
    "\n",
    "# for the custom ingestion component, the apache beam pipeline needs to be able to\n",
    "# find the sibling scripts it imports.\n",
    "# 2 solutions: (1) create a tar archive and use --extra_package in pipeline args\n",
    "# or (2) use setup.py and --setup_file in pipeline args.\n",
    "\n",
    "SETUP_FILE_PATH = os.path.abspath('setup.py')\n",
    "beam_pipeline_args = [\n",
    "  '--direct_running_mode=multi_processing',\n",
    "  '--direct_num_workers=0',\n",
    "  f'--setup_file={SETUP_FILE_PATH}',\n",
    "  #f'--extra_package={ingest_tar_file}'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a4011-c7cf-4ed2-9bb7-5f3a53af12d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "\n",
    "tf.get_logger().propagate = False\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.WARNING)\n",
    "logging.set_stderrthreshold(logging.WARNING)\n",
    "\n",
    "context = InteractiveContext(pipeline_name=PIPELINE_NAME, pipeline_root=PIPELINE_ROOT,\n",
    "  metadata_connection_config=metadata_connection_config,\n",
    "  beam_pipeline_args=beam_pipeline_args\n",
    ")\n",
    "\n",
    "factory = PipelineComponentsFactory(\n",
    "    num_examples=1000209, infiles_dict_ser=infiles_dict_ser,\n",
    "    output_config_ser=output_config_ser, transform_dir=tr_dir,\n",
    "    user_id_max=user_id_max, movie_id_max=movie_id_max,\n",
    "    n_genres=n_genres, n_age_groups=n_age_groups,\n",
    "    min_eval_size=MIN_EVAL_SIZE, batch_size=BATCH_SIZE, num_epochs=NUM_EPOCHS, device=\"CPU\",\n",
    "    serving_model_dir=serving_model_dir, output_parquet_path=output_parquet_path)\n",
    "\n",
    "components = factory.build_components(PIPELINE_TYPE.PREPROCESSING)\n",
    "\n",
    "for component in components:\n",
    "    context.run(component)\n",
    "\n",
    "print(f'done pre-processing data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5668d235-1d07-439b-a6c3-beaa701f3315",
   "metadata": {},
   "source": [
    "## EDA on the transformed data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc80d679-b7ab-40f4-90a3-77c24f06fd2e",
   "metadata": {},
   "source": [
    "### using Polars, Plotly.express \n",
    "\n",
    "this can take an hour on a single COTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b01259-457b-4c57-8a67-26b13ddd29ff",
   "metadata": {},
   "source": [
    "%run src/main/python/eda/eda_transformed.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b6dec-5ee5-4ebe-bb37-d559f8438b21",
   "metadata": {},
   "source": [
    "Some of the images are shown here from a former saved run.\n",
    "\n",
    "You can see a clear correlation between rating and movie_id, then less\n",
    "so between rating and age and rating and occupation.\n",
    "\n",
    "<img src=\"src/test/resources/train_dist_corr_heatmap.png\">\n",
    "\n",
    "You can see many co-occurrences between movie genres.\n",
    "\n",
    "<img src=\"src/test/resources/train_genre_cooccurence_rating_5_heatmap.png\">\n",
    "\n",
    "You can see that Drama, then Comedy, then Action are the most popular movie genres.\n",
    "\n",
    "<img src=\"src/test/resources/train_genres_rating_5.png\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f330e36e-74b9-4695-973c-25431bc3ea12",
   "metadata": {},
   "source": [
    "### using Pandas, Pyspark MLLIB FPGrowth\n",
    "\n",
    "This does a market basket analysis with movie_ids.\n",
    "\n",
    "If you want the PrefixSpan plots also, set\n",
    "PLOT_PREFIXSPAN = True\n",
    "but beware that the script will take much longer to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba2cda2-d3c6-4289-90a8-3ebc634373aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_PREFIXSPAN=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290d54c1-d223-40eb-9590-8e158f07a5aa",
   "metadata": {},
   "source": [
    "%run src/main/python/eda/eda_transformed_pyspark_mllib.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c5727-401a-40a2-9ee1-145e000c266a",
   "metadata": {},
   "source": [
    "Some of the images are shown here from a former saved run.\n",
    "\n",
    "You can see that many association rules can be derived from the data.\n",
    "<img src=\"src/test/resources/train_movies_assoc_rules_rating_5.png\">\n",
    "\n",
    "and that there are many frequent itemsets.\n",
    "<img src=\"src/test/resources/train_movies_itemsets_rating_5.png\">\n",
    "\n",
    "<img src=\"src/test/resources/train_movies_itemsets_rating_5_2.png\">\n",
    "\n",
    "The results show that neural network models will have good material to exploit.\n",
    "\n",
    "The PrefixScan model can be enabled in the script to provide images to explore sequences\n",
    "for actions or as precursor to Sequential DNN models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951c493f-6964-452d-997d-e51cb246c912",
   "metadata": {},
   "source": [
    "### Data and Concept Drift\n",
    "After exploring the data inputs to the model, we want to define monitoring\n",
    "for data and concept shifts.\n",
    "\n",
    "let X = features\n",
    "\n",
    "let Y = targets\n",
    "\n",
    "Data shift is a change in the joint distribution, P(X, Y). \n",
    "\n",
    "Using the probability product rule, we can explore 4 causes for the\n",
    "simplest changes in P(X,Y)\n",
    "$$ P(X, Y) = P(Y, X) = P(X|Y)P(Y) = P(Y|X)P(X) $$\n",
    "\n",
    "We can look for changes in one member in the following pairs at any time\n",
    "(one is simpler than exploring more than 1 member changing at same time):\n",
    "$$ P(X|Y) * P(Y) $$\n",
    "$$ P(Y|X) * P(X) $$\n",
    "\n",
    "* Covariate shift:\n",
    "  $$ P(X) changed,  P(Y|X) unchanged $$\n",
    "  Distr of model inputs changes.\n",
    "* Label shift:\n",
    "  $$ P(Y) changed,  P(X|Y) unchanged $$\n",
    "  Distr of model outputs changes, but for any given output, the input distribution stays the same.\n",
    "  \n",
    "* Concept shift:\n",
    "  $$ P(X) unchanged,  P(Y|X) changed $$\n",
    "* Manifestation shift:\n",
    "  $$ P(Y) unchanged,  P(X|Y) changed $$\n",
    "\n",
    "[see more at NannyML](https://www.nannyml.com/blog/concept-drift)\n",
    "\n",
    "if the train, eval, and test split are random, then one could use\n",
    "the maximum differences in their distributions as a lower limit on \n",
    "the estimate for stochastic error.  A trigger for data drift should\n",
    "then be GEQ about 3 times that stochastic error.\n",
    "\n",
    "The previous data doesn't exist yet for this project, but one could\n",
    "either download another movie-lens dataset of different time period,\n",
    "or split this 1M dataset by a timestamp ordering into 2 partitions.\n",
    "\n",
    "More data is available at [GroupLens](https://files.grouplens.org/datasets/movielens/)\n",
    "\n",
    "### Data [Drift and Skew using TFDV](https://www.tensorflow.org/tfx/tutorials/data_validation/tfdv_basic)\n",
    "* Drift\n",
    "  Drift detection is supported for categorical features and between consecutive spans of data\n",
    "  (i.e., between span N and span N+1), such as between different days of training data.\n",
    "    * L-infinity distance\n",
    "    * alerts when drift is higher than threshold distance\n",
    "* Skew\n",
    "    * data - schema skew\n",
    "      occurs when the training and serving data do not conform to the same schema.\n",
    "      Any expected deviations between the two (such as the label feature being only present in the training data but not in serving) should be specified through environments field in the schema.\n",
    "    * feature skew\n",
    "      occurs when the training and serving feature values are different\n",
    "      This can happen when:\n",
    "        * A data source of features is modified between training and serving time\n",
    "        * A difference in logic for generating between training and serving.\n",
    "    * distribution skew\n",
    "      occurs when the training and serving distributions are significantly different.\n",
    "      some key causes:\n",
    "        * different code or different data sources to generate the training dataset\n",
    "        * a faulty sampling mechanism that chooses a non-representative subsample of the serving data to train on.\n",
    "\n",
    "\n",
    "TODO: finish adding to this below with the components measuring them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0770fd1-41d6-4f7a-848e-9e73589c10ca",
   "metadata": {},
   "source": [
    "### using TFDV to look at the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4c4dc0-6bbc-4e19-beba-ca8dc797ee2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tfx.dsl.io import fileio\n",
    "from tfx.orchestration import metadata\n",
    "from tfx.components import StatisticsGen, SchemaGen, ExampleValidator\n",
    "from tfx.utils import io_utils\n",
    "from tensorflow_metadata.proto.v0 import anomalies_pb2, schema_pb2\n",
    "from tensorflow_metadata.proto.v0 import statistics_pb2\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "import tensorflow_data_validation as tfdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd4e2ca38c1076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Schema from SchemaGen:\")\n",
    "_list = store.get_artifacts_by_type(\"Schema\")\n",
    "print(f'Schema count={len(_list)}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"SchemaGen\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_path = os.path.join(artifact_uri, \"schema.pbtxt\")\n",
    "schema = tfdv.load_schema_text(file_path)\n",
    "#tfdv.visualize_artifacts(schema)\n",
    "tfdv.display_schema(schema=schema)\n",
    "\n",
    "print(\"ExampleStatistics from StatisticsGen:\")\n",
    "_list = store.get_artifacts_by_type(\"ExampleStatistics\")\n",
    "print(f'ExampleStatistics count={len(_list)}')\n",
    "#print(f'ExampleStatistics ={_list}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"StatisticsGen\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name, \"FeatureStats.pb\") \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "stats_dict = {}\n",
    "for file_path in file_paths:\n",
    "    if \"test\" in file_path:\n",
    "        #plotting train and eval\n",
    "        continue\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            serialized_stats = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")    \n",
    "    stats = statistics_pb2.DatasetFeatureStatisticsList()\n",
    "    stats.ParseFromString(serialized_stats)\n",
    "    if \"train\" in file_path:\n",
    "        stats_dict['train'] = stats\n",
    "    else:\n",
    "        stats_dict['eval'] = stats\n",
    "tfdv.visualize_statistics(lhs_statistics=stats_dict['eval'],\n",
    "    rhs_statistics=stats_dict['train'],\n",
    "    lhs_name='EVAL_DATASET', rhs_name='TRAIN_DATASET')\n",
    "\n",
    "print(\"ExampleAnomalies from ExampleValidator:\")\n",
    "_list = store.get_artifacts_by_type(\"ExampleAnomalies\")\n",
    "print(f'ExampleAnomalies count={len(_list)}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"ExampleValidator\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name, \"SchemaDiff.pb\") \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            serialized_anomalies = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Anomaly file not found at {file_path}\")\n",
    "    anomalies = anomalies_pb2.Anomalies()\n",
    "    anomalies.ParseFromString(serialized_anomalies)\n",
    "    tfdv.display_anomalies(anomalies)\n",
    "\n",
    "print(\"ExampleStatistics from pre-transform stats of Transform:\")\n",
    "_list = store.get_artifacts_by_type(\"ExampleStatistics\")\n",
    "#print(f'ExampleStatistics={_list}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"pre_transform_stats\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name) \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            serialized_stats = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")    \n",
    "    stats = statistics_pb2.DatasetFeatureStatisticsList()\n",
    "    stats.ParseFromString(serialized_stats)\n",
    "    tfdv.visualize_statistics(stats)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d681e-6788-456e-8a77-91c4ea809963",
   "metadata": {},
   "source": [
    "### using TFDV to look at the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b45664b-bfed-4877-a876-9663cc2e169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Schema from post-Transform:\")\n",
    "_list = store.get_artifacts_by_type(\"Schema\")\n",
    "print(f'Schema count={len(_list)}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"post_transform_schema\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_path = os.path.join(artifact_uri, \"schema.pbtxt\")\n",
    "schema = tfdv.load_schema_text(file_path)\n",
    "#tfdv.visualize_artifacts(schema)\n",
    "tfdv.display_schema(schema=schema)\n",
    "\n",
    "print(\"ExampleStatistics from post-transform stats of Transform:\")\n",
    "_list = store.get_artifacts_by_type(\"ExampleStatistics\")\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"post_transform_stats\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name) \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            serialized_stats = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")    \n",
    "    stats = statistics_pb2.DatasetFeatureStatisticsList()\n",
    "    stats.ParseFromString(serialized_stats)\n",
    "    tfdv.visualize_statistics(stats)\n",
    "    \n",
    "print(\"ExampleAnomalies from post-transform of Transform:\")\n",
    "_list = store.get_artifacts_by_type(\"ExampleAnomalies\")\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"post_transform_anomalies\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name) \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    anomalies = anomalies_pb2.Anomalies()\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            serialized_anomalies = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Anomaly file not found at {file_path}\")\n",
    "    anomalies = anomalies_pb2.Anomalies()\n",
    "    anomalies.ParseFromString(serialized_anomalies)\n",
    "    tfdv.display_anomalies(anomalies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553960d4-7320-49b1-8cdd-dd5547a3057d",
   "metadata": {},
   "source": [
    "## Save the data schema with version control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd61195-54fd-4927-9d73-5e06dcaf52c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "_list = store.get_artifacts_by_type(\"Schema\")\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"pre_transform_schema\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "pre_transform_file_path = [os.path.join(artifact_uri, name) for name in os.listdir(artifact_uri)][0]\n",
    "\n",
    "for artifact in _list:\n",
    "    if \"post_transform_schema\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "post_transform_file_path = [os.path.join(artifact_uri, name) for name in os.listdir(artifact_uri)][0]\n",
    "\n",
    "pre_dir = os.path.join(get_project_dir(), \"src/main/resources\", \"pre_transform\")\n",
    "post_dir = os.path.join(get_project_dir(), \"src/main/resources\", \"post_transform\")\n",
    "os.makedirs(pre_dir, exist_ok=True)\n",
    "os.makedirs(post_dir, exist_ok=True)\n",
    "\n",
    "pre_schema_path = os.path.join(pre_dir, \"schema.pbtxt\")\n",
    "post_schema_path = os.path.join(post_dir, \"schema.pbtxt\")\n",
    "\n",
    "shutil.copyfile(pre_transform_file_path, pre_schema_path)\n",
    "shutil.copyfile(post_transform_file_path, post_schema_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307091b-211e-4f81-95ae-eed7ef9389b2",
   "metadata": {},
   "source": [
    "## Run baseline model pipeline with full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02d88cf-ffb3-4396-afcb-bc4c35ebac92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline_factory = PipelineComponentsFactory(\n",
    "  num_examples=1000209, infiles_dict_ser=infiles_dict_ser,\n",
    "  output_config_ser=output_config_ser, transform_dir=tr_dir,\n",
    "  user_id_max=user_id_max, movie_id_max=movie_id_max,\n",
    "  n_genres=n_genres, n_age_groups=n_age_groups,\n",
    "  min_eval_size=MIN_EVAL_SIZE, batch_size=BATCH_SIZE, num_epochs=NUM_EPOCHS, device=\"CPU\",\n",
    "  serving_model_dir=serving_model_dir, output_parquet_path=output_parquet_path)\n",
    "\n",
    "SETUP_FILE_PATH = os.path.abspath('setup.py')\n",
    "beam_pipeline_args = [\n",
    "  '--direct_running_mode=multi_processing',\n",
    "  '--direct_num_workers=0',\n",
    "  f'--setup_file={SETUP_FILE_PATH}',\n",
    "  #f'--extra_package={ingest_tar_file}'\n",
    "]\n",
    "\n",
    "baseline_components = pipeline_factory.build_components(PIPELINE_TYPE.BASELINE,\n",
    "  run_example_diff=False, pre_transform_schema_dir_path=pre_dir,\n",
    "  post_transform_schema_dir_path=post_dir)\n",
    "\n",
    "# create baseline model\n",
    "my_pipeline = tfx.dsl.Pipeline(\n",
    "  pipeline_name=PIPELINE_NAME,\n",
    "  pipeline_root=PIPELINE_ROOT,\n",
    "  components=baseline_components,\n",
    "  enable_cache=ENABLE_CACHE,\n",
    "  metadata_connection_config=metadata_connection_config,\n",
    "  beam_pipeline_args=beam_pipeline_args,\n",
    ")\n",
    "\n",
    "tfx.orchestration.LocalDagRunner().run(my_pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8502e6-e510-4f23-badb-0d655e64e402",
   "metadata": {},
   "source": [
    "### Visualize Baseline model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92ba2e-7383-4c93-8267-10cd8445450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_analysis.proto import validation_result_pb2\n",
    "\n",
    "def print_model_evaluation(artifact_uri):\n",
    "\n",
    "    for name in os.listdir(artifact_uri):\n",
    "        print(f\"file_name={name}\")\n",
    "        file_path = os.path.join(artifact_uri, name)\n",
    "        if name.startswith(\"metrics\"):\n",
    "            raw_dataset = tf.data.TFRecordDataset(file_path)\n",
    "            for serialized_proto in raw_dataset:\n",
    "              metrics_for_slice = metrics_for_slice_pb2.MetricsForSlice()\n",
    "              metrics_for_slice.ParseFromString(serialized_proto.numpy())\n",
    "              print(f'metrics_for_slice={metrics_for_slice}')\n",
    "        elif name.startswith(\"validations\"):\n",
    "            raw_dataset = tf.data.TFRecordDataset([file_path])\n",
    "            for serialized_validation_result in raw_dataset.as_numpy_iterator():\n",
    "                validation_result = validation_result_pb2.ValidationResult()\n",
    "                validation_result.ParseFromString(serialized_validation_result)\n",
    "                \n",
    "                # Now you can inspect the validation_result object\n",
    "                print(f\"Validation OK: {validation_result.validation_ok}\")\n",
    "                \n",
    "                # If validation_ok is False, you can see the failing checks:\n",
    "                if not validation_result.validation_ok:\n",
    "                    if hasattr(validation_result, \"metric_failures\"):\n",
    "                        for failure in validation_result.metric_failures:\n",
    "                            print(f\"  Failed Metric: {failure.metric_key.name}\")\n",
    "                            print(f\"  Failure Type: {failure.failure_type}\")\n",
    "                            print(f\"  Observed Value: {failure.observed_value.value}\")\n",
    "            validation_result = tfma.load_validation_result(file_path)\n",
    "            print(validation_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1820d838-34a3-4860-bf1a-5e23ba2af06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_analysis.proto import metrics_for_slice_pb2\n",
    "\n",
    "#add training and eval plots: Trainer/model_run\n",
    "#  Tensorboard can visualize them\n",
    "print(f'plot ModelRun using tensorboard')\n",
    "%load_ext tensorboard\n",
    "_list = store.get_artifacts_by_type(\"ModelRun\")\n",
    "print(f'ModelRun count={len(_list)}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"Trainer\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        %tensorboard --logdir {artifact_uri}\n",
    "\n",
    "#no baseline model yet, so just read files:\n",
    "print(\"ModelEvaluation from Evaluator:\")\n",
    "_list = store.get_artifacts_by_type(\"ModelEvaluation\")\n",
    "print(f'Schema count={len(_list)}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "artifact_uri = _list[0].uri\n",
    "assert(artifact_uri is not None)\n",
    "#file_path = os.path.join(artifact_uri, \"metrics*\")\n",
    "print(f'ModelEvaluation uri={artifact_uri}')\n",
    "print_model_evaluation(artifact_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe0a7d9-5203-4698-9de8-a51d7811856a",
   "metadata": {},
   "source": [
    "## Run full model pipeline with full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b85116-6266-4777-9444-f938f174a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_types = store.get_artifact_types()\n",
    "logging.debug(f\"MLMD store artifact_types={artifact_types}\")\n",
    "artifacts = store.get_artifacts()\n",
    "logging.debug(f\"MLMD store artifacts={artifacts}\")\n",
    "\n",
    "components = pipeline_factory.build_components(PIPELINE_TYPE.PRODUCTION,\n",
    "  run_example_diff=False, pre_transform_schema_dir_path=pre_dir,\n",
    "  post_transform_schema_dir_path=post_dir)\n",
    "  \n",
    "# simulate experimentation of one model family\n",
    "my_pipeline = tfx.dsl.Pipeline(\n",
    "  pipeline_name=PIPELINE_NAME,\n",
    "  pipeline_root=PIPELINE_ROOT,\n",
    "  components=components,\n",
    "  enable_cache=ENABLE_CACHE,\n",
    "  metadata_connection_config=metadata_connection_config,\n",
    "  beam_pipeline_args=beam_pipeline_args,\n",
    ")\n",
    "\n",
    "tfx.orchestration.LocalDagRunner().run(my_pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3129dbd0-8256-41f3-b579-02e0bc5d2efa",
   "metadata": {},
   "source": [
    "### Visualize model fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f5b6e-3d1b-4f5e-a331-9beb21a2b18c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#add training and eval plots: Trainer/model_run\n",
    "#  Tensorboard can visualize them\n",
    "print(f'plot ModelRun using tensorboard')\n",
    "%load_ext tensorboard\n",
    "_list = store.get_artifacts_by_type(\"ModelRun\")\n",
    "print(f'ModelRun count={len(_list)}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"Trainer\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        %tensorboard --logdir {artifact_uri}\n",
    "\n",
    "print(\"ModelEvaluation from Evaluator:\")\n",
    "_list = store.get_artifacts_by_type(\"ModelEvaluation\")\n",
    "print(f'Schema count={len(_list)}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "artifact_uri = _list[0].uri\n",
    "print_model_evaluation(artifact_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb5a19-c8c5-4573-a1a9-855c51807a4f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Monitoring the deployed model\n",
    "\n",
    "The model deployed to production can be monitored to detect when the business utility drops below an acceptable threshold.\n",
    "The business utility here is linked to the accuracy of recommending movies to the user that they would like and haven't seen.\n",
    "\n",
    "Detecting model degradation when users have watched a movie, and before they have rated them, requires bootstrapping\n",
    "using an extra model trained from reference data that has the user ratings. \n",
    "\n",
    "NannyML is a popular library used for detecting changes in ML model features, targets, and relationships between\n",
    "them.  \n",
    "The (NannyML Model performance estimator) [https://nannyml.readthedocs.io/en/stable/how_it_works/performance_estimation.html#dle-implementation-details] for regression  is their Direct Loss Estimator algorithm (DLE).\n",
    "\n",
    "The models:\n",
    "* f = the monitored recommender model\n",
    "* h = the Nanny model (discussed below)\n",
    "\n",
    "The datasets used:\n",
    "* train: used to train f.  contains features X and targets Y where targets are the ratings.\n",
    "* reference: used to train h. contains features X and targets Y\n",
    "* analysis: recent data.  contains only features X\n",
    "The datasets are ordered by time.\n",
    "\n",
    "The nanny model h is an extra mode used for degradation monitoring.\n",
    "* h is trained with X_reference, and y_reference\n",
    "    * for each observation in X, calculate absolute error AE_reference = | f(X_reference) - y_reference |\n",
    "    * train A_reference = h(X_reference, f(X_reference))\n",
    "          * DLE for regression uses LightGBM\n",
    "* predict AE_analysis using h\n",
    "    * for each observation in X: AE_analysis_est = h( X_analysis, f(X_analysis))\n",
    "    * MAE_analysis_est = mean of the AE_analysis_est\n",
    "* the variance of large chunks of data are determined and the upper and lower bounds for anomalies are set using the sample error using those variances.  When a predicted MAE exceed the thresholds, an alert can be triggered and root cause analysis can be performed to decide if the model should be retrained or refactored and retrained as part of a Continuous Training (CT) workflow.\n",
    "\n",
    "DLE assumes:\n",
    "* no concept drift\n",
    "* no covariate shift to previously unseen regions of input space\n",
    "* noise is heteroscedastic around the monitored model target, y,\n",
    "  and it is dependent on the monitored model input features\n",
    "* the dataset to be analyzed is large enough so that the performance estimate is not dominated by sampling error\n",
    "\n",
    "#### Model monitoring is a separate process from the serving inference, so an application can be built for it or cloud options\n",
    "can be used when configuring batch inference.\n",
    "\n",
    "TODO: add cloud model monitoring options and details...\n",
    "Apache Airflow,  Vertex AI Model Monitoring, Azure ML Model monitoring though NannyML is an option through Azure Marketplace, Amazon SageMaker Model monitor and NannyML is an option through the marketplace,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edc3d0c-7ddb-44d1-8e1c-f56ebc2178de",
   "metadata": {},
   "source": [
    "## Linking to business value\n",
    "TODO: add the ranking model and precision@K, recall@K and NDCG.  this is in the other notebook, so can be merged when finished....\n",
    "\n",
    "TODO: list supplemental data that could be used to link to business value:\n",
    "click through rate, conversion rate, user engagement, churn, revenue uplift from associated ads.\n",
    "\n",
    "TODO: quantifying the business value:\n",
    "A/B testing with control group and test group where the later receives ranked recommendation from the new model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c7a2b-f8c8-48f7-ab1b-0d094b00adcb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "TFX pipelines are valuable tools in MLOps\n",
    "* highly scalable\n",
    "    * distributed data pre-processing\n",
    "    * distributed model training\n",
    "* configurable to run on a variety of architectures\n",
    "    * e.g. TPUs, GPUs for accelerated training\n",
    "* configurable for variety of different data source types\n",
    "* configurable for fault tolerance and failover\n",
    "* configurable for different types of pipeline storage and model registry\n",
    "* configurable for cloud native, cloud specific, and local environments\n",
    "* robust, consistent processing\n",
    "* configurable exported model types compatible with keras, pytorch, jax:\n",
    "    * default saved_models\n",
    "    * liteRT for embedded and IOT environments\n",
    "    * TensorflowJS for browsers\n",
    "* usable in cloud environments\n",
    "    * compatible with many orchestrators\n",
    "        * Apache Airflow, Apache Beam, Kubeflow pipelines\n",
    "    * can be used in containers (required by kubernetes for example)\n",
    "    * compatible with cluster management systems like kubernetes, flink, spark, and cloud native offerings\n",
    "    * can be compiled into Kubeflow pipelines\n",
    "    * can be run from a command line interface in the cloud or locally\n",
    "* the MLMD store is usable by a variety of monitoring systems including cloud-specific systems\n",
    "* Tensorboard for visualization of model training output, TFDV for visualization of data\n",
    "* compatible with use of BI tools like GCP's Looker, DataPrep\n",
    "* inter-operative with Vertex AI Training, Prediction, Dataflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
