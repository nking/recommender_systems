{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "567a22b5-ead8-4cf5-9bcf-cc0984cfbaf7",
   "metadata": {},
   "source": [
    "# Movie Lens MLOps with TFX\n",
    "\n",
    "The goal of a recommender system for Movie Lens is to learn to accurately predict a user's ratings\n",
    "in order to be able to suggest movies to the user that they would like and have not seen.\n",
    "\n",
    "The Movie Lens data is extracted, analyzed, processed and stored and registered with an MLMetadata registry.  Regression models are trained and tuned\n",
    "to predict the ratings.  The best models are evaluated, validated, and deployed to storage, MLMD registry, and/or serving endpoints.  The deployed models are monitored for model degradation and anomalies.  The live \n",
    "incoming data is also monitored for shifts in distributions.\n",
    "The model validation involves testing, including A/B testing if possible and manual confirmation that the\n",
    "model aligns with business objectives.\n",
    "All of these steps are called machine learning operations (MLOps) and are automated when possible.\n",
    "There are iterative and continuous loops in segments of a total MLOps pipeline or pipelines.\n",
    "\n",
    "## Using Tensorflow's TFX for MLOps\n",
    "where MLOps is Continuous delivery and automation pipelines in machine learning\n",
    "\n",
    "This is a local, non-Kaggle notebook in which TFX 1.16.0 and python 3.10 and the compatible versions of other libraries are installed in a virtual environment that this notebook is running in.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50571b6d-4578-48a7-8864-cfa7565dfcbc",
   "metadata": {},
   "source": [
    "paths are relative to the github repository directory, \"recommender_systems\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed99ee786e13e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "from tfx.orchestration import metadata\n",
    "\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "from ml_metadata.metadata_store import metadata_store\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src/test/python/movie_lens_tfx\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src/main/python/movie_lens_tfx\"))\n",
    "\n",
    "from helper import *\n",
    "from movie_lens_tfx.PipelineComponentsFactory import *\n",
    "from movie_lens_tfx.tune_train_movie_lens import *\n",
    "\n",
    "from absl import logging\n",
    "tf.get_logger().propagate = False\n",
    "logging.set_verbosity(logging.WARNING)\n",
    "logging.set_stderrthreshold(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c98cdd-f021-49f6-af4a-aa571bf03b04",
   "metadata": {},
   "source": [
    "## EDA on the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad33acc-b994-420b-a0ad-ae1f178987e3",
   "metadata": {},
   "source": [
    "### w/ Polars and Plotly express\n",
    "output is written to bin/local_notebook/images/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95770000-3547-4541-8657-8b51fa0aa731",
   "metadata": {},
   "source": [
    "%run src/main/python/eda/eda_raw.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fec77f-0192-4d93-b922-5d5c3be21383",
   "metadata": {},
   "source": [
    "the generated images aren't plotted here, but similar plots are shown via TFDV below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a6b2d4-2479-4069-aee1-59ecd131e040",
   "metadata": {},
   "source": [
    "### Run data pre-processing on full dataset to get the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a693174b-6f67-48b0-a227-85324cb3bf2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD=/home/nichole/projects/github/recommender_systems, kaggle=False\n",
      "removing: /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines\n"
     ]
    }
   ],
   "source": [
    "infiles_dict_ser, output_config_ser, split_names = get_test_data(use_small=False)\n",
    "user_id_max = 6040\n",
    "movie_id_max = 3952\n",
    "n_genres = N_GENRES\n",
    "n_age_groups = N_AGE_GROUPS\n",
    "n_occupations = 21\n",
    "MIN_EVAL_SIZE = 50 #make this larger for production pipeline\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "test_num = \"1\"\n",
    "    \n",
    "PIPELINE_NAME = 'TestPipelines'\n",
    "output_data_dir = os.path.join(get_bin_dir(), \"local_notebook\", test_num)\n",
    "PIPELINE_ROOT = os.path.join(output_data_dir, PIPELINE_NAME)\n",
    "\n",
    "# remove results from previous test runs:\n",
    "try:\n",
    "  print(f\"removing: {PIPELINE_ROOT}\")\n",
    "  shutil.rmtree(PIPELINE_ROOT)\n",
    "except OSError as e:\n",
    "  pass\n",
    "METADATA_PATH = os.path.join(PIPELINE_ROOT, 'tfx_metadata',\n",
    "                             'metadata.db')\n",
    "os.makedirs(os.path.join(PIPELINE_ROOT, 'tfx_metadata'),\n",
    "            exist_ok=True)\n",
    "\n",
    "ENABLE_CACHE = True\n",
    "\n",
    "# metadata_connection_config = metadata_store_pb2.ConnectionConfig()\n",
    "# metadata_connection_config.sqlite.SetInParent()\n",
    "# metadata_connection = metadata.Metadata(metadata_connection_config)\n",
    "metadata_connection_config = metadata.sqlite_metadata_connection_config(\n",
    "  METADATA_PATH)\n",
    "\n",
    "store = metadata_store.MetadataStore(metadata_connection_config)\n",
    "\n",
    "if get_kaggle():\n",
    "  tr_dir = \"/kaggle/working/\"\n",
    "else:\n",
    "  tr_dir = os.path.join(get_project_dir(), \"src/main/python/movie_lens_tfx\")\n",
    "\n",
    "serving_model_dir = os.path.join(PIPELINE_ROOT, 'serving_model')\n",
    "output_parquet_path = os.path.join(PIPELINE_ROOT, \"transformed_parquet\")\n",
    "\n",
    "# for the custom ingestion component, the apache beam pipeline needs to be able to\n",
    "# find the sibling scripts it imports.\n",
    "# 2 solutions: (1) create a tar archive and use --extra_package in pipeline args\n",
    "# or (2) use setup.py and --setup_file in pipeline args.\n",
    "\n",
    "SETUP_FILE_PATH = os.path.abspath('setup.py')\n",
    "beam_pipeline_args = [\n",
    "  '--direct_running_mode=multi_processing',\n",
    "  '--direct_num_workers=0',\n",
    "  f'--setup_file={SETUP_FILE_PATH}',\n",
    "  #f'--extra_package={ingest_tar_file}'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb6a4011-c7cf-4ed2-9bb7-5f3a53af12d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889177   nanos: 303650617 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889177   nanos: 314613103 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889177   nanos: 346210479 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889177   nanos: 354513406 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889177   nanos: 366740703 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889177   nanos: 375945568 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889177   nanos: 382572650 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889177   nanos: 391425609 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "2025-11-11 11:26:18.004625: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU wi2025-11-11 11:26:18.004625: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "ll not be used.\n",
      "2025-11-11 11:26:18.007905: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:26:18.012568: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:26:18.012800: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:26:18.013469: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:26:18.025894: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:26:18.031079: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:26:18.115211: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:26:18.115302: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:26:18.125573: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:26:18.145073: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:26:19.473555: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 11:26:19.523156: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 11:26:19.611420: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 11:26:19.776305: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889207   nanos: 149097681 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_49\" transform_id: \"write_to_tfrecord_39340354265/Write/WriteImpl/WriteBundles\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889207   nanos: 227487564 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_52\" transform_id: \"write_to_tfrecord_39340354265/Write/WriteImpl/WriteBundles\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889207   nanos: 274809360 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_51\" transform_id: \"write_to_tfrecord_39340354265/Write/WriteImpl/WriteBundles\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889207   nanos: 283194541 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_50\" transform_id: \"write_to_tfrecord_39340354265/Write/WriteImpl/WriteBundles\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889296   nanos: 628276109 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889296   nanos: 636474609 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889296   nanos: 645905256 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889296   nanos: 656473398 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889296   nanos: 707422018 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889296   nanos: 703397989 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889296   nanos: 711048364 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889296   nanos: 715242862 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "2025-11-11 11:28:17.408133: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:28:17.408445: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:28:17.412786: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:28:17.416930: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:28:17.417422: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:28:17.418980: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:28:17.426476: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:28:17.431539: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:28:17.522717: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:28:17.534147: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:28:17.534306: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:28:17.538770: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:28:18.942859: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 11:28:18.944720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 11:28:18.956455: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 11:28:18.964260: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889300   nanos: 818531274 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_138\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889300   nanos: 825146436 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_137\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889300   nanos: 853224754 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_139\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889300   nanos: 881112575 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_140\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build/lib\n",
      "copying transform_movie_lens.py -> build/lib\n",
      "copying PipelineComponentsFactory.py -> build/lib\n",
      "copying tune_train_movie_lens.py -> build/lib\n",
      "installing to /tmp/tmpddpnpocf\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/transform_movie_lens.py -> /tmp/tmpddpnpocf/.\n",
      "copying build/lib/PipelineComponentsFactory.py -> /tmp/tmpddpnpocf/.\n",
      "copying build/lib/tune_train_movie_lens.py -> /tmp/tmpddpnpocf/.\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Transform.egg-info\n",
      "writing tfx_user_code_Transform.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Transform.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Transform.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Transform.egg-info to /tmp/tmpddpnpocf/./tfx_user_code_Transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3.10.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmpddpnpocf/tfx_user_code_transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96.dist-info/WHEEL\n",
      "creating '/tmp/tmpghpwirq6/tfx_user_code_transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl' and adding '/tmp/tmpddpnpocf' to it\n",
      "adding 'PipelineComponentsFactory.py'\n",
      "adding 'transform_movie_lens.py'\n",
      "adding 'tune_train_movie_lens.py'\n",
      "adding 'tfx_user_code_transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96.dist-info/METADATA'\n",
      "adding 'tfx_user_code_transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96.dist-info/RECORD'\n",
      "removing /tmp/tmpddpnpocf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:90: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        This deprecation is overdue, please update your project and remove deprecated\n",
      "        calls to avoid build errors in the future.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'transform_movie_lens@/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl', 'stats_options_updater_fn': None} 'stats_options_updater_fn'\n",
      "INFO:absl:Installing '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/home/nichole/miniconda3/envs/tfx_py310/bin/python3.10', '-m', 'pip', 'install', '--target', '/tmp/tmpuzep4ev1', '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tfx-user-code-transform\n",
      "Successfully installed tfx-user-code-transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96\n",
      "Processing ./bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successfully installed '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl'.\n",
      "INFO:absl:Installing '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/home/nichole/miniconda3/envs/tfx_py310/bin/python3.10', '-m', 'pip', 'install', '--target', '/tmp/tmpvc0gv9pe', '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tfx-user-code-transform\n",
      "Successfully installed tfx-user-code-transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96\n",
      "Processing ./bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successfully installed '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl'.\n",
      "DEBUG:absl:Inputs to executor.Transform function: {'disable_statistics': False, 'schema_path': '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/SchemaGen/schema/3/schema.pbtxt', 'examples_data_format': 6, 'data_view_uri': None, 'analyze_data_paths': ['/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/MovieLensExampleGen/output_examples/1/Split-train/*'], 'analyze_paths_file_formats': ['tfrecords_gzip'], 'transform_data_paths': ['/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/MovieLensExampleGen/output_examples/1/Split-test/*', '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/MovieLensExampleGen/output_examples/1/Split-train/*', '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/MovieLensExampleGen/output_examples/1/Split-eval/*'], 'transform_paths_file_formats': ['tfrecords_gzip', 'tfrecords_gzip', 'tfrecords_gzip'], 'preprocessing_fn': <function preprocessing_fn at 0x704e57137d00>, 'stats_options_updater_fn': None, 'make_beam_pipeline_fn': <bound method BaseBeamExecutor._make_beam_pipeline of <tfx.components.transform.executor.Executor object at 0x704ea7d9f1c0>>, 'force_tf_compat_v1': False, 'save_options': None}\n",
      "DEBUG:absl:Outputs to executor.Transform function: {'transform_output_path': '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transform_graph/5', 'transform_materialize_output_paths': ['/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transformed_examples/5/Split-test/transformed_examples', '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transformed_examples/5/Split-train/transformed_examples', '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transformed_examples/5/Split-eval/transformed_examples'], 'temp_path': '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transform_graph/5/.temp_path', 'pre_transform_output_stats_path': '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/pre_transform_stats/5', 'pre_transform_output_schema_path': '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/pre_transform_schema/5', 'post_transform_output_anomalies_path': '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/post_transform_anomalies/5', 'post_transform_output_stats_path': '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/post_transform_stats/5', 'post_transform_output_schema_path': '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/post_transform_schema/5', 'cache_output_path': '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/updated_analyzer_cache/5'}\n",
      "DEBUG:absl:Force tf.compat.v1: False\n",
      "DEBUG:absl:SaveOptions: None\n",
      "DEBUG:absl:Analyze data patterns: [(0, '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/MovieLensExampleGen/output_examples/1/Split-train/*')]\n",
      "DEBUG:absl:Transform data patterns: [(0, '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/MovieLensExampleGen/output_examples/1/Split-test/*'), (1, '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/MovieLensExampleGen/output_examples/1/Split-train/*'), (2, '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/MovieLensExampleGen/output_examples/1/Split-eval/*')]\n",
      "DEBUG:absl:Transform materialization output paths: [(0, '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transformed_examples/5/Split-test/transformed_examples'), (1, '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transformed_examples/5/Split-train/transformed_examples'), (2, '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transformed_examples/5/Split-eval/transformed_examples')]\n",
      "DEBUG:absl:Transform output path: /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transform_graph/5\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tfx-user-code-transform\n",
      "Successfully installed tfx-user-code-transform-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "DEBUG:absl:inputs['genres']=Tensor(\"inputs_1_copy:0\", shape=(None, 1), dtype=string)\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "DEBUG:absl:inputs['genres']=Tensor(\"inputs_1_copy:0\", shape=(None, 1), dtype=string)\n",
      "DEBUG:absl:inputs['genres']=Tensor(\"inputs_1_copy:0\", shape=(None, 1), dtype=string)\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "DEBUG:absl:inputs['genres']=Tensor(\"inputs_1_copy:0\", shape=(None, 1), dtype=string)\n",
      "DEBUG:absl:inputs['genres']=Tensor(\"inputs_1_copy:0\", shape=(None, 1), dtype=string)\n",
      "DEBUG:absl:inputs['genres']=Tensor(\"inputs_1_copy:0\", shape=(None, 1), dtype=string)\n",
      "DEBUG:absl:inputs['genres']=Tensor(\"PlaceholderWithDefault_1:0\", shape=(None, 1), dtype=string)\n",
      "DEBUG:absl:Using existing cache in: None\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889333   nanos: 212058067 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889333   nanos: 221039295 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889333   nanos: 234356641 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889333   nanos: 244179725 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889333   nanos: 296505689 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889333   nanos: 305210828 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889333   nanos: 366804838 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889333   nanos: 373398542 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "2025-11-11 11:28:54.083230: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:28:54.083783: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:28:54.084155: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:28:54.088395: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:28:54.090236: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:28:54.097907: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:28:54.107839: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:28:54.113560: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:28:54.204096: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:28:54.218700: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:28:54.225920: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:28:54.230557: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:28:55.753069: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 11:28:55.754441: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 11:28:55.807571: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 11:28:55.826805: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889342   nanos: 685546398 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_494\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889342   nanos: 706511259 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_493\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889342   nanos: 738024234 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_495\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889342   nanos: 742881774 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_496\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x765adeec4160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x765adeec4160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x765adeec4160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x765adeec4160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x765adeec4160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x765adeec4160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x765adeec4160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x70224b5a8700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x70224b5a8700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x70224b5a8700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x70224b5a8700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x70224b5a8700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x70224b5a8700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x70224b5a8700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "DEBUG:absl:Cleaning up temp path /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transform_graph/5/.temp_path on executor success\n",
      "INFO:absl:Running publisher for Transform\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "DEBUG:absl:ConnectionConfig: sqlite {\n",
      "  filename_uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/tfx_metadata/metadata.db\"\n",
      "  connection_mode: READWRITE_OPENCREATE\n",
      "}\n",
      "\n",
      "DEBUG:absl:Outputs: {'transform_graph': [Artifact(artifact: id: 5\n",
      "type_id: 22\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transform_graph/5\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"transform_graph:2025-11-11T11:28:39.958297\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"producer_component\"\n",
      "  value {\n",
      "    string_value: \"Transform\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "name: \"transform_graph:2025-11-11T11:28:39.958297\"\n",
      ", artifact_type: id: 22\n",
      "name: \"TransformGraph\"\n",
      ")], 'transformed_examples': [Artifact(artifact: id: 6\n",
      "type_id: 14\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transformed_examples/5\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"test\\\", \\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"transformed_examples:2025-11-11T11:28:39.958297\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"producer_component\"\n",
      "  value {\n",
      "    string_value: \"Transform\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "name: \"transformed_examples:2025-11-11T11:28:39.958297\"\n",
      ", artifact_type: id: 14\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")], 'updated_analyzer_cache': [Artifact(artifact: id: 7\n",
      "type_id: 23\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/updated_analyzer_cache/5\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"updated_analyzer_cache:2025-11-11T11:28:39.958297\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"producer_component\"\n",
      "  value {\n",
      "    string_value: \"Transform\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "name: \"updated_analyzer_cache:2025-11-11T11:28:39.958297\"\n",
      ", artifact_type: id: 23\n",
      "name: \"TransformCache\"\n",
      ")], 'pre_transform_schema': [Artifact(artifact: id: 8\n",
      "type_id: 18\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/pre_transform_schema/5\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"pre_transform_schema:2025-11-11T11:28:39.958297\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"producer_component\"\n",
      "  value {\n",
      "    string_value: \"Transform\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "name: \"pre_transform_schema:2025-11-11T11:28:39.958297\"\n",
      ", artifact_type: id: 18\n",
      "name: \"Schema\"\n",
      ")], 'pre_transform_stats': [Artifact(artifact: id: 9\n",
      "type_id: 16\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/pre_transform_stats/5\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"pre_transform_stats:2025-11-11T11:28:39.958297\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"producer_component\"\n",
      "  value {\n",
      "    string_value: \"Transform\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "name: \"pre_transform_stats:2025-11-11T11:28:39.958297\"\n",
      ", artifact_type: id: 16\n",
      "name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'post_transform_schema': [Artifact(artifact: id: 10\n",
      "type_id: 18\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/post_transform_schema/5\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"post_transform_schema:2025-11-11T11:28:39.958297\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"producer_component\"\n",
      "  value {\n",
      "    string_value: \"Transform\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "name: \"post_transform_schema:2025-11-11T11:28:39.958297\"\n",
      ", artifact_type: id: 18\n",
      "name: \"Schema\"\n",
      ")], 'post_transform_stats': [Artifact(artifact: id: 11\n",
      "type_id: 16\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/post_transform_stats/5\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"post_transform_stats:2025-11-11T11:28:39.958297\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"producer_component\"\n",
      "  value {\n",
      "    string_value: \"Transform\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "name: \"post_transform_stats:2025-11-11T11:28:39.958297\"\n",
      ", artifact_type: id: 16\n",
      "name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'post_transform_anomalies': [Artifact(artifact: id: 12\n",
      "type_id: 20\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/post_transform_anomalies/5\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"post_transform_anomalies:2025-11-11T11:28:39.958297\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"producer_component\"\n",
      "  value {\n",
      "    string_value: \"Transform\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "name: \"post_transform_anomalies:2025-11-11T11:28:39.958297\"\n",
      ", artifact_type: id: 20\n",
      "name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}\n",
      "DEBUG:absl:Execution properties: None\n",
      "INFO:absl:Running driver for FromTFRecordToParquet\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "DEBUG:absl:ConnectionConfig: sqlite {\n",
      "  filename_uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/tfx_metadata/metadata.db\"\n",
      "  connection_mode: READWRITE_OPENCREATE\n",
      "}\n",
      "\n",
      "DEBUG:absl:Resolved input artifacts are: {'transform_graph': [Artifact(artifact: id: 5\n",
      "type_id: 22\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transform_graph/5\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"transform_graph:2025-11-11T11:28:39.958297\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"producer_component\"\n",
      "  value {\n",
      "    string_value: \"Transform\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"transform_graph:2025-11-11T11:28:39.958297\"\n",
      ", artifact_type: id: 22\n",
      "name: \"TransformGraph\"\n",
      ")], 'transformed_examples': [Artifact(artifact: id: 6\n",
      "type_id: 14\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transformed_examples/5\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"test\\\", \\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"transformed_examples:2025-11-11T11:28:39.958297\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"producer_component\"\n",
      "  value {\n",
      "    string_value: \"Transform\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"transformed_examples:2025-11-11T11:28:39.958297\"\n",
      ", artifact_type: id: 14\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}\n",
      "DEBUG:absl:Run context TestPipelines already exists.\n",
      "DEBUG:absl:ID of run context TestPipelines is 1.\n",
      "DEBUG:absl:Pipeline context [TestPipelines : 1]\n",
      "DEBUG:absl:ID of run context TestPipelines.2025-11-11T11:29:57.154873 is 12.\n",
      "DEBUG:absl:Pipeline run context [TestPipelines.2025-11-11T11:29:57.154873 : 12]\n",
      "DEBUG:absl:Registering an execution type with id 24.\n",
      "DEBUG:absl:Prepared EXECUTION:\n",
      " type_id: 24\n",
      "last_known_state: RUNNING\n",
      "properties {\n",
      "  key: \"component_id\"\n",
      "  value {\n",
      "    string_value: \"FromTFRecordToParquet\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"output_file_path\"\n",
      "  value {\n",
      "    string_value: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/transformed_parquet\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"pipeline_name\"\n",
      "  value {\n",
      "    string_value: \"TestPipelines\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"pipeline_root\"\n",
      "  value {\n",
      "    string_value: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"run_id\"\n",
      "  value {\n",
      "    string_value: \"2025-11-11T11:29:57.154873\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"state\"\n",
      "  value {\n",
      "    string_value: \"new\"\n",
      "  }\n",
      "}\n",
      "type: \"movie_lens_tfx.misc.tfrecord_to_parquet.FromTFRecordToParquet\"\n",
      "\n",
      "DEBUG:absl:Trying to fetch cached output artifacts with the following info: \n",
      "input_artifacts: {'transform_graph': [Artifact(artifact: id: 5\n",
      "type_id: 22\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transform_graph/5\"\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"transform_graph:2025-11-11T11:28:39.958297\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"producer_component\"\n",
      "  value {\n",
      "    string_value: \"Transform\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"transform_graph:2025-11-11T11:28:39.958297\"\n",
      ", artifact_type: id: 22\n",
      "name: \"TransformGraph\"\n",
      ")], 'transformed_examples': [Artifact(artifact: id: 6\n",
      "type_id: 14\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transformed_examples/5\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"test\\\", \\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"name\"\n",
      "  value {\n",
      "    string_value: \"transformed_examples:2025-11-11T11:28:39.958297\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"producer_component\"\n",
      "  value {\n",
      "    string_value: \"Transform\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "name: \"transformed_examples:2025-11-11T11:28:39.958297\"\n",
      ", artifact_type: id: 14\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]} \n",
      "exec_properties: {'output_file_path': '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/transformed_parquet'} \n",
      "component_info ComponentInfo(component_type: movie_lens_tfx.misc.tfrecord_to_parquet.FromTFRecordToParquet, component_id: FromTFRecordToParquet, pipeline_info: PipelineInfo(pipeline_name: TestPipelines, pipeline_root: /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines, run_id: 2025-11-11T11:29:57.154873))\n",
      "DEBUG:absl:Prepared EXECUTION:\n",
      " type_id: 24\n",
      "last_known_state: COMPLETE\n",
      "properties {\n",
      "  key: \"component_id\"\n",
      "  value {\n",
      "    string_value: \"FromTFRecordToParquet\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"output_file_path\"\n",
      "  value {\n",
      "    string_value: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/transformed_parquet\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"pipeline_name\"\n",
      "  value {\n",
      "    string_value: \"TestPipelines\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"pipeline_root\"\n",
      "  value {\n",
      "    string_value: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"run_id\"\n",
      "  value {\n",
      "    string_value: \"2025-11-11T11:29:57.154873\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"state\"\n",
      "  value {\n",
      "    string_value: \"complete\"\n",
      "  }\n",
      "}\n",
      "type: \"movie_lens_tfx.misc.tfrecord_to_parquet.FromTFRecordToParquet\"\n",
      "\n",
      "DEBUG:absl:Cached results not available, move on to new execution\n",
      "DEBUG:absl:Output artifacts skeleton for the upcoming execution are: {}\n",
      "DEBUG:absl:Execution properties for the upcoming execution are: {'output_file_path': '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/transformed_parquet'}\n",
      "INFO:absl:Running executor for FromTFRecordToParquet\n",
      "INFO:absl:Nonempty beam arg setup_file already includes dependency\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 18\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr_wk has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature sec_into_yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature weekday has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889401   nanos: 35168409 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889401   nanos: 46081304 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889401   nanos: 121034383 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889401   nanos: 137368917 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889401   nanos: 231004238 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889401   nanos: 249839544 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889401   nanos: 510123014 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889401   nanos: 516360521 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "2025-11-11 11:30:02.413739: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:30:02.418634: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:30:02.421621: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:30:02.424817: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:30:02.429023: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:30:02.431593: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:30:02.432123: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:30:02.438323: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:30:02.546399: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:30:02.550428: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:30:02.556406: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:30:02.563020: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:30:04.109016: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 11:30:04.109027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 11:30:04.259744: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 11:30:04.352748: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889411   nanos: 667358636 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_725\" transform_id: \"ReadTFRecords_866373157/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889411   nanos: 858525514 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_727\" transform_id: \"ReadTFRecords_866373157/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889411   nanos: 952390193 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_726\" transform_id: \"ReadTFRecords_866373157/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762889412   nanos: 12391328 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_728\" transform_id: \"ReadTFRecords_866373157/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-10\" \n",
      "INFO:absl:Running publisher for FromTFRecordToParquet\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "DEBUG:absl:ConnectionConfig: sqlite {\n",
      "  filename_uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/tfx_metadata/metadata.db\"\n",
      "  connection_mode: READWRITE_OPENCREATE\n",
      "}\n",
      "\n",
      "DEBUG:absl:Outputs: {}\n",
      "DEBUG:absl:Execution properties: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done pre-processing data\n"
     ]
    }
   ],
   "source": [
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "\n",
    "tf.get_logger().propagate = False\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.WARNING)\n",
    "logging.set_stderrthreshold(logging.WARNING)\n",
    "\n",
    "context = InteractiveContext(pipeline_name=PIPELINE_NAME, pipeline_root=PIPELINE_ROOT,\n",
    "  metadata_connection_config=metadata_connection_config,\n",
    "  beam_pipeline_args=beam_pipeline_args\n",
    ")\n",
    "\n",
    "factory = PipelineComponentsFactory(\n",
    "    num_examples=1000209, infiles_dict_ser=infiles_dict_ser,\n",
    "    output_config_ser=output_config_ser, transform_dir=tr_dir,\n",
    "    user_id_max=user_id_max, movie_id_max=movie_id_max,\n",
    "    n_genres=n_genres, n_age_groups=n_age_groups,\n",
    "    min_eval_size=MIN_EVAL_SIZE, batch_size=BATCH_SIZE, num_epochs=NUM_EPOCHS, device=\"CPU\",\n",
    "    serving_model_dir=serving_model_dir, output_parquet_path=output_parquet_path)\n",
    "\n",
    "components = factory.build_components(PIPELINE_TYPE.PREPROCESSING)\n",
    "\n",
    "for component in components:\n",
    "    context.run(component)\n",
    "\n",
    "print(f'done pre-processing data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5668d235-1d07-439b-a6c3-beaa701f3315",
   "metadata": {},
   "source": [
    "## EDA on the transformed data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc80d679-b7ab-40f4-90a3-77c24f06fd2e",
   "metadata": {},
   "source": [
    "### using Polars, Plotly.express \n",
    "\n",
    "this can take an hour on a single COTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b01259-457b-4c57-8a67-26b13ddd29ff",
   "metadata": {},
   "source": [
    "%run src/main/python/eda/eda_transformed.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b6dec-5ee5-4ebe-bb37-d559f8438b21",
   "metadata": {},
   "source": [
    "Some of the images are shown here from a former saved run.\n",
    "\n",
    "You can see a clear correlation between rating and movie_id, then less\n",
    "so between rating and age and rating and occupation.\n",
    "\n",
    "<img src=\"src/test/resources/train_dist_corr_heatmap.png\">\n",
    "\n",
    "You can see many co-occurrences between movie genres.\n",
    "\n",
    "<img src=\"src/test/resources/train_genre_cooccurence_rating_5_heatmap.png\">\n",
    "\n",
    "You can see that Drama, then Comedy, then Action are the most popular movie genres.\n",
    "\n",
    "<img src=\"src/test/resources/train_genres_rating_5.png\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f330e36e-74b9-4695-973c-25431bc3ea12",
   "metadata": {},
   "source": [
    "### using Pandas, Pyspark MLLIB FPGrowth\n",
    "\n",
    "This does a market basket analysis with movie_ids.\n",
    "\n",
    "If you want the PrefixSpan plots also, set\n",
    "PLOT_PREFIXSPAN = True\n",
    "but beware that the script will take much longer to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba2cda2-d3c6-4289-90a8-3ebc634373aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_PREFIXSPAN=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290d54c1-d223-40eb-9590-8e158f07a5aa",
   "metadata": {},
   "source": [
    "%run src/main/python/eda/eda_transformed_pyspark_mllib.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c5727-401a-40a2-9ee1-145e000c266a",
   "metadata": {},
   "source": [
    "Some of the images are shown here from a former saved run.\n",
    "\n",
    "You can see that many association rules can be derived from the data.\n",
    "<img src=\"src/test/resources/train_movies_assoc_rules_rating_5.png\">\n",
    "\n",
    "and that there are many frequent itemsets.\n",
    "<img src=\"src/test/resources/train_movies_itemsets_rating_5.png\">\n",
    "\n",
    "<img src=\"src/test/resources/train_movies_itemsets_rating_5_2.png\">\n",
    "\n",
    "The results show that neural network models will have good material to exploit.\n",
    "\n",
    "The PrefixScan model can be enabled in the script to provide images to explore sequences\n",
    "for actions or as precursor to Sequential DNN models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951c493f-6964-452d-997d-e51cb246c912",
   "metadata": {},
   "source": [
    "### Data and Concept Drift\n",
    "After exploring the data inputs to the model, we want to define monitoring\n",
    "for data and concept shifts.\n",
    "\n",
    "let X = features\n",
    "\n",
    "let Y = targets\n",
    "\n",
    "Data shift is a change in the joint distribution, P(X, Y). \n",
    "\n",
    "Using the probability product rule, we can explore 4 causes for the\n",
    "simplest changes in P(X,Y)\n",
    "$$ P(X, Y) = P(Y, X) = P(X|Y)P(Y) = P(Y|X)P(X) $$\n",
    "\n",
    "We can look for changes in one member in the following pairs at any time\n",
    "(one is simpler than exploring more than 1 member changing at same time):\n",
    "$$ P(X|Y) * P(Y) $$\n",
    "$$ P(Y|X) * P(X) $$\n",
    "\n",
    "* Covariate shift:\n",
    "  $$ P(X) changed,  P(Y|X) unchanged $$\n",
    "  Distr of model inputs changes.\n",
    "* Label shift:\n",
    "  $$ P(Y) changed,  P(X|Y) unchanged $$\n",
    "  Distr of model outputs changes, but for any given output, the input distribution stays the same.\n",
    "  \n",
    "* Concept shift:\n",
    "  $$ P(X) unchanged,  P(Y|X) changed $$\n",
    "* Manifestation shift:\n",
    "  $$ P(Y) unchanged,  P(X|Y) changed $$\n",
    "\n",
    "[see more at NannyML](https://www.nannyml.com/blog/concept-drift)\n",
    "\n",
    "if the train, eval, and test split are random, then one could use\n",
    "the maximum differences in their distributions as a lower limit on \n",
    "the estimate for stochastic error.  A trigger for data drift should\n",
    "then be GEQ about 3 times that stochastic error.\n",
    "\n",
    "The previous data doesn't exist yet for this project, but one could\n",
    "either download another movie-lens dataset of different time period,\n",
    "or split this 1M dataset by a timestamp ordering into 2 partitions.\n",
    "\n",
    "More data is available at [GroupLens](https://files.grouplens.org/datasets/movielens/)\n",
    "\n",
    "### Data [Drift and Skew using TFDV](https://www.tensorflow.org/tfx/tutorials/data_validation/tfdv_basic)\n",
    "* Drift\n",
    "  Drift detection is supported for categorical features and between consecutive spans of data\n",
    "  (i.e., between span N and span N+1), such as between different days of training data.\n",
    "    * L-infinity distance\n",
    "    * alerts when drift is higher than threshold distance\n",
    "* Skew\n",
    "    * data - schema skew\n",
    "      occurs when the training and serving data do not conform to the same schema.\n",
    "      Any expected deviations between the two (such as the label feature being only present in the training data but not in serving) should be specified through environments field in the schema.\n",
    "    * feature skew\n",
    "      occurs when the training and serving feature values are different\n",
    "      This can happen when:\n",
    "        * A data source of features is modified between training and serving time\n",
    "        * A difference in logic for generating between training and serving.\n",
    "    * distribution skew\n",
    "      occurs when the training and serving distributions are significantly different.\n",
    "      some key causes:\n",
    "        * different code or different data sources to generate the training dataset\n",
    "        * a faulty sampling mechanism that chooses a non-representative subsample of the serving data to train on.\n",
    "\n",
    "\n",
    "TODO: finish adding to this below with the components measuring them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0770fd1-41d6-4f7a-848e-9e73589c10ca",
   "metadata": {},
   "source": [
    "### using TFDV to look at the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d4c4dc0-6bbc-4e19-beba-ca8dc797ee2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tfx.dsl.io import fileio\n",
    "from tfx.orchestration import metadata\n",
    "from tfx.components import StatisticsGen, SchemaGen, ExampleValidator\n",
    "from tfx.utils import io_utils\n",
    "from tensorflow_metadata.proto.v0 import anomalies_pb2, schema_pb2\n",
    "from tensorflow_metadata.proto.v0 import statistics_pb2\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "import tensorflow_data_validation as tfdv"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Schema from SchemaGen:\")\n",
    "_list = store.get_artifacts_by_type(\"Schema\")\n",
    "print(f'Schema count={len(_list)}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"SchemaGen\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_path = os.path.join(artifact_uri, \"schema.pbtxt\")\n",
    "schema = tfdv.load_schema_text(file_path)\n",
    "#tfdv.visualize_artifacts(schema)\n",
    "tfdv.display_schema(schema=schema)\n",
    "\n",
    "print(\"ExampleStatistics from StatisticsGen:\")\n",
    "_list = store.get_artifacts_by_type(\"ExampleStatistics\")\n",
    "print(f'ExampleStatistics count={len(_list)}')\n",
    "#print(f'ExampleStatistics ={_list}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"StatisticsGen\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name, \"FeatureStats.pb\") \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "stats_dict = {}\n",
    "for file_path in file_paths:\n",
    "    if \"test\" in file_path:\n",
    "        #plotting train and eval\n",
    "        continue\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            serialized_stats = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")    \n",
    "    stats = statistics_pb2.DatasetFeatureStatisticsList()\n",
    "    stats.ParseFromString(serialized_stats)\n",
    "    if \"train\" in file_path:\n",
    "        stats_dict['train'] = stats\n",
    "    else:\n",
    "        stats_dict['eval'] = stats\n",
    "tfdv.visualize_statistics(lhs_statistics=stats_dict['eval'],\n",
    "    rhs_statistics=stats_dict['train'],\n",
    "    lhs_name='EVAL_DATASET', rhs_name='TRAIN_DATASET')\n",
    "\n",
    "print(\"ExampleAnomalies from ExampleValidator:\")\n",
    "_list = store.get_artifacts_by_type(\"ExampleAnomalies\")\n",
    "print(f'ExampleAnomalies count={len(_list)}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"ExampleValidator\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name, \"SchemaDiff.pb\") \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            serialized_anomalies = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Anomaly file not found at {file_path}\")\n",
    "    anomalies = anomalies_pb2.Anomalies()\n",
    "    anomalies.ParseFromString(serialized_anomalies)\n",
    "    tfdv.display_anomalies(anomalies)\n",
    "\n",
    "print(\"ExampleStatistics from pre-transform stats of Transform:\")\n",
    "_list = store.get_artifacts_by_type(\"ExampleStatistics\")\n",
    "#print(f'ExampleStatistics={_list}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"pre_transform_stats\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name) \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            serialized_stats = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")    \n",
    "    stats = statistics_pb2.DatasetFeatureStatisticsList()\n",
    "    stats.ParseFromString(serialized_stats)\n",
    "    tfdv.visualize_statistics(stats)\n",
    "    "
   ],
   "id": "6bd4e2ca38c1076d"
  },
  {
   "cell_type": "markdown",
   "id": "1f8d681e-6788-456e-8a77-91c4ea809963",
   "metadata": {},
   "source": [
    "### using TFDV to look at the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b45664b-bfed-4877-a876-9663cc2e169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema from post-Transform:\n",
      "Schema count=3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Valency</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'age'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'gender'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'genres'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'hr'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'hr_wk'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'month'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'movie_id'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'occupation'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'rating'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'sec_into_yr'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'user_id'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'weekday'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'yr'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Type  Presence Valency Domain\n",
       "Feature name                                 \n",
       "'age'          FLOAT  required              -\n",
       "'gender'       FLOAT  required              -\n",
       "'genres'       FLOAT  required              -\n",
       "'hr'           FLOAT  required              -\n",
       "'hr_wk'        FLOAT  required              -\n",
       "'month'        FLOAT  required              -\n",
       "'movie_id'     FLOAT  required              -\n",
       "'occupation'   FLOAT  required              -\n",
       "'rating'       FLOAT  required              -\n",
       "'sec_into_yr'  FLOAT  required              -\n",
       "'user_id'      FLOAT  required              -\n",
       "'weekday'      FLOAT  required              -\n",
       "'yr'           FLOAT  required              -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExampleStatistics from post-transform stats of Transform:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id='facets-iframe' width=\"100%\" height=\"500px\"></iframe>\n",
       "        <script>\n",
       "        facets_iframe = document.getElementById('facets-iframe');\n",
       "        facets_html = '<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"><\\/script><link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/master/facets-dist/facets-jupyter.html\"><facets-overview proto-input=\"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\"></facets-overview>';\n",
       "        facets_iframe.srcdoc = facets_html;\n",
       "         facets_iframe.id = \"\";\n",
       "         setTimeout(() => {\n",
       "           facets_iframe.setAttribute('height', facets_iframe.contentWindow.document.body.offsetHeight + 'px')\n",
       "         }, 1500)\n",
       "         </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExampleAnomalies from post-transform of Transform:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4 style=\"color:green;\">No anomalies found.</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(\"Schema from post-Transform:\")\n",
    "_list = store.get_artifacts_by_type(\"Schema\")\n",
    "print(f'Schema count={len(_list)}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"post_transform_schema\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_path = os.path.join(artifact_uri, \"schema.pbtxt\")\n",
    "schema = tfdv.load_schema_text(file_path)\n",
    "#tfdv.visualize_artifacts(schema)\n",
    "tfdv.display_schema(schema=schema)\n",
    "\n",
    "print(\"ExampleStatistics from post-transform stats of Transform:\")\n",
    "_list = store.get_artifacts_by_type(\"ExampleStatistics\")\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"post_transform_stats\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name) \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            serialized_stats = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")    \n",
    "    stats = statistics_pb2.DatasetFeatureStatisticsList()\n",
    "    stats.ParseFromString(serialized_stats)\n",
    "    tfdv.visualize_statistics(stats)\n",
    "    \n",
    "print(\"ExampleAnomalies from post-transform of Transform:\")\n",
    "_list = store.get_artifacts_by_type(\"ExampleAnomalies\")\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"post_transform_anomalies\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name) \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    anomalies = anomalies_pb2.Anomalies()\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            serialized_anomalies = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Anomaly file not found at {file_path}\")\n",
    "    anomalies = anomalies_pb2.Anomalies()\n",
    "    anomalies.ParseFromString(serialized_anomalies)\n",
    "    tfdv.display_anomalies(anomalies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553960d4-7320-49b1-8cdd-dd5547a3057d",
   "metadata": {},
   "source": [
    "## Save the data schema with version control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd61195-54fd-4927-9d73-5e06dcaf52c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nichole/projects/github/recommender_systems/src/main/resources/post_transform/schema.pbtxt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "_list = store.get_artifacts_by_type(\"Schema\")\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"pre_transform_schema\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "pre_transform_file_path = [os.path.join(artifact_uri, name) for name in os.listdir(artifact_uri)][0]\n",
    "\n",
    "for artifact in _list:\n",
    "    if \"post_transform_schema\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "post_transform_file_path = [os.path.join(artifact_uri, name) for name in os.listdir(artifact_uri)][0]\n",
    "\n",
    "pre_dir = os.path.join(get_project_dir(), \"src/main/resources\", \"pre_transform\")\n",
    "post_dir = os.path.join(get_project_dir(), \"src/main/resources\", \"post_transform\")\n",
    "os.makedirs(pre_dir, exist_ok=True)\n",
    "os.makedirs(post_dir, exist_ok=True)\n",
    "\n",
    "pre_schema_path = os.path.join(pre_dir, \"schema.pbtxt\")\n",
    "post_schema_path = os.path.join(post_dir, \"schema.pbtxt\")\n",
    "\n",
    "shutil.copyfile(pre_transform_file_path, pre_schema_path)\n",
    "shutil.copyfile(post_transform_file_path, post_schema_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307091b-211e-4f81-95ae-eed7ef9389b2",
   "metadata": {},
   "source": [
    "## Run baseline model pipeline with full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e02d88cf-ffb3-4396-afcb-bc4c35ebac92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Finished tuning... Tuner ID: tuner0\n",
      "INFO:absl:Best HyperParameters: {'space': [{'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.0001, 'conditions': [], 'values': [0.0001], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'regl2', 'default': 0.0, 'conditions': [], 'values': [0.0, 0.001, 0.01], 'ordered': True}}, {'class_name': 'Float', 'config': {'name': 'drop_rate', 'default': 0.5, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': None, 'sampling': 'linear'}}, {'class_name': 'Choice', 'config': {'name': 'embed_out_dim', 'default': 32, 'conditions': [], 'values': [32], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'layer_sizes', 'default': '[32]', 'conditions': [], 'values': ['[32]'], 'ordered': False}}, {'class_name': 'Fixed', 'config': {'name': 'feature_acronym', 'conditions': [], 'value': ''}}, {'class_name': 'Fixed', 'config': {'name': 'incl_genres', 'conditions': [], 'value': True}}, {'class_name': 'Fixed', 'config': {'name': 'BATCH_SIZE', 'conditions': [], 'value': 64}}, {'class_name': 'Fixed', 'config': {'name': 'NUM_EPOCHS', 'conditions': [], 'value': 20}}, {'class_name': 'Fixed', 'config': {'name': 'use_bias_corr', 'conditions': [], 'value': False}}, {'class_name': 'Fixed', 'config': {'name': 'user_id_max', 'conditions': [], 'value': 6040}}, {'class_name': 'Fixed', 'config': {'name': 'movie_id_max', 'conditions': [], 'value': 3952}}, {'class_name': 'Fixed', 'config': {'name': 'n_age_groups', 'conditions': [], 'value': 7}}, {'class_name': 'Fixed', 'config': {'name': 'n_genres', 'conditions': [], 'value': 18}}, {'class_name': 'Fixed', 'config': {'name': 'run_eagerly', 'conditions': [], 'value': False}}, {'class_name': 'Fixed', 'config': {'name': 'device', 'conditions': [], 'value': 'CPU'}}, {'class_name': 'Fixed', 'config': {'name': 'MAX_TUNE_TRIALS', 'conditions': [], 'value': 10}}, {'class_name': 'Fixed', 'config': {'name': 'input_dataset_element_spec_ser', 'conditions': [], 'value': 'gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu'}}, {'class_name': 'Fixed', 'config': {'name': 'num_train', 'conditions': [], 'value': 800167}}, {'class_name': 'Fixed', 'config': {'name': 'num_eval', 'conditions': [], 'value': 100020}}], 'values': {'learning_rate': 0.0001, 'regl2': 0.01, 'drop_rate': 0.3728729932455548, 'embed_out_dim': 32, 'layer_sizes': '[32]', 'feature_acronym': '', 'incl_genres': True, 'BATCH_SIZE': 64, 'NUM_EPOCHS': 20, 'use_bias_corr': False, 'user_id_max': 6040, 'movie_id_max': 3952, 'n_age_groups': 7, 'n_genres': 18, 'run_eagerly': False, 'device': 'CPU', 'MAX_TUNE_TRIALS': 10, 'input_dataset_element_spec_ser': 'gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu', 'num_train': 800167, 'num_eval': 100020}}\n",
      "INFO:absl:Best Hyperparameters are written to /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Tuner/best_hyperparameters/14/best_hyperparameters.txt.\n",
      "INFO:absl:Tuner results are written to /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Tuner/tuner_results/14/tuner_results.json.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 14 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Deleted stateful_working_dir /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Tuner/.system/stateful_working_dir/b808db45-3307-44f2-9bd9-fb7ca4bff036\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'tuner_results': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Tuner/tuner_results/14\"\n",
      ", artifact_type: name: \"TunerResults\"\n",
      ")], 'best_hyperparameters': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Tuner/best_hyperparameters/14\"\n",
      ", artifact_type: name: \"HyperParameters\"\n",
      ")]}) for execution 14\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Tuner is finished.\n",
      "INFO:absl:Component Trainer is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2025-11-11T11:38:47.929076\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:38:47.929076\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transformed_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Tuner\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:38:47.929076\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Tuner\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"HyperParameters\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"best_hyperparameters\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:38:47.929076\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"tune_train_movie_lens@/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Transform\"\n",
      "upstream_nodes: \"Tuner\"\n",
      "downstream_nodes: \"Evaluator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[Trainer] Resolved inputs: ({'hyperparameters': [Artifact(artifact: id: 27\n",
      "type_id: 32\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Tuner/best_hyperparameters/14\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"HyperParameters\"\n",
      "create_time_since_epoch: 1762890649520\n",
      "last_update_time_since_epoch: 1762890649520\n",
      ", artifact_type: id: 32\n",
      "name: \"HyperParameters\"\n",
      ")], 'transform_graph': [Artifact(artifact: id: 25\n",
      "type_id: 22\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transform_graph/13\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"TransformGraph\"\n",
      "create_time_since_epoch: 1762890166156\n",
      "last_update_time_since_epoch: 1762890166156\n",
      ", artifact_type: id: 22\n",
      "name: \"TransformGraph\"\n",
      ")], 'examples': [Artifact(artifact: id: 19\n",
      "type_id: 14\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transformed_examples/13\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"test\\\", \\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1762890166155\n",
      "last_update_time_since_epoch: 1762890166155\n",
      ", artifact_type: id: 14\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 15\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=15, input_dict={'hyperparameters': [Artifact(artifact: id: 27\n",
      "type_id: 32\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Tuner/best_hyperparameters/14\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"HyperParameters\"\n",
      "create_time_since_epoch: 1762890649520\n",
      "last_update_time_since_epoch: 1762890649520\n",
      ", artifact_type: id: 32\n",
      "name: \"HyperParameters\"\n",
      ")], 'transform_graph': [Artifact(artifact: id: 25\n",
      "type_id: 22\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transform_graph/13\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"TransformGraph\"\n",
      "create_time_since_epoch: 1762890166156\n",
      "last_update_time_since_epoch: 1762890166156\n",
      ", artifact_type: id: 22\n",
      "name: \"TransformGraph\"\n",
      ")], 'examples': [Artifact(artifact: id: 19\n",
      "type_id: 14\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transformed_examples/13\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"test\\\", \\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1762890166155\n",
      "last_update_time_since_epoch: 1762890166155\n",
      ", artifact_type: id: 14\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/15\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'model_run': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model_run/15\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")]}), exec_properties={'train_args': '{}', 'eval_args': '{}', 'module_path': 'tune_train_movie_lens@/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl', 'custom_config': 'null'}, execution_output_uri='/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/.system/executor_execution/15/executor_output.pb', stateful_working_dir='/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/.system/stateful_working_dir/abe2ad13-3d2e-4f3e-b081-e3a6ab7ddbe4', tmp_dir='/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/.system/executor_execution/15/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2025-11-11T11:38:47.929076\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:38:47.929076\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transformed_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Tuner\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:38:47.929076\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Tuner\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"HyperParameters\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"best_hyperparameters\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:38:47.929076\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"tune_train_movie_lens@/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Transform\"\n",
      "upstream_nodes: \"Tuner\"\n",
      "downstream_nodes: \"Evaluator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"TestPipelines\"\n",
      ", pipeline_run_id='2025-11-11T11:38:47.929076', top_level_pipeline_run_id=None, frontend_url=None)\n",
      "INFO:absl:Train on the 'train' split when train_args.splits is not set.\n",
      "INFO:absl:Evaluate on the 'eval' split when eval_args.splits is not set.\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "INFO:absl:udf_utils.get_fn {'train_args': '{}', 'eval_args': '{}', 'module_path': 'tune_train_movie_lens@/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl', 'custom_config': 'null'} 'run_fn'\n",
      "INFO:absl:Installing '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/home/nichole/miniconda3/envs/tfx_py310/bin/python3.10', '-m', 'pip', 'install', '--target', '/tmp/tmpxx6u66rp', '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 48s]\n",
      "val_loss: 0.04282231628894806\n",
      "\n",
      "Best val_loss So Far: 0.04225507378578186\n",
      "Total elapsed time: 00h 08m 00s\n",
      "Results summary\n",
      "Results in /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Tuner/.system/executor_execution/14/.temp/14/movie_lens_2t_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.01\n",
      "drop_rate: 0.3728729932455548\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: \n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.04225507378578186\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.01\n",
      "drop_rate: 0.17063992284306054\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: \n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.04251997172832489\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.0\n",
      "drop_rate: 0.4716395332419465\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: \n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.04282231628894806\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.01\n",
      "drop_rate: 0.4958359370107448\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: \n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.043106816709041595\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.01\n",
      "drop_rate: 0.42174706356581126\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: \n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.0434720441699028\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.001\n",
      "drop_rate: 0.2549371811918642\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: \n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.0434969887137413\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.01\n",
      "drop_rate: 0.4948290252945917\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: \n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.04363849759101868\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.001\n",
      "drop_rate: 0.4920737684743526\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: \n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.04364297166466713\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.0\n",
      "drop_rate: 0.1918019628639033\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: \n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.0437161847949028\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.0\n",
      "drop_rate: 0.3097510239173148\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: \n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.043771304190158844\n",
      "Processing ./bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successfully installed '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl'.\n",
      "INFO:absl:Training model.\n",
      "INFO:absl:HyperParameters for training: {'space': [{'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.0001, 'conditions': [], 'values': [0.0001], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'regl2', 'default': 0.0, 'conditions': [], 'values': [0.0, 0.001, 0.01], 'ordered': True}}, {'class_name': 'Float', 'config': {'name': 'drop_rate', 'default': 0.5, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': None, 'sampling': 'linear'}}, {'class_name': 'Choice', 'config': {'name': 'embed_out_dim', 'default': 32, 'conditions': [], 'values': [32], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'layer_sizes', 'default': '[32]', 'conditions': [], 'values': ['[32]'], 'ordered': False}}, {'class_name': 'Fixed', 'config': {'name': 'feature_acronym', 'conditions': [], 'value': ''}}, {'class_name': 'Fixed', 'config': {'name': 'incl_genres', 'conditions': [], 'value': True}}, {'class_name': 'Fixed', 'config': {'name': 'BATCH_SIZE', 'conditions': [], 'value': 64}}, {'class_name': 'Fixed', 'config': {'name': 'NUM_EPOCHS', 'conditions': [], 'value': 20}}, {'class_name': 'Fixed', 'config': {'name': 'use_bias_corr', 'conditions': [], 'value': False}}, {'class_name': 'Fixed', 'config': {'name': 'user_id_max', 'conditions': [], 'value': 6040}}, {'class_name': 'Fixed', 'config': {'name': 'movie_id_max', 'conditions': [], 'value': 3952}}, {'class_name': 'Fixed', 'config': {'name': 'n_age_groups', 'conditions': [], 'value': 7}}, {'class_name': 'Fixed', 'config': {'name': 'n_genres', 'conditions': [], 'value': 18}}, {'class_name': 'Fixed', 'config': {'name': 'run_eagerly', 'conditions': [], 'value': False}}, {'class_name': 'Fixed', 'config': {'name': 'device', 'conditions': [], 'value': 'CPU'}}, {'class_name': 'Fixed', 'config': {'name': 'MAX_TUNE_TRIALS', 'conditions': [], 'value': 10}}, {'class_name': 'Fixed', 'config': {'name': 'input_dataset_element_spec_ser', 'conditions': [], 'value': 'gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu'}}, {'class_name': 'Fixed', 'config': {'name': 'num_train', 'conditions': [], 'value': 800167}}, {'class_name': 'Fixed', 'config': {'name': 'num_eval', 'conditions': [], 'value': 100020}}], 'values': {'learning_rate': 0.0001, 'regl2': 0.01, 'drop_rate': 0.3728729932455548, 'embed_out_dim': 32, 'layer_sizes': '[32]', 'feature_acronym': '', 'incl_genres': True, 'BATCH_SIZE': 64, 'NUM_EPOCHS': 20, 'use_bias_corr': False, 'user_id_max': 6040, 'movie_id_max': 3952, 'n_age_groups': 7, 'n_genres': 18, 'run_eagerly': False, 'device': 'CPU', 'MAX_TUNE_TRIALS': 10, 'input_dataset_element_spec_ser': 'gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu', 'num_train': 800167, 'num_eval': 100020}}\n",
      "INFO:absl:device=Device.CPU, distribution strategy=<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x704e53db68f0>\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 18\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr_wk has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature sec_into_yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature weekday has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tfx-user-code-trainer\n",
      "Successfully installed tfx-user-code-trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Feature yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 18\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr_wk has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature sec_into_yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature weekday has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 18\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr_wk has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature sec_into_yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature weekday has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 18\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr_wk has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature sec_into_yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature weekday has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Model: \"two_tower_dnn_1\"\n",
      "\n",
      " Layer (type)                     Output Shape                  Param # \n",
      "\n",
      " query_model_1 (QueryModel)       (None, 32)                    194,400 \n",
      "\n",
      " candidate_model_1                (None, 32)                    129,216 \n",
      " (CandidateModel)                                                       \n",
      "\n",
      " dot_1 (Dot)                      (None, 1)                           0 \n",
      "\n",
      " activation_1 (Activation)        (None, 1)                           0 \n",
      "\n",
      " Total params: 323,616 (1.23 MB)\n",
      " Trainable params: 323,616 (1.23 MB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m12503/12503\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m54s\u001B[0m 4ms/step - mean_absolute_error: 0.1732 - root_mean_squared_error: 0.2071 - loss: 0.0426 - val_loss: 0.0429\n",
      "Epoch 2/20\n",
      "\u001B[1m12503/12503\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m53s\u001B[0m 4ms/step - mean_absolute_error: 0.1679 - root_mean_squared_error: 0.2010 - loss: 0.0386 - val_loss: 0.0404\n",
      "Epoch 3/20\n",
      "\u001B[1m12503/12503\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m82s\u001B[0m 7ms/step - mean_absolute_error: 0.1664 - root_mean_squared_error: 0.1992 - loss: 0.0383 - val_loss: 0.0397\n",
      "Epoch 4/20\n",
      "\u001B[1m12503/12503\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m82s\u001B[0m 7ms/step - mean_absolute_error: 0.1654 - root_mean_squared_error: 0.1982 - loss: 0.0381 - val_loss: 0.0393\n",
      "Epoch 5/20\n",
      "\u001B[1m12503/12503\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m52s\u001B[0m 4ms/step - mean_absolute_error: 0.1655 - root_mean_squared_error: 0.1984 - loss: 0.0380 - val_loss: 0.0394\n",
      "Epoch 6/20\n",
      "\u001B[1m12503/12503\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m82s\u001B[0m 7ms/step - mean_absolute_error: 0.1659 - root_mean_squared_error: 0.1989 - loss: 0.0380 - val_loss: 0.0396\n",
      "Epoch 7/20\n",
      "\u001B[1m12503/12503\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m52s\u001B[0m 4ms/step - mean_absolute_error: 0.1656 - root_mean_squared_error: 0.1986 - loss: 0.0379 - val_loss: 0.0394\n",
      "fit history.history={'mean_absolute_error': [0.1732100248336792, 0.16791404783725739, 0.1664000153541565, 0.16543526947498322, 0.1654801368713379, 0.16585801541805267, 0.16559599339962006], 'root_mean_squared_error': [0.20709560811519623, 0.20095473527908325, 0.1992039978504181, 0.1981678158044815, 0.19842064380645752, 0.19891424477100372, 0.1985769271850586], 'loss': [0.042630087584257126, 0.03857485577464104, 0.03826330229640007, 0.03814293071627617, 0.038044095039367676, 0.03798294812440872, 0.03792377933859825], 'val_loss': [0.0428885892033577, 0.040382806211709976, 0.03968223184347153, 0.03927048295736313, 0.03937075287103653, 0.039566878229379654, 0.03943279758095741]}\n",
      "INFO:tensorflow:struct2tensor is not available.\n",
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n",
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Function `call` contains input name(s) resource with unsupported characters which will be renamed to candidate_model_1_1_dense_candidate_1_dense_5_1_biasadd_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Function `serve_query_model` contains input name(s) resource with unsupported characters which will be renamed to query_model_1_1_dense_query_1_dense_3_1_biasadd_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Function `serve_candidate_model` contains input name(s) resource with unsupported characters which will be renamed to candidate_model_1_1_dense_candidate_1_dense_5_1_biasadd_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_features_fn spec = {raw_feature_spec}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:eval_transformed_features = {'user_id': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:10' shape=(None, 1) dtype=float32>, 'genres': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:2' shape=(None, 1, 18) dtype=float32>, 'occupation': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:7' shape=(None, 1) dtype=float32>, 'sec_into_yr': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:9' shape=(None, 1) dtype=float32>, 'weekday': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:11' shape=(None, 1) dtype=float32>, 'age': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:0' shape=(None, 1) dtype=float32>, 'yr': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:12' shape=(None, 1) dtype=float32>, 'movie_id': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:6' shape=(None, 1) dtype=float32>, 'gender': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:1' shape=(None, 1) dtype=float32>, 'hr_wk': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:4' shape=(None, 1) dtype=float32>, 'month': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:5' shape=(None, 1) dtype=float32>, 'hr': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:3' shape=(None, 1) dtype=float32>, 'rating': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:8' shape=(None, 1) dtype=float32>}\n",
      "INFO:absl:Function `transform_features_fn` contains input name(s) 2287481, 2287485, 2287489 with unsupported characters which will be renamed to transform_features_layer_2287481, transform_features_layer_2287485, transform_features_layer_2287489 in the SavedModel.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_serving: LABEL_KEY=rating, raw_feature_spec={'gender': FixedLenFeature(shape=[1], dtype=tf.string, default_value=None), 'genres': FixedLenFeature(shape=[1], dtype=tf.string, default_value=None), 'age': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None), 'movie_id': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None), 'occupation': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None), 'timestamp': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None), 'user_id': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Function `serve_tf_examples_fn` contains input name(s) 2287597, 2287601, 2287605, 2287739, 2287741, 2287743, 2287745, 2287747, 2287749, 2287751, 2287753 with unsupported characters which will be renamed to transform_features_layer_2287597, transform_features_layer_2287601, transform_features_layer_2287605, two_tower_dnn_1_1_2287739, two_tower_dnn_1_1_2287741, two_tower_dnn_1_1_2287743, two_tower_dnn_1_1_2287745, two_tower_dnn_1_1_2287747, two_tower_dnn_1_1_2287749, two_tower_dnn_1_1_2287751, two_tower_dnn_1_1_2287753 in the SavedModel.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_serving: have outputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Sharding callback duration: 17\n",
      "INFO:absl:Sharding callback duration: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/15/Format-Serving/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Writing fingerprint to /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/15/Format-Serving/fingerprint.pb\n",
      "INFO:absl:Training complete. Model written to /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/15/Format-Serving. ModelRun written to /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model_run/15\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 15 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Deleted stateful_working_dir /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/.system/stateful_working_dir/abe2ad13-3d2e-4f3e-b081-e3a6ab7ddbe4\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/15\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'model_run': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model_run/15\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")]}) for execution 15\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Trainer is finished.\n",
      "INFO:absl:Component Evaluator is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
      "    base_type: EVALUATE\n",
      "  }\n",
      "  id: \"Evaluator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2025-11-11T11:38:47.929076\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines.Evaluator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"baseline_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"latest_blessed_model_resolver\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:38:47.929076\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.latest_blessed_model_resolver\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"MovieLensExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:38:47.929076\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.MovieLensExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"output_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:38:47.929076\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"blessing\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelBlessing\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"evaluation\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelEvaluation\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"eval_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\",\\n          \\\"threshold\\\": {\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 50.0\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"rating\\\",\\n      \\\"preprocessing_function_names\\\": [\\n        \\\"transform_features\\\"\\n      ],\\n      \\\"signature_name\\\": \\\"serving_default\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {}\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"example_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"fairness_indicator_thresholds\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"MovieLensExampleGen\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "upstream_nodes: \"latest_blessed_model_resolver\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[Evaluator] Resolved inputs: ({'model': [Artifact(artifact: id: 28\n",
      "type_id: 34\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/15\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Model\"\n",
      "create_time_since_epoch: 1762891116762\n",
      "last_update_time_since_epoch: 1762891116762\n",
      ", artifact_type: id: 34\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'baseline_model': [], 'examples': [Artifact(artifact: id: 13\n",
      "type_id: 14\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/MovieLensExampleGen/output_examples/7\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1762890049222\n",
      "last_update_time_since_epoch: 1762890049222\n",
      ", artifact_type: id: 14\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 16\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=16, input_dict={'model': [Artifact(artifact: id: 28\n",
      "type_id: 34\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/15\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Model\"\n",
      "create_time_since_epoch: 1762891116762\n",
      "last_update_time_since_epoch: 1762891116762\n",
      ", artifact_type: id: 34\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'baseline_model': [], 'examples': [Artifact(artifact: id: 13\n",
      "type_id: 14\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/MovieLensExampleGen/output_examples/7\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1762890049222\n",
      "last_update_time_since_epoch: 1762890049222\n",
      ", artifact_type: id: 14\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'evaluation': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/evaluation/16\"\n",
      ", artifact_type: name: \"ModelEvaluation\"\n",
      ")], 'blessing': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/blessing/16\"\n",
      ", artifact_type: name: \"ModelBlessing\"\n",
      ")]}), exec_properties={'example_splits': 'null', 'fairness_indicator_thresholds': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"ExampleCount\",\\n          \"threshold\": {\\n            \"value_threshold\": {\\n              \"lower_bound\": 50.0\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"rating\",\\n      \"preprocessing_function_names\": [\\n        \"transform_features\"\\n      ],\\n      \"signature_name\": \"serving_default\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}'}, execution_output_uri='/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/.system/executor_execution/16/executor_output.pb', stateful_working_dir='/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/.system/stateful_working_dir/d8605875-3326-4412-b82c-7c666400e8f2', tmp_dir='/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/.system/executor_execution/16/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
      "    base_type: EVALUATE\n",
      "  }\n",
      "  id: \"Evaluator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2025-11-11T11:38:47.929076\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines.Evaluator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"baseline_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"latest_blessed_model_resolver\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:38:47.929076\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.latest_blessed_model_resolver\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"MovieLensExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:38:47.929076\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.MovieLensExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"output_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:38:47.929076\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"blessing\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelBlessing\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"evaluation\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelEvaluation\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"eval_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\",\\n          \\\"threshold\\\": {\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 50.0\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"rating\\\",\\n      \\\"preprocessing_function_names\\\": [\\n        \\\"transform_features\\\"\\n      ],\\n      \\\"signature_name\\\": \\\"serving_default\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {}\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"example_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"fairness_indicator_thresholds\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"MovieLensExampleGen\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "upstream_nodes: \"latest_blessed_model_resolver\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"TestPipelines\"\n",
      ", pipeline_run_id='2025-11-11T11:38:47.929076', top_level_pipeline_run_id=None, frontend_url=None)\n",
      "INFO:absl:Nonempty beam arg setup_file already includes dependency\n",
      "INFO:absl:udf_utils.get_fn {'example_splits': 'null', 'fairness_indicator_thresholds': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"ExampleCount\",\\n          \"threshold\": {\\n            \"value_threshold\": {\\n              \"lower_bound\": 50.0\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"rating\",\\n      \"preprocessing_function_names\": [\\n        \"transform_features\"\\n      ],\\n      \"signature_name\": \"serving_default\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}'} 'custom_eval_shared_model'\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  signature_name: \"serving_default\"\n",
      "  label_key: \"rating\"\n",
      "  preprocessing_function_names: \"transform_features\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 50.0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/15/Format-Serving as  model.\n",
      "INFO:absl:The 'example_splits' parameter is not set, using 'eval' split.\n",
      "INFO:absl:Evaluating model.\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "INFO:absl:udf_utils.get_fn {'example_splits': 'null', 'fairness_indicator_thresholds': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"ExampleCount\",\\n          \"threshold\": {\\n            \"value_threshold\": {\\n              \"lower_bound\": 50.0\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"rating\",\\n      \"preprocessing_function_names\": [\\n        \"transform_features\"\\n      ],\\n      \"signature_name\": \"serving_default\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}'} 'custom_extractors'\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  signature_name: \"serving_default\"\n",
      "  label_key: \"rating\"\n",
      "  preprocessing_function_names: \"transform_features\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 50.0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  model_names: \"\"\n",
      "}\n",
      "\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  signature_name: \"serving_default\"\n",
      "  label_key: \"rating\"\n",
      "  preprocessing_function_names: \"transform_features\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 50.0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  model_names: \"\"\n",
      "}\n",
      "\n",
      "INFO:absl:eval_shared_models have model_types: {'tf_generic'}\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  signature_name: \"serving_default\"\n",
      "  label_key: \"rating\"\n",
      "  preprocessing_function_names: \"transform_features\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 50.0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  model_names: \"\"\n",
      "}\n",
      "\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762891121   nanos: 620830774 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762891121   nanos: 629750013 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762891121   nanos: 673415899 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762891121   nanos: 686285734 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762891121   nanos: 761183738 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762891121   nanos: 753765106 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762891121   nanos: 773706674 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762891121   nanos: 786970615 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "2025-11-11 11:58:42.170512: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:58:42.176493: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:58:42.261906: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:58:42.275913: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:58:42.287844: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:58:42.362449: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:58:42.368425: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:58:42.496079: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:58:42.506560: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:58:42.635537: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:58:42.648530: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:58:42.869280: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:58:44.169057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 11:58:44.302883: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 11:58:44.547729: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 11:58:44.660246: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762891129   nanos: 191723823 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1511\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762891129   nanos: 264740943 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1512\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762891129   nanos: 280723094 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1510\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762891129   nanos: 304238796 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1509\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x7e8c1e6c3910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x7e8c1e6c3910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x7e8c1e6c3910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x7e8c1e6c3910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x7e8c1e6c3910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x7e8c1e6c3910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x732931997910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x732931997910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x732931997910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x732931997910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x732931997910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x732931997910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x7ac49053f910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x7ac49053f910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x7ac49053f910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x7ac49053f910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x7ac49053f910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x7ac49053f910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x725ba967b910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x725ba967b910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x725ba967b910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x725ba967b910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x725ba967b910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x725ba967b910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "INFO:absl:Evaluation complete. Results written to /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/evaluation/16.\n",
      "INFO:absl:Checking validation results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow_model_analysis/writers/metrics_plots_and_validations_writer.py:112: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Blessing result True written to /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/blessing/16.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 16 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Deleted stateful_working_dir /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/.system/stateful_working_dir/d8605875-3326-4412-b82c-7c666400e8f2\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'evaluation': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/evaluation/16\"\n",
      ", artifact_type: name: \"ModelEvaluation\"\n",
      ")], 'blessing': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/blessing/16\"\n",
      ", artifact_type: name: \"ModelBlessing\"\n",
      ")]}) for execution 16\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Evaluator is finished.\n"
     ]
    }
   ],
   "source": [
    "pipeline_factory = PipelineComponentsFactory(\n",
    "  num_examples=1000209, infiles_dict_ser=infiles_dict_ser,\n",
    "  output_config_ser=output_config_ser, transform_dir=tr_dir,\n",
    "  user_id_max=user_id_max, movie_id_max=movie_id_max,\n",
    "  n_genres=n_genres, n_age_groups=n_age_groups,\n",
    "  min_eval_size=MIN_EVAL_SIZE, batch_size=BATCH_SIZE, num_epochs=NUM_EPOCHS, device=\"CPU\",\n",
    "  serving_model_dir=serving_model_dir, output_parquet_path=output_parquet_path)\n",
    "\n",
    "SETUP_FILE_PATH = os.path.abspath('setup.py')\n",
    "beam_pipeline_args = [\n",
    "  '--direct_running_mode=multi_processing',\n",
    "  '--direct_num_workers=0',\n",
    "  f'--setup_file={SETUP_FILE_PATH}',\n",
    "  #f'--extra_package={ingest_tar_file}'\n",
    "]\n",
    "\n",
    "baseline_components = pipeline_factory.build_components(PIPELINE_TYPE.BASELINE,\n",
    "  run_example_diff=False, pre_transform_schema_dir_path=pre_dir,\n",
    "  post_transform_schema_dir_path=post_dir)\n",
    "\n",
    "# create baseline model\n",
    "my_pipeline = tfx.dsl.Pipeline(\n",
    "  pipeline_name=PIPELINE_NAME,\n",
    "  pipeline_root=PIPELINE_ROOT,\n",
    "  components=baseline_components,\n",
    "  enable_cache=ENABLE_CACHE,\n",
    "  metadata_connection_config=metadata_connection_config,\n",
    "  beam_pipeline_args=beam_pipeline_args,\n",
    ")\n",
    "\n",
    "tfx.orchestration.LocalDagRunner().run(my_pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8502e6-e510-4f23-badb-0d655e64e402",
   "metadata": {},
   "source": [
    "### Visualize Baseline model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b92ba2e-7383-4c93-8267-10cd8445450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_analysis.proto import validation_result_pb2\n",
    "\n",
    "def print_model_evaluation(artifact_uri):\n",
    "\n",
    "    for name in os.listdir(artifact_uri):\n",
    "        print(f\"file_name={name}\")\n",
    "        file_path = os.path.join(artifact_uri, name)\n",
    "        if name.startswith(\"metrics\"):\n",
    "            raw_dataset = tf.data.TFRecordDataset(file_path)\n",
    "            for serialized_proto in raw_dataset:\n",
    "              metrics_for_slice = metrics_for_slice_pb2.MetricsForSlice()\n",
    "              metrics_for_slice.ParseFromString(serialized_proto.numpy())\n",
    "              print(f'metrics_for_slice={metrics_for_slice}')\n",
    "        elif name.startswith(\"validations\"):\n",
    "            raw_dataset = tf.data.TFRecordDataset([file_path])\n",
    "            for serialized_validation_result in raw_dataset.as_numpy_iterator():\n",
    "                validation_result = validation_result_pb2.ValidationResult()\n",
    "                validation_result.ParseFromString(serialized_validation_result)\n",
    "                \n",
    "                # Now you can inspect the validation_result object\n",
    "                print(f\"Validation OK: {validation_result.validation_ok}\")\n",
    "                \n",
    "                # If validation_ok is False, you can see the failing checks:\n",
    "                if not validation_result.validation_ok:\n",
    "                    if hasattr(validation_result, \"metric_failures\"):\n",
    "                        for failure in validation_result.metric_failures:\n",
    "                            print(f\"  Failed Metric: {failure.metric_key.name}\")\n",
    "                            print(f\"  Failure Type: {failure.failure_type}\")\n",
    "                            print(f\"  Observed Value: {failure.observed_value.value}\")\n",
    "            validation_result = tfma.load_validation_result(file_path)\n",
    "            print(validation_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1820d838-34a3-4860-bf1a-5e23ba2af06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot ModelRun using tensorboard\n",
      "ModelRun count=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5301f8b4d0c69d2e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5301f8b4d0c69d2e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelEvaluation from Evaluator:\n",
      "Schema count=1\n",
      "ModelEvaluation uri=/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/evaluation/16\n",
      "file_name=metrics-00000-of-00001.tfrecord\n",
      "metrics_for_slice=slice_key {\n",
      "}\n",
      "metric_keys_and_values {\n",
      "  key {\n",
      "    name: \"example_count\"\n",
      "    example_weighted {\n",
      "    }\n",
      "  }\n",
      "  value {\n",
      "    double_value {\n",
      "      value: 99930.0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "file_name=eval_config.json\n",
      "file_name=plots-00000-of-00001.tfrecord\n",
      "file_name=attributions-00000-of-00001.tfrecord\n",
      "file_name=validations.tfrecord\n",
      "Validation OK: True\n",
      "validation_ok: true\n",
      "validation_details {\n",
      "  slicing_details {\n",
      "    slicing_spec {\n",
      "    }\n",
      "    num_matching_slices: 1\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 11:59:07.899446: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-11-11 11:59:07.925206: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_model_analysis.proto import metrics_for_slice_pb2\n",
    "\n",
    "#add training and eval plots: Trainer/model_run\n",
    "#  Tensorboard can visualize them\n",
    "print(f'plot ModelRun using tensorboard')\n",
    "%load_ext tensorboard\n",
    "_list = store.get_artifacts_by_type(\"ModelRun\")\n",
    "print(f'ModelRun count={len(_list)}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"Trainer\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        %tensorboard --logdir {artifact_uri}\n",
    "\n",
    "#no baseline model yet, so just read files:\n",
    "print(\"ModelEvaluation from Evaluator:\")\n",
    "_list = store.get_artifacts_by_type(\"ModelEvaluation\")\n",
    "print(f'Schema count={len(_list)}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "artifact_uri = _list[0].uri\n",
    "assert(artifact_uri is not None)\n",
    "#file_path = os.path.join(artifact_uri, \"metrics*\")\n",
    "print(f'ModelEvaluation uri={artifact_uri}')\n",
    "print_model_evaluation(artifact_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe0a7d9-5203-4698-9de8-a51d7811856a",
   "metadata": {},
   "source": [
    "## Run full model pipeline with full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19b85116-6266-4777-9444-f938f174a25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Finished tuning... Tuner ID: tuner0\n",
      "INFO:absl:Best HyperParameters: {'space': [{'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.0001, 'conditions': [], 'values': [0.0001], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'regl2', 'default': 0.0, 'conditions': [], 'values': [0.0, 0.001, 0.01], 'ordered': True}}, {'class_name': 'Float', 'config': {'name': 'drop_rate', 'default': 0.5, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': None, 'sampling': 'linear'}}, {'class_name': 'Choice', 'config': {'name': 'embed_out_dim', 'default': 32, 'conditions': [], 'values': [32], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'layer_sizes', 'default': '[32]', 'conditions': [], 'values': ['[32]'], 'ordered': False}}, {'class_name': 'Fixed', 'config': {'name': 'feature_acronym', 'conditions': [], 'value': 'a'}}, {'class_name': 'Fixed', 'config': {'name': 'incl_genres', 'conditions': [], 'value': True}}, {'class_name': 'Fixed', 'config': {'name': 'BATCH_SIZE', 'conditions': [], 'value': 64}}, {'class_name': 'Fixed', 'config': {'name': 'NUM_EPOCHS', 'conditions': [], 'value': 20}}, {'class_name': 'Fixed', 'config': {'name': 'use_bias_corr', 'conditions': [], 'value': False}}, {'class_name': 'Fixed', 'config': {'name': 'user_id_max', 'conditions': [], 'value': 6040}}, {'class_name': 'Fixed', 'config': {'name': 'movie_id_max', 'conditions': [], 'value': 3952}}, {'class_name': 'Fixed', 'config': {'name': 'n_age_groups', 'conditions': [], 'value': 7}}, {'class_name': 'Fixed', 'config': {'name': 'n_genres', 'conditions': [], 'value': 18}}, {'class_name': 'Fixed', 'config': {'name': 'run_eagerly', 'conditions': [], 'value': False}}, {'class_name': 'Fixed', 'config': {'name': 'device', 'conditions': [], 'value': 'CPU'}}, {'class_name': 'Fixed', 'config': {'name': 'MAX_TUNE_TRIALS', 'conditions': [], 'value': 10}}, {'class_name': 'Fixed', 'config': {'name': 'input_dataset_element_spec_ser', 'conditions': [], 'value': 'gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu'}}, {'class_name': 'Fixed', 'config': {'name': 'num_train', 'conditions': [], 'value': 800167}}, {'class_name': 'Fixed', 'config': {'name': 'num_eval', 'conditions': [], 'value': 100020}}], 'values': {'learning_rate': 0.0001, 'regl2': 0.01, 'drop_rate': 0.3486446815326035, 'embed_out_dim': 32, 'layer_sizes': '[32]', 'feature_acronym': 'a', 'incl_genres': True, 'BATCH_SIZE': 64, 'NUM_EPOCHS': 20, 'use_bias_corr': False, 'user_id_max': 6040, 'movie_id_max': 3952, 'n_age_groups': 7, 'n_genres': 18, 'run_eagerly': False, 'device': 'CPU', 'MAX_TUNE_TRIALS': 10, 'input_dataset_element_spec_ser': 'gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu', 'num_train': 800167, 'num_eval': 100020}}\n",
      "INFO:absl:Best Hyperparameters are written to /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Tuner/best_hyperparameters/24/best_hyperparameters.txt.\n",
      "INFO:absl:Tuner results are written to /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Tuner/tuner_results/24/tuner_results.json.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 24 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Deleted stateful_working_dir /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Tuner/.system/stateful_working_dir/78287d29-caa5-43a8-b906-2e435efc9b34\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'best_hyperparameters': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Tuner/best_hyperparameters/24\"\n",
      ", artifact_type: name: \"HyperParameters\"\n",
      ")], 'tuner_results': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Tuner/tuner_results/24\"\n",
      ", artifact_type: name: \"TunerResults\"\n",
      ")]}) for execution 24\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Tuner is finished.\n",
      "INFO:absl:Component Trainer is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2025-11-11T11:59:09.440688\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transformed_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Tuner\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Tuner\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"HyperParameters\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"best_hyperparameters\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"tune_train_movie_lens@/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Transform\"\n",
      "upstream_nodes: \"Tuner\"\n",
      "downstream_nodes: \"Evaluator\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[Trainer] Resolved inputs: ({'hyperparameters': [Artifact(artifact: id: 32\n",
      "type_id: 32\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Tuner/best_hyperparameters/24\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"HyperParameters\"\n",
      "create_time_since_epoch: 1762891663554\n",
      "last_update_time_since_epoch: 1762891663554\n",
      ", artifact_type: id: 32\n",
      "name: \"HyperParameters\"\n",
      ")], 'examples': [Artifact(artifact: id: 19\n",
      "type_id: 14\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transformed_examples/13\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"test\\\", \\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1762890166155\n",
      "last_update_time_since_epoch: 1762890166155\n",
      ", artifact_type: id: 14\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")], 'transform_graph': [Artifact(artifact: id: 25\n",
      "type_id: 22\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transform_graph/13\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"TransformGraph\"\n",
      "create_time_since_epoch: 1762890166156\n",
      "last_update_time_since_epoch: 1762890166156\n",
      ", artifact_type: id: 22\n",
      "name: \"TransformGraph\"\n",
      ")]},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 25\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=25, input_dict={'hyperparameters': [Artifact(artifact: id: 32\n",
      "type_id: 32\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Tuner/best_hyperparameters/24\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"HyperParameters\"\n",
      "create_time_since_epoch: 1762891663554\n",
      "last_update_time_since_epoch: 1762891663554\n",
      ", artifact_type: id: 32\n",
      "name: \"HyperParameters\"\n",
      ")], 'examples': [Artifact(artifact: id: 19\n",
      "type_id: 14\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transformed_examples/13\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"test\\\", \\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1762890166155\n",
      "last_update_time_since_epoch: 1762890166155\n",
      ", artifact_type: id: 14\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")], 'transform_graph': [Artifact(artifact: id: 25\n",
      "type_id: 22\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Transform/transform_graph/13\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"TransformGraph\"\n",
      "create_time_since_epoch: 1762890166156\n",
      "last_update_time_since_epoch: 1762890166156\n",
      ", artifact_type: id: 22\n",
      "name: \"TransformGraph\"\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/25\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'model_run': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model_run/25\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")]}), exec_properties={'custom_config': 'null', 'eval_args': '{}', 'train_args': '{}', 'module_path': 'tune_train_movie_lens@/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl'}, execution_output_uri='/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/.system/executor_execution/25/executor_output.pb', stateful_working_dir='/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/.system/stateful_working_dir/67f21853-e51c-42c3-ac86-fe27aec3c4bd', tmp_dir='/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/.system/executor_execution/25/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.trainer.component.Trainer\"\n",
      "    base_type: TRAIN\n",
      "  }\n",
      "  id: \"Trainer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2025-11-11T11:59:09.440688\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines.Trainer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transformed_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Tuner\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Tuner\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"HyperParameters\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"best_hyperparameters\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Transform\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Transform\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"TransformGraph\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"transform_graph\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Model\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"model_run\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelRun\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"eval_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"tune_train_movie_lens@/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"train_args\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Transform\"\n",
      "upstream_nodes: \"Tuner\"\n",
      "downstream_nodes: \"Evaluator\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"TestPipelines\"\n",
      ", pipeline_run_id='2025-11-11T11:59:09.440688', top_level_pipeline_run_id=None, frontend_url=None)\n",
      "INFO:absl:Train on the 'train' split when train_args.splits is not set.\n",
      "INFO:absl:Evaluate on the 'eval' split when eval_args.splits is not set.\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "INFO:absl:udf_utils.get_fn {'custom_config': 'null', 'eval_args': '{}', 'train_args': '{}', 'module_path': 'tune_train_movie_lens@/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl'} 'run_fn'\n",
      "INFO:absl:Installing '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl' to a temporary directory.\n",
      "INFO:absl:Executing: ['/home/nichole/miniconda3/envs/tfx_py310/bin/python3.10', '-m', 'pip', 'install', '--target', '/tmp/tmptrd2iwzw', '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 51s]\n",
      "val_loss: 0.04303045943379402\n",
      "\n",
      "Best val_loss So Far: 0.04282228276133537\n",
      "Total elapsed time: 00h 08m 29s\n",
      "Results summary\n",
      "Results in /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Tuner/.system/executor_execution/24/.temp/24/movie_lens_2t_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.01\n",
      "drop_rate: 0.3486446815326035\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: a\n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.04282228276133537\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.001\n",
      "drop_rate: 0.44177759554471363\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: a\n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.04296161234378815\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.01\n",
      "drop_rate: 0.4730512546901994\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: a\n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.04303045943379402\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.0\n",
      "drop_rate: 0.3352580185236099\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: a\n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.04306033253669739\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.0\n",
      "drop_rate: 0.40275859293495675\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: a\n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.043073248118162155\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.0\n",
      "drop_rate: 0.19237672799777888\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: a\n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.043249450623989105\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.0\n",
      "drop_rate: 0.23976878699377935\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: a\n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.043303653597831726\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.0\n",
      "drop_rate: 0.10567612036806949\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: a\n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.04349610209465027\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.0\n",
      "drop_rate: 0.1846975634959494\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: a\n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.04358592629432678\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "regl2: 0.001\n",
      "drop_rate: 0.19578642512248023\n",
      "embed_out_dim: 32\n",
      "layer_sizes: [32]\n",
      "feature_acronym: a\n",
      "incl_genres: True\n",
      "BATCH_SIZE: 64\n",
      "NUM_EPOCHS: 20\n",
      "use_bias_corr: False\n",
      "user_id_max: 6040\n",
      "movie_id_max: 3952\n",
      "n_age_groups: 7\n",
      "n_genres: 18\n",
      "run_eagerly: False\n",
      "device: CPU\n",
      "MAX_TUNE_TRIALS: 10\n",
      "input_dataset_element_spec_ser: gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu\n",
      "num_train: 800167\n",
      "num_eval: 100020\n",
      "Score: 0.04363402724266052\n",
      "Processing ./bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Successfully installed '/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/_wheels/tfx_user_code_trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96-py3-none-any.whl'.\n",
      "INFO:absl:Training model.\n",
      "INFO:absl:HyperParameters for training: {'space': [{'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.0001, 'conditions': [], 'values': [0.0001], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'regl2', 'default': 0.0, 'conditions': [], 'values': [0.0, 0.001, 0.01], 'ordered': True}}, {'class_name': 'Float', 'config': {'name': 'drop_rate', 'default': 0.5, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': None, 'sampling': 'linear'}}, {'class_name': 'Choice', 'config': {'name': 'embed_out_dim', 'default': 32, 'conditions': [], 'values': [32], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'layer_sizes', 'default': '[32]', 'conditions': [], 'values': ['[32]'], 'ordered': False}}, {'class_name': 'Fixed', 'config': {'name': 'feature_acronym', 'conditions': [], 'value': 'a'}}, {'class_name': 'Fixed', 'config': {'name': 'incl_genres', 'conditions': [], 'value': True}}, {'class_name': 'Fixed', 'config': {'name': 'BATCH_SIZE', 'conditions': [], 'value': 64}}, {'class_name': 'Fixed', 'config': {'name': 'NUM_EPOCHS', 'conditions': [], 'value': 20}}, {'class_name': 'Fixed', 'config': {'name': 'use_bias_corr', 'conditions': [], 'value': False}}, {'class_name': 'Fixed', 'config': {'name': 'user_id_max', 'conditions': [], 'value': 6040}}, {'class_name': 'Fixed', 'config': {'name': 'movie_id_max', 'conditions': [], 'value': 3952}}, {'class_name': 'Fixed', 'config': {'name': 'n_age_groups', 'conditions': [], 'value': 7}}, {'class_name': 'Fixed', 'config': {'name': 'n_genres', 'conditions': [], 'value': 18}}, {'class_name': 'Fixed', 'config': {'name': 'run_eagerly', 'conditions': [], 'value': False}}, {'class_name': 'Fixed', 'config': {'name': 'device', 'conditions': [], 'value': 'CPU'}}, {'class_name': 'Fixed', 'config': {'name': 'MAX_TUNE_TRIALS', 'conditions': [], 'value': 10}}, {'class_name': 'Fixed', 'config': {'name': 'input_dataset_element_spec_ser', 'conditions': [], 'value': 'gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu'}}, {'class_name': 'Fixed', 'config': {'name': 'num_train', 'conditions': [], 'value': 800167}}, {'class_name': 'Fixed', 'config': {'name': 'num_eval', 'conditions': [], 'value': 100020}}], 'values': {'learning_rate': 0.0001, 'regl2': 0.01, 'drop_rate': 0.3486446815326035, 'embed_out_dim': 32, 'layer_sizes': '[32]', 'feature_acronym': 'a', 'incl_genres': True, 'BATCH_SIZE': 64, 'NUM_EPOCHS': 20, 'use_bias_corr': False, 'user_id_max': 6040, 'movie_id_max': 3952, 'n_age_groups': 7, 'n_genres': 18, 'run_eagerly': False, 'device': 'CPU', 'MAX_TUNE_TRIALS': 10, 'input_dataset_element_spec_ser': 'gASV1AIAAAAAAAB9lCiMA2FnZZSMInRlbnNvcmZsb3cucHl0aG9uLmZyYW1ld29yay50ZW5zb3KUjApUZW5zb3JTcGVjlJOUjCh0ZW5zb3JmbG93LnB5dGhvbi5mcmFtZXdvcmsudGVuc29yX3NoYXBllIwLVGVuc29yU2hhcGWUk5RdlChoBYwJRGltZW5zaW9ulJOUS0CFlFKUaApLAYWUUpRlhZRSlIwidGVuc29yZmxvdy5weXRob24uZnJhbWV3b3JrLmR0eXBlc5SMCGFzX2R0eXBllJOUjAdmbG9hdDMylIWUUpROh5RSlIwGZ2VuZGVylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAZnZW5yZXOUaARoB12UKGgKS0CFlFKUaApLAYWUUpRoCksShZRSlGWFlFKUaBZOh5RSlIwCaHKUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMBWhyX3drlGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAVtb250aJRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlIwIbW92aWVfaWSUaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMCm9jY3VwYXRpb26UaARoB12UKGgKS0CFlFKUaApLAYWUUpRlhZRSlGgWToeUUpSMC3NlY19pbnRvX3lylGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd1c2VyX2lklGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAd3ZWVrZGF5lGgEaAddlChoCktAhZRSlGgKSwGFlFKUZYWUUpRoFk6HlFKUjAJ5cpRoBGgHXZQoaApLQIWUUpRoCksBhZRSlGWFlFKUaBZOh5RSlHUu', 'num_train': 800167, 'num_eval': 100020}}\n",
      "INFO:absl:device=Device.CPU, distribution strategy=<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy object at 0x704e53db68f0>\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 18\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr_wk has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature sec_into_yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature weekday has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tfx-user-code-trainer\n",
      "Successfully installed tfx-user-code-trainer-0.0+01a9a7107559a9e3785c0a8611d5a3a2edaa77a555ec16ab341d5199f0ec9b96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 18\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr_wk has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature sec_into_yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature weekday has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 18\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr_wk has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature sec_into_yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature weekday has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 18\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature hr_wk has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature sec_into_yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature weekday has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature yr has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Model: \"two_tower_dnn_1\"\n",
      "\n",
      " Layer (type)                     Output Shape                  Param # \n",
      "\n",
      " query_model_1 (QueryModel)       (None, 32)                    195,712 \n",
      "\n",
      " candidate_model_1                (None, 32)                    129,216 \n",
      " (CandidateModel)                                                       \n",
      "\n",
      " dot_1 (Dot)                      (None, 1)                           0 \n",
      "\n",
      " activation_1 (Activation)        (None, 1)                           0 \n",
      "\n",
      " Total params: 324,928 (1.24 MB)\n",
      " Trainable params: 324,928 (1.24 MB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m12503/12503\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m57s\u001B[0m 4ms/step - mean_absolute_error: 0.1725 - root_mean_squared_error: 0.2064 - loss: 0.0417 - val_loss: 0.0426\n",
      "Epoch 2/20\n",
      "\u001B[1m12503/12503\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m55s\u001B[0m 4ms/step - mean_absolute_error: 0.1680 - root_mean_squared_error: 0.2010 - loss: 0.0386 - val_loss: 0.0404\n",
      "Epoch 3/20\n",
      "\u001B[1m12503/12503\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m55s\u001B[0m 4ms/step - mean_absolute_error: 0.1670 - root_mean_squared_error: 0.1998 - loss: 0.0383 - val_loss: 0.0399\n",
      "Epoch 4/20\n",
      "\u001B[1m12503/12503\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m55s\u001B[0m 4ms/step - mean_absolute_error: 0.1657 - root_mean_squared_error: 0.1986 - loss: 0.0382 - val_loss: 0.0394\n",
      "Epoch 5/20\n",
      "\u001B[1m12503/12503\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m55s\u001B[0m 4ms/step - mean_absolute_error: 0.1659 - root_mean_squared_error: 0.1989 - loss: 0.0381 - val_loss: 0.0396\n",
      "Epoch 6/20\n",
      "\u001B[1m12503/12503\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m82s\u001B[0m 7ms/step - mean_absolute_error: 0.1661 - root_mean_squared_error: 0.1994 - loss: 0.0380 - val_loss: 0.0397\n",
      "Epoch 7/20\n",
      "\u001B[1m12503/12503\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m54s\u001B[0m 4ms/step - mean_absolute_error: 0.1660 - root_mean_squared_error: 0.1993 - loss: 0.0379 - val_loss: 0.0397\n",
      "fit history.history={'mean_absolute_error': [0.1725432276725769, 0.16804426908493042, 0.16695423424243927, 0.16574051976203918, 0.16593071818351746, 0.16609793901443481, 0.16602833569049835], 'root_mean_squared_error': [0.20637021958827972, 0.20104792714118958, 0.19984014332294464, 0.19859902560710907, 0.19893553853034973, 0.19935621321201324, 0.19925013184547424], 'loss': [0.041729554533958435, 0.03858039528131485, 0.03829227387905121, 0.03815246373414993, 0.03805501013994217, 0.0379900261759758, 0.037946902215480804], 'val_loss': [0.042588669806718826, 0.04042027145624161, 0.03993608057498932, 0.03944157063961029, 0.03957534581422806, 0.03974289819598198, 0.03970061242580414]}\n",
      "INFO:tensorflow:struct2tensor is not available.\n",
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n",
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Function `call` contains input name(s) resource with unsupported characters which will be renamed to candidate_model_1_1_dense_candidate_1_dense_5_1_biasadd_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Function `serve_query_model` contains input name(s) resource with unsupported characters which will be renamed to query_model_1_1_dense_query_1_dense_3_1_biasadd_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Function `serve_candidate_model` contains input name(s) resource with unsupported characters which will be renamed to candidate_model_1_1_dense_candidate_1_dense_5_1_biasadd_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:eval_transformed_features = {'age': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:0' shape=(None, 1) dtype=float32>, 'gender': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:1' shape=(None, 1) dtype=float32>, 'sec_into_yr': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:9' shape=(None, 1) dtype=float32>, 'weekday': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:11' shape=(None, 1) dtype=float32>, 'user_id': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:10' shape=(None, 1) dtype=float32>, 'month': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:5' shape=(None, 1) dtype=float32>, 'hr_wk': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:4' shape=(None, 1) dtype=float32>, 'yr': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:12' shape=(None, 1) dtype=float32>, 'movie_id': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:6' shape=(None, 1) dtype=float32>, 'genres': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:2' shape=(None, 1, 18) dtype=float32>, 'occupation': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:7' shape=(None, 1) dtype=float32>, 'hr': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:3' shape=(None, 1) dtype=float32>, 'rating': <tf.Tensor 'transform_features_layer/StatefulPartitionedCall:8' shape=(None, 1) dtype=float32>}\n",
      "INFO:absl:Function `transform_features_fn` contains input name(s) 4588319, 4588323, 4588327 with unsupported characters which will be renamed to transform_features_layer_4588319, transform_features_layer_4588323, transform_features_layer_4588327 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_features_fn spec = {raw_feature_spec}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_serving: LABEL_KEY=rating, raw_feature_spec={'gender': FixedLenFeature(shape=[1], dtype=tf.string, default_value=None), 'genres': FixedLenFeature(shape=[1], dtype=tf.string, default_value=None), 'age': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None), 'movie_id': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None), 'occupation': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None), 'timestamp': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None), 'user_id': FixedLenFeature(shape=[1], dtype=tf.int64, default_value=None)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Function `serve_tf_examples_fn` contains input name(s) 4588435, 4588439, 4588443, 4588600, 4588602, 4588604, 4588606, 4588608, 4588610, 4588612, 4588614, 4588616 with unsupported characters which will be renamed to transform_features_layer_4588435, transform_features_layer_4588439, transform_features_layer_4588443, two_tower_dnn_1_1_4588600, two_tower_dnn_1_1_4588602, two_tower_dnn_1_1_4588604, two_tower_dnn_1_1_4588606, two_tower_dnn_1_1_4588608, two_tower_dnn_1_1_4588610, two_tower_dnn_1_1_4588612, two_tower_dnn_1_1_4588614, two_tower_dnn_1_1_4588616 in the SavedModel.\n",
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_serving: have outputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Feature gender has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature genres has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature age has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature movie_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature occupation has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature rating has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature timestamp has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Feature user_id has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "INFO:absl:Sharding callback duration: 18\n",
      "INFO:absl:Sharding callback duration: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/25/Format-Serving/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Writing fingerprint to /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/25/Format-Serving/fingerprint.pb\n",
      "INFO:absl:Training complete. Model written to /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/25/Format-Serving. ModelRun written to /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model_run/25\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 25 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Deleted stateful_working_dir /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/.system/stateful_working_dir/67f21853-e51c-42c3-ac86-fe27aec3c4bd\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/25\"\n",
      ", artifact_type: name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'model_run': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model_run/25\"\n",
      ", artifact_type: name: \"ModelRun\"\n",
      ")]}) for execution 25\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Trainer is finished.\n",
      "INFO:absl:Component Evaluator is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
      "    base_type: EVALUATE\n",
      "  }\n",
      "  id: \"Evaluator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2025-11-11T11:59:09.440688\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines.Evaluator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"baseline_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"latest_blessed_model_resolver\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.latest_blessed_model_resolver\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"MovieLensExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.MovieLensExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"output_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"blessing\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelBlessing\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"evaluation\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelEvaluation\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"eval_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\",\\n          \\\"threshold\\\": {\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 50.0\\n            }\\n          }\\n        },\\n        {\\n          \\\"class_name\\\": \\\"MeanAbsoluteError\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": 0.4,\\n              \\\"direction\\\": \\\"LOWER_IS_BETTER\\\"\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"rating\\\",\\n      \\\"name\\\": \\\"candidate\\\",\\n      \\\"preprocessing_function_names\\\": [\\n        \\\"transform_features\\\"\\n      ],\\n      \\\"signature_name\\\": \\\"serving_default\\\"\\n    },\\n    {\\n      \\\"is_baseline\\\": true,\\n      \\\"label_key\\\": \\\"rating\\\",\\n      \\\"name\\\": \\\"baseline\\\",\\n      \\\"preprocessing_function_names\\\": [\\n        \\\"transform_features\\\"\\n      ],\\n      \\\"signature_name\\\": \\\"serving_default\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {}\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"example_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"fairness_indicator_thresholds\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"MovieLensExampleGen\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "upstream_nodes: \"latest_blessed_model_resolver\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[Evaluator] Resolved inputs: ({'examples': [Artifact(artifact: id: 13\n",
      "type_id: 14\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/MovieLensExampleGen/output_examples/7\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1762890049222\n",
      "last_update_time_since_epoch: 1762890049222\n",
      ", artifact_type: id: 14\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")], 'model': [Artifact(artifact: id: 34\n",
      "type_id: 34\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/25\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Model\"\n",
      "create_time_since_epoch: 1762892082306\n",
      "last_update_time_since_epoch: 1762892082306\n",
      ", artifact_type: id: 34\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'baseline_model': [Artifact(artifact: id: 28\n",
      "type_id: 34\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/15\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Model\"\n",
      "create_time_since_epoch: 1762891116762\n",
      "last_update_time_since_epoch: 1762891116762\n",
      ", artifact_type: id: 34\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 26\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=26, input_dict={'examples': [Artifact(artifact: id: 13\n",
      "type_id: 14\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/MovieLensExampleGen/output_examples/7\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\", \\\"test\\\"]\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1762890049222\n",
      "last_update_time_since_epoch: 1762890049222\n",
      ", artifact_type: id: 14\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")], 'model': [Artifact(artifact: id: 34\n",
      "type_id: 34\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/25\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Model\"\n",
      "create_time_since_epoch: 1762892082306\n",
      "last_update_time_since_epoch: 1762892082306\n",
      ", artifact_type: id: 34\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")], 'baseline_model': [Artifact(artifact: id: 28\n",
      "type_id: 34\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/15\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Model\"\n",
      "create_time_since_epoch: 1762891116762\n",
      "last_update_time_since_epoch: 1762891116762\n",
      ", artifact_type: id: 34\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'blessing': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/blessing/26\"\n",
      ", artifact_type: name: \"ModelBlessing\"\n",
      ")], 'evaluation': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/evaluation/26\"\n",
      ", artifact_type: name: \"ModelEvaluation\"\n",
      ")]}), exec_properties={'example_splits': 'null', 'fairness_indicator_thresholds': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"ExampleCount\",\\n          \"threshold\": {\\n            \"value_threshold\": {\\n              \"lower_bound\": 50.0\\n            }\\n          }\\n        },\\n        {\\n          \"class_name\": \"MeanAbsoluteError\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.4,\\n              \"direction\": \"LOWER_IS_BETTER\"\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"rating\",\\n      \"name\": \"candidate\",\\n      \"preprocessing_function_names\": [\\n        \"transform_features\"\\n      ],\\n      \"signature_name\": \"serving_default\"\\n    },\\n    {\\n      \"is_baseline\": true,\\n      \"label_key\": \"rating\",\\n      \"name\": \"baseline\",\\n      \"preprocessing_function_names\": [\\n        \"transform_features\"\\n      ],\\n      \"signature_name\": \"serving_default\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}'}, execution_output_uri='/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/.system/executor_execution/26/executor_output.pb', stateful_working_dir='/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/.system/stateful_working_dir/f5054118-81b8-4e4d-be06-b248b7c9508c', tmp_dir='/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/.system/executor_execution/26/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.evaluator.component.Evaluator\"\n",
      "    base_type: EVALUATE\n",
      "  }\n",
      "  id: \"Evaluator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2025-11-11T11:59:09.440688\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines.Evaluator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"baseline_model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"latest_blessed_model_resolver\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.latest_blessed_model_resolver\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"MovieLensExampleGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.MovieLensExampleGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"output_examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"blessing\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelBlessing\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"evaluation\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ModelEvaluation\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"eval_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"ExampleCount\\\",\\n          \\\"threshold\\\": {\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 50.0\\n            }\\n          }\\n        },\\n        {\\n          \\\"class_name\\\": \\\"MeanAbsoluteError\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": 0.4,\\n              \\\"direction\\\": \\\"LOWER_IS_BETTER\\\"\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"rating\\\",\\n      \\\"name\\\": \\\"candidate\\\",\\n      \\\"preprocessing_function_names\\\": [\\n        \\\"transform_features\\\"\\n      ],\\n      \\\"signature_name\\\": \\\"serving_default\\\"\\n    },\\n    {\\n      \\\"is_baseline\\\": true,\\n      \\\"label_key\\\": \\\"rating\\\",\\n      \\\"name\\\": \\\"baseline\\\",\\n      \\\"preprocessing_function_names\\\": [\\n        \\\"transform_features\\\"\\n      ],\\n      \\\"signature_name\\\": \\\"serving_default\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {}\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"example_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"fairness_indicator_thresholds\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"MovieLensExampleGen\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "upstream_nodes: \"latest_blessed_model_resolver\"\n",
      "downstream_nodes: \"Pusher\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"TestPipelines\"\n",
      ", pipeline_run_id='2025-11-11T11:59:09.440688', top_level_pipeline_run_id=None, frontend_url=None)\n",
      "INFO:absl:Nonempty beam arg setup_file already includes dependency\n",
      "INFO:absl:udf_utils.get_fn {'example_splits': 'null', 'fairness_indicator_thresholds': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"ExampleCount\",\\n          \"threshold\": {\\n            \"value_threshold\": {\\n              \"lower_bound\": 50.0\\n            }\\n          }\\n        },\\n        {\\n          \"class_name\": \"MeanAbsoluteError\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.4,\\n              \"direction\": \"LOWER_IS_BETTER\"\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"rating\",\\n      \"name\": \"candidate\",\\n      \"preprocessing_function_names\": [\\n        \"transform_features\"\\n      ],\\n      \"signature_name\": \"serving_default\"\\n    },\\n    {\\n      \"is_baseline\": true,\\n      \"label_key\": \"rating\",\\n      \"name\": \"baseline\",\\n      \"preprocessing_function_names\": [\\n        \"transform_features\"\\n      ],\\n      \"signature_name\": \"serving_default\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}'} 'custom_eval_shared_model'\n",
      "INFO:absl:Using /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/25/Format-Serving as candidate model.\n",
      "INFO:absl:Using /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/15/Format-Serving as baseline model.\n",
      "INFO:absl:The 'example_splits' parameter is not set, using 'eval' split.\n",
      "INFO:absl:Evaluating model.\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "INFO:absl:udf_utils.get_fn {'example_splits': 'null', 'fairness_indicator_thresholds': 'null', 'eval_config': '{\\n  \"metrics_specs\": [\\n    {\\n      \"metrics\": [\\n        {\\n          \"class_name\": \"ExampleCount\",\\n          \"threshold\": {\\n            \"value_threshold\": {\\n              \"lower_bound\": 50.0\\n            }\\n          }\\n        },\\n        {\\n          \"class_name\": \"MeanAbsoluteError\",\\n          \"threshold\": {\\n            \"change_threshold\": {\\n              \"absolute\": 0.4,\\n              \"direction\": \"LOWER_IS_BETTER\"\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \"model_specs\": [\\n    {\\n      \"label_key\": \"rating\",\\n      \"name\": \"candidate\",\\n      \"preprocessing_function_names\": [\\n        \"transform_features\"\\n      ],\\n      \"signature_name\": \"serving_default\"\\n    },\\n    {\\n      \"is_baseline\": true,\\n      \"label_key\": \"rating\",\\n      \"name\": \"baseline\",\\n      \"preprocessing_function_names\": [\\n        \"transform_features\"\\n      ],\\n      \"signature_name\": \"serving_default\"\\n    }\\n  ],\\n  \"slicing_specs\": [\\n    {}\\n  ]\\n}'} 'custom_extractors'\n",
      "INFO:absl:eval_shared_models have model_types: {'tf_generic'}\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762892086   nanos: 964621067 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762892086   nanos: 973538160 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762892087   nanos: 10549068 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762892087   nanos: 36621332 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762892087   nanos: 63540935 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762892087   nanos: 83812236 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762892087   nanos: 118813037 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762892087   nanos: 130270719 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386\" thread: \"MainThread\" \n",
      "2025-11-11 12:14:47.797896: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 12:14:47.804790: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 12:14:47.851681: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 12:14:47.865403: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 12:14:47.944546: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 12:14:47.990536: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 12:14:48.001083: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 12:14:48.008726: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 12:14:48.020131: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 12:14:48.091062: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 12:14:48.139975: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 12:14:48.238092: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 12:14:49.818246: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 12:14:49.940151: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 12:14:50.016890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-11-11 12:14:50.229443: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762892096   nanos: 169239997 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1653\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762892096   nanos: 215223550 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1656\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762892096   nanos: 222972154 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1654\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1762892096   nanos: 265638351 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1655\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-10\" \n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x751c829f8790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x751c829f8790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x751c829f8790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x751c829f8790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x751c829f8790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x751c829f8790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x73e21ebf8790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x73e21ebf8790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x73e21ebf8790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x73e21ebf8790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x73e21ebf8790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x73e21ebf8790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x712c2b004790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x712c2b004790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x712c2b004790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x712c2b004790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x712c2b004790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x712c2b004790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x703d06d78790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x703d06d78790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x703d06d78790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x703d06d78790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x703d06d78790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x703d06d78790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nichole/miniconda3/envs/tfx_py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 291, in __del__\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "INFO:absl:Evaluation complete. Results written to /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/evaluation/26.\n",
      "INFO:absl:Checking validation results.\n",
      "INFO:absl:Blessing result True written to /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/blessing/26.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 26 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Deleted stateful_working_dir /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/.system/stateful_working_dir/f5054118-81b8-4e4d-be06-b248b7c9508c\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'blessing': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/blessing/26\"\n",
      ", artifact_type: name: \"ModelBlessing\"\n",
      ")], 'evaluation': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/evaluation/26\"\n",
      ", artifact_type: name: \"ModelEvaluation\"\n",
      ")]}) for execution 26\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Evaluator is finished.\n",
      "INFO:absl:Component Pusher is running.\n",
      "INFO:absl:Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "    base_type: DEPLOY\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2025-11-11T11:59:09.440688\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"_Evaluator.blessing\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Evaluator\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Evaluator\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ModelBlessing\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"blessing\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model_blessing\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Evaluator\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Evaluator\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ModelBlessing\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"blessing\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  conditionals {\n",
      "    key: \"cond_1\"\n",
      "    value {\n",
      "      placeholder_expression {\n",
      "        operator {\n",
      "          compare_op {\n",
      "            lhs {\n",
      "              operator {\n",
      "                artifact_property_op {\n",
      "                  expression {\n",
      "                    operator {\n",
      "                      index_op {\n",
      "                        expression {\n",
      "                          placeholder {\n",
      "                            key: \"_Evaluator.blessing\"\n",
      "                          }\n",
      "                        }\n",
      "                      }\n",
      "                    }\n",
      "                  }\n",
      "                  key: \"blessed\"\n",
      "                  is_custom_property: true\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            rhs {\n",
      "              value {\n",
      "                int_value: 1\n",
      "              }\n",
      "            }\n",
      "            op: EQUAL\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/serving_model\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Evaluator\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "INFO:absl:[Pusher] Resolved inputs: ({'model_blessing': [Artifact(artifact: id: 36\n",
      "type_id: 38\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/blessing/26\"\n",
      "custom_properties {\n",
      "  key: \"baseline_model\"\n",
      "  value {\n",
      "    string_value: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/15\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"baseline_model_id\"\n",
      "  value {\n",
      "    int_value: 28\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"blessed\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model\"\n",
      "  value {\n",
      "    string_value: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/25\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model_id\"\n",
      "  value {\n",
      "    int_value: 34\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"ModelBlessing\"\n",
      "create_time_since_epoch: 1762892127066\n",
      "last_update_time_since_epoch: 1762892127066\n",
      ", artifact_type: id: 38\n",
      "name: \"ModelBlessing\"\n",
      ")], '_Evaluator.blessing': [Artifact(artifact: id: 36\n",
      "type_id: 38\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/blessing/26\"\n",
      "custom_properties {\n",
      "  key: \"baseline_model\"\n",
      "  value {\n",
      "    string_value: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/15\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"baseline_model_id\"\n",
      "  value {\n",
      "    int_value: 28\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"blessed\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model\"\n",
      "  value {\n",
      "    string_value: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/25\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model_id\"\n",
      "  value {\n",
      "    int_value: 34\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"ModelBlessing\"\n",
      "create_time_since_epoch: 1762892127066\n",
      "last_update_time_since_epoch: 1762892127066\n",
      ", artifact_type: id: 38\n",
      "name: \"ModelBlessing\"\n",
      ")], 'model': [Artifact(artifact: id: 34\n",
      "type_id: 34\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/25\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Model\"\n",
      "create_time_since_epoch: 1762892082306\n",
      "last_update_time_since_epoch: 1762892082306\n",
      ", artifact_type: id: 34\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]},)\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Going to run a new execution 27\n",
      "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=27, input_dict={'model_blessing': [Artifact(artifact: id: 36\n",
      "type_id: 38\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/blessing/26\"\n",
      "custom_properties {\n",
      "  key: \"baseline_model\"\n",
      "  value {\n",
      "    string_value: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/15\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"baseline_model_id\"\n",
      "  value {\n",
      "    int_value: 28\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"blessed\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model\"\n",
      "  value {\n",
      "    string_value: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/25\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model_id\"\n",
      "  value {\n",
      "    int_value: 34\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"ModelBlessing\"\n",
      "create_time_since_epoch: 1762892127066\n",
      "last_update_time_since_epoch: 1762892127066\n",
      ", artifact_type: id: 38\n",
      "name: \"ModelBlessing\"\n",
      ")], '_Evaluator.blessing': [Artifact(artifact: id: 36\n",
      "type_id: 38\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Evaluator/blessing/26\"\n",
      "custom_properties {\n",
      "  key: \"baseline_model\"\n",
      "  value {\n",
      "    string_value: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/15\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"baseline_model_id\"\n",
      "  value {\n",
      "    int_value: 28\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"blessed\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model\"\n",
      "  value {\n",
      "    string_value: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/25\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"current_model_id\"\n",
      "  value {\n",
      "    int_value: 34\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"ModelBlessing\"\n",
      "create_time_since_epoch: 1762892127066\n",
      "last_update_time_since_epoch: 1762892127066\n",
      ", artifact_type: id: 38\n",
      "name: \"ModelBlessing\"\n",
      ")], 'model': [Artifact(artifact: id: 34\n",
      "type_id: 34\n",
      "uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Trainer/model/25\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.16.0\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Model\"\n",
      "create_time_since_epoch: 1762892082306\n",
      "last_update_time_since_epoch: 1762892082306\n",
      ", artifact_type: id: 34\n",
      "name: \"Model\"\n",
      "base_type: MODEL\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Pusher/pushed_model/27\"\n",
      ", artifact_type: name: \"PushedModel\"\n",
      "base_type: MODEL\n",
      ")]}), exec_properties={'push_destination': '{\\n  \"filesystem\": {\\n    \"base_directory\": \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/serving_model\"\\n  }\\n}', 'custom_config': 'null'}, execution_output_uri='/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Pusher/.system/executor_execution/27/executor_output.pb', stateful_working_dir='/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Pusher/.system/stateful_working_dir/0aef8e7d-3d57-42c5-80a1-74e11d0f21bc', tmp_dir='/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Pusher/.system/executor_execution/27/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.pusher.component.Pusher\"\n",
      "    base_type: DEPLOY\n",
      "  }\n",
      "  id: \"Pusher\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2025-11-11T11:59:09.440688\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"TestPipelines.Pusher\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"_Evaluator.blessing\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Evaluator\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Evaluator\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ModelBlessing\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"blessing\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Trainer\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Trainer\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "        output_key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model_blessing\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"Evaluator\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2025-11-11T11:59:09.440688\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"TestPipelines.Evaluator\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ModelBlessing\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"blessing\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  conditionals {\n",
      "    key: \"cond_1\"\n",
      "    value {\n",
      "      placeholder_expression {\n",
      "        operator {\n",
      "          compare_op {\n",
      "            lhs {\n",
      "              operator {\n",
      "                artifact_property_op {\n",
      "                  expression {\n",
      "                    operator {\n",
      "                      index_op {\n",
      "                        expression {\n",
      "                          placeholder {\n",
      "                            key: \"_Evaluator.blessing\"\n",
      "                          }\n",
      "                        }\n",
      "                      }\n",
      "                    }\n",
      "                  }\n",
      "                  key: \"blessed\"\n",
      "                  is_custom_property: true\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            rhs {\n",
      "              value {\n",
      "                int_value: 1\n",
      "              }\n",
      "            }\n",
      "            op: EQUAL\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"pushed_model\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"PushedModel\"\n",
      "          base_type: MODEL\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"push_destination\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/serving_model\\\"\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"Evaluator\"\n",
      "upstream_nodes: \"Trainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "    enable_cache: true\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"TestPipelines\"\n",
      ", pipeline_run_id='2025-11-11T11:59:09.440688', top_level_pipeline_run_id=None, frontend_url=None)\n",
      "INFO:absl:Model version: 1762892127\n",
      "INFO:absl:Model written to serving path /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/serving_model/1762892127.\n",
      "INFO:absl:Model pushed to /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Pusher/pushed_model/27.\n",
      "INFO:absl:Cleaning up stateless execution info.\n",
      "INFO:absl:Execution 27 succeeded.\n",
      "INFO:absl:Cleaning up stateful execution info.\n",
      "INFO:absl:Deleted stateful_working_dir /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Pusher/.system/stateful_working_dir/0aef8e7d-3d57-42c5-80a1-74e11d0f21bc\n",
      "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"/home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines/Pusher/pushed_model/27\"\n",
      ", artifact_type: name: \"PushedModel\"\n",
      "base_type: MODEL\n",
      ")]}) for execution 27\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Pusher is finished.\n"
     ]
    }
   ],
   "source": [
    "artifact_types = store.get_artifact_types()\n",
    "logging.debug(f\"MLMD store artifact_types={artifact_types}\")\n",
    "artifacts = store.get_artifacts()\n",
    "logging.debug(f\"MLMD store artifacts={artifacts}\")\n",
    "\n",
    "components = pipeline_factory.build_components(PIPELINE_TYPE.PRODUCTION,\n",
    "  run_example_diff=False, pre_transform_schema_dir_path=pre_dir,\n",
    "  post_transform_schema_dir_path=post_dir)\n",
    "  \n",
    "# simulate experimentation of one model family\n",
    "my_pipeline = tfx.dsl.Pipeline(\n",
    "  pipeline_name=PIPELINE_NAME,\n",
    "  pipeline_root=PIPELINE_ROOT,\n",
    "  components=components,\n",
    "  enable_cache=ENABLE_CACHE,\n",
    "  metadata_connection_config=metadata_connection_config,\n",
    "  beam_pipeline_args=beam_pipeline_args,\n",
    ")\n",
    "\n",
    "tfx.orchestration.LocalDagRunner().run(my_pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3129dbd0-8256-41f3-b579-02e0bc5d2efa",
   "metadata": {},
   "source": [
    "### Visualize model fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f11f5b6e-3d1b-4f5e-a331-9beb21a2b18c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot ModelRun using tensorboard\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "ModelRun count=2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c244ba3f0c37f03a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c244ba3f0c37f03a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 254478), started 0:16:24 ago. (Use '!kill 254478' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7e12f14ca58a99ca\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7e12f14ca58a99ca\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelEvaluation from Evaluator:\n",
      "Schema count=2\n",
      "file_name=metrics-00000-of-00001.tfrecord\n",
      "metrics_for_slice=slice_key {\n",
      "}\n",
      "metric_keys_and_values {\n",
      "  key {\n",
      "    name: \"example_count\"\n",
      "    model_name: \"candidate\"\n",
      "    example_weighted {\n",
      "    }\n",
      "  }\n",
      "  value {\n",
      "    double_value {\n",
      "      value: 99930.0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "metric_keys_and_values {\n",
      "  key {\n",
      "    name: \"example_count\"\n",
      "    model_name: \"baseline\"\n",
      "    example_weighted {\n",
      "    }\n",
      "  }\n",
      "  value {\n",
      "    double_value {\n",
      "      value: 99930.0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "metric_keys_and_values {\n",
      "  key {\n",
      "    name: \"mean_absolute_error\"\n",
      "    model_name: \"candidate\"\n",
      "    example_weighted {\n",
      "    }\n",
      "  }\n",
      "  value {\n",
      "    double_value {\n",
      "      value: 0.16602131369887746\n",
      "    }\n",
      "  }\n",
      "}\n",
      "metric_keys_and_values {\n",
      "  key {\n",
      "    name: \"mean_absolute_error\"\n",
      "    model_name: \"baseline\"\n",
      "    example_weighted {\n",
      "    }\n",
      "  }\n",
      "  value {\n",
      "    double_value {\n",
      "      value: 0.16560006661606674\n",
      "    }\n",
      "  }\n",
      "}\n",
      "metric_keys_and_values {\n",
      "  key {\n",
      "    name: \"example_count\"\n",
      "    model_name: \"candidate\"\n",
      "    is_diff: true\n",
      "    example_weighted {\n",
      "    }\n",
      "  }\n",
      "  value {\n",
      "    double_value {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "metric_keys_and_values {\n",
      "  key {\n",
      "    name: \"mean_absolute_error\"\n",
      "    model_name: \"candidate\"\n",
      "    is_diff: true\n",
      "    example_weighted {\n",
      "    }\n",
      "  }\n",
      "  value {\n",
      "    double_value {\n",
      "      value: 0.0004212470828107162\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "file_name=eval_config.json\n",
      "file_name=plots-00000-of-00001.tfrecord\n",
      "file_name=attributions-00000-of-00001.tfrecord\n",
      "file_name=validations.tfrecord\n",
      "Validation OK: True\n",
      "validation_ok: true\n",
      "validation_details {\n",
      "  slicing_details {\n",
      "    slicing_spec {\n",
      "    }\n",
      "    num_matching_slices: 1\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 12:15:31.824539: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-11-11 12:15:31.854755: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "#add training and eval plots: Trainer/model_run\n",
    "#  Tensorboard can visualize them\n",
    "print(f'plot ModelRun using tensorboard')\n",
    "%load_ext tensorboard\n",
    "_list = store.get_artifacts_by_type(\"ModelRun\")\n",
    "print(f'ModelRun count={len(_list)}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"Trainer\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        %tensorboard --logdir {artifact_uri}\n",
    "\n",
    "print(\"ModelEvaluation from Evaluator:\")\n",
    "_list = store.get_artifacts_by_type(\"ModelEvaluation\")\n",
    "print(f'Schema count={len(_list)}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "artifact_uri = _list[0].uri\n",
    "print_model_evaluation(artifact_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb5a19-c8c5-4573-a1a9-855c51807a4f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Monitoring deployed model\n",
    "\n",
    "The model deployed to production is monitored to detect when the business utility drops below an acceptable threshold.\n",
    "The business utility here is linked to the accuracy of recommending movies to the user that they would like and haven't seen.\n",
    "\n",
    "Detecting model degradation when users have watched a movie, and before they have rated them, requires bootstrapping\n",
    "using an extra model trained from reference data that has the user ratings. \n",
    "\n",
    "NannyML is a popular library used for detecting changes in ML model features, targets, and relationships between\n",
    "them.  \n",
    "The (NannyML Model performance estimator) [https://nannyml.readthedocs.io/en/stable/how_it_works/performance_estimation.html#dle-implementation-details] for regression  is their Direct Loss Estimator algorithm (DLE).\n",
    "\n",
    "The models:\n",
    "* f = the monitored recommender model\n",
    "* h = the Nanny model (discussed below)\n",
    "\n",
    "The datasets used:\n",
    "* train: used to train f.  contains features X and targets Y where targets are the ratings.\n",
    "* reference: used to train h. contains features X and targets Y\n",
    "* analysis: recent data.  contains only features X\n",
    "The datasets are ordered by time.\n",
    "\n",
    "The nanny model h is an extra mode used for degradation monitoring.\n",
    "* h is trained with X_reference, and y_reference\n",
    "    * for each observation in X, calculate absolute error AE_reference = | f(X_reference) - y_reference |\n",
    "    * train A_reference = h(X_reference, f(X_reference))\n",
    "          * DLE for regression uses LightGBM\n",
    "* predict AE_analysis using h\n",
    "    * for each observation in X: AE_analysis_est = h( X_analysis, f(X_analysis))\n",
    "    * MAE_analysis_est = mean of the AE_analysis_est\n",
    "* the variance of large chunks of data are determined and the upper and lower bounds for anomalies are set using the sample error using those variances.  When a predicted MAE exceed the thresholds, an alert can be triggered and root cause analysis can be performed to decide if the model should be retrained or refactored and retrained as part of a Continuous Training (CT) workflow.\n",
    "\n",
    "DLE assumes:\n",
    "* no concept drift\n",
    "* no covariate shift to previously unseen regions of input space\n",
    "* noise is heteroscedastic around the monitored model target, y,\n",
    "  and it is dependent on the monitored model input features\n",
    "* the dataset to be analyzed is large enough so that the performance estimate is not dominated by sampling error\n",
    "\n",
    "#### Model monitoring is a separate process from the serving inference, so an application can be built for it or cloud options\n",
    "can be used when configuring batch inference.\n",
    "\n",
    "TODO: add cloud model monitoring options and details...\n",
    "Apache Airflow,  Vertex AI Model Monitoring, Azure ML Model monitoring though NannyML is an option through Azure Marketplace, Amazon SageMaker Model monitor and NannyML is an option through the marketplace,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edc3d0c-7ddb-44d1-8e1c-f56ebc2178de",
   "metadata": {},
   "source": [
    "## Linking to business value\n",
    "TODO: add the ranking model and precision@K, recall@K and NDCG.  this is in the other notebook, so can be merged when finished....\n",
    "\n",
    "TODO: list supplemental data that could be used to link to business value:\n",
    "click through rate, conversion rate, user engagement, churn, revenue uplift from associated ads.\n",
    "\n",
    "TODO: quantifying the business value:\n",
    "A/B testing with control group and test group where the later receives ranked recommendation from the new model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c7a2b-f8c8-48f7-ab1b-0d094b00adcb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "TFX pipelines are valuable tools in MLOps\n",
    "* highly scalable\n",
    "    * distributed data pre-processing\n",
    "    * distributed model training\n",
    "* configurable to run on a variety of architectures\n",
    "    * e.g. TPUs, GPUs for accelerated training\n",
    "* configurable for variety of different data source types\n",
    "* configurable for fault tolerance and failover\n",
    "* configurable for different types of pipeline storage and model registry\n",
    "* configurable for cloud native, cloud specific, and local environments\n",
    "* robust, consistent processing\n",
    "* configurable exported model types compatible with keras, pytorch, jax:\n",
    "    * default saved_models\n",
    "    * liteRT for embedded and IOT environments\n",
    "    * TensorflowJS for browsers\n",
    "* usable in cloud environments\n",
    "    * compatible with many orchestrators\n",
    "        * Apache Airflow, Apache Beam, Kubeflow pipelines\n",
    "    * can be used in containers (required by kubernetes for example)\n",
    "    * compatible with cluster management systems like kubernetes, flink, spark, and cloud native offerings\n",
    "    * can be compiled into Kubeflow pipelines\n",
    "    * can be run from a command line interface in the cloud or locally\n",
    "* the MLMD store is usable by a variety of monitoring systems including cloud-specific systems\n",
    "* Tensorboard for visualization of model training output, TFDV for visualization of data\n",
    "* compatible with use of BI tools like GCP's Looker, DataPrep\n",
    "* inter-operative with Vertex AI Training, Prediction, Dataflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
