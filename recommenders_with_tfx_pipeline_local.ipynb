{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50571b6d-4578-48a7-8864-cfa7565dfcbc",
   "metadata": {},
   "source": [
    "This is a local, non-Kaggle notebook in which TFX 1.16.0 and python 3.10 and the compatible versions of other libraries are installed in a virtual environment that this notebook is running in.\n",
    "\n",
    "paths are relative to the github repository directory, \"recommender_systems\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ed99ee786e13e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 16:49:09.522381: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-04 16:49:09.525394: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-04 16:49:09.567642: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-04 16:49:10.438659: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO:absl:tensorflow_io is not available: No module named 'tensorflow_io'\n",
      "INFO:absl:tensorflow_ranking is not available: No module named 'tensorflow_ranking'\n",
      "INFO:absl:tensorflow_text is not available: No module named 'tensorflow_text'\n",
      "INFO:absl:tensorflow_decision_forests is not available: No module named 'tensorflow_decision_forests'\n",
      "INFO:absl:struct2tensor is not available: No module named 'struct2tensor'\n",
      "INFO:absl:tensorflow_text is not available.\n",
      "INFO:absl:tensorflow_recommenders is not available.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "from tfx.orchestration import metadata\n",
    "\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "from ml_metadata.metadata_store import metadata_store\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src/test/python/movie_lens_tfx\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src/main/python/movie_lens_tfx\"))\n",
    "\n",
    "from helper import *\n",
    "from movie_lens_tfx.PipelineComponentsFactory import *\n",
    "from movie_lens_tfx.tune_train_movie_lens import *\n",
    "\n",
    "from absl import logging\n",
    "tf.get_logger().propagate = False\n",
    "logging.set_verbosity(logging.WARNING)\n",
    "logging.set_stderrthreshold(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c98cdd-f021-49f6-af4a-aa571bf03b04",
   "metadata": {},
   "source": [
    "## EDA on the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad33acc-b994-420b-a0ad-ae1f178987e3",
   "metadata": {},
   "source": [
    "### w/ Polars and Plotly express\n",
    "output is written to bin/local_notebook/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e6b19f-4bd3-46eb-b4a2-537f9f2507fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD=/home/nichole/projects/github/recommender_systems, kaggle=False\n",
      "key=ratings, file_path=/home/nichole/projects/github/recommender_systems/src/main/resources/ml-1m/ratings.dat\n",
      "key=users, file_path=/home/nichole/projects/github/recommender_systems/src/main/resources/ml-1m/users.dat\n",
      "key=movies, file_path=/home/nichole/projects/github/recommender_systems/src/main/resources/ml-1m/movies.dat\n",
      "177 movies were not rated\n",
      "0 users did not rate\n",
      "\n",
      "ratings: DESCRIBE\n",
      "<bound method DataFrame.describe of shape: (1_000_209, 4)\n",
      "┌─────────┬──────────┬────────┬───────────┐\n",
      "│ user_id ┆ movie_id ┆ rating ┆ timestamp │\n",
      "│ ---     ┆ ---      ┆ ---    ┆ ---       │\n",
      "│ i64     ┆ i64      ┆ i64    ┆ i64       │\n",
      "╞═════════╪══════════╪════════╪═══════════╡\n",
      "│ 1       ┆ 1193     ┆ 5      ┆ 978300760 │\n",
      "│ 1       ┆ 661      ┆ 3      ┆ 978302109 │\n",
      "│ 1       ┆ 914      ┆ 3      ┆ 978301968 │\n",
      "│ 1       ┆ 3408     ┆ 4      ┆ 978300275 │\n",
      "│ 1       ┆ 2355     ┆ 5      ┆ 978824291 │\n",
      "│ …       ┆ …        ┆ …      ┆ …         │\n",
      "│ 6040    ┆ 1091     ┆ 1      ┆ 956716541 │\n",
      "│ 6040    ┆ 1094     ┆ 5      ┆ 956704887 │\n",
      "│ 6040    ┆ 562      ┆ 5      ┆ 956704746 │\n",
      "│ 6040    ┆ 1096     ┆ 4      ┆ 956715648 │\n",
      "│ 6040    ┆ 1097     ┆ 4      ┆ 956715569 │\n",
      "└─────────┴──────────┴────────┴───────────┘>\n",
      "\n",
      "users: DESCRIBE\n",
      "<bound method DataFrame.describe of shape: (6_040, 5)\n",
      "┌─────────┬────────┬─────┬────────────┬─────────┐\n",
      "│ user_id ┆ gender ┆ age ┆ occupation ┆ zipcode │\n",
      "│ ---     ┆ ---    ┆ --- ┆ ---        ┆ ---     │\n",
      "│ i64     ┆ str    ┆ i64 ┆ i64        ┆ str     │\n",
      "╞═════════╪════════╪═════╪════════════╪═════════╡\n",
      "│ 1       ┆ F      ┆ 1   ┆ 10         ┆ 48067   │\n",
      "│ 2       ┆ M      ┆ 56  ┆ 16         ┆ 70072   │\n",
      "│ 3       ┆ M      ┆ 25  ┆ 15         ┆ 55117   │\n",
      "│ 4       ┆ M      ┆ 45  ┆ 7          ┆ 02460   │\n",
      "│ 5       ┆ M      ┆ 25  ┆ 20         ┆ 55455   │\n",
      "│ …       ┆ …      ┆ …   ┆ …          ┆ …       │\n",
      "│ 6036    ┆ F      ┆ 25  ┆ 15         ┆ 32603   │\n",
      "│ 6037    ┆ F      ┆ 45  ┆ 1          ┆ 76006   │\n",
      "│ 6038    ┆ F      ┆ 56  ┆ 1          ┆ 14706   │\n",
      "│ 6039    ┆ F      ┆ 45  ┆ 0          ┆ 01060   │\n",
      "│ 6040    ┆ M      ┆ 25  ┆ 6          ┆ 11106   │\n",
      "└─────────┴────────┴─────┴────────────┴─────────┘>\n",
      "\n",
      "movies: DESCRIBE\n",
      "<bound method DataFrame.describe of shape: (3_883, 3)\n",
      "┌──────────┬────────────────────────────────────┬──────────────────────────────┐\n",
      "│ movie_id ┆ title                              ┆ genres                       │\n",
      "│ ---      ┆ ---                                ┆ ---                          │\n",
      "│ i64      ┆ str                                ┆ str                          │\n",
      "╞══════════╪════════════════════════════════════╪══════════════════════════════╡\n",
      "│ 1        ┆ Toy Story (1995)                   ┆ Animation|Children's|Comedy  │\n",
      "│ 2        ┆ Jumanji (1995)                     ┆ Adventure|Children's|Fantasy │\n",
      "│ 3        ┆ Grumpier Old Men (1995)            ┆ Comedy|Romance               │\n",
      "│ 4        ┆ Waiting to Exhale (1995)           ┆ Comedy|Drama                 │\n",
      "│ 5        ┆ Father of the Bride Part II (1995) ┆ Comedy                       │\n",
      "│ …        ┆ …                                  ┆ …                            │\n",
      "│ 3948     ┆ Meet the Parents (2000)            ┆ Comedy                       │\n",
      "│ 3949     ┆ Requiem for a Dream (2000)         ┆ Drama                        │\n",
      "│ 3950     ┆ Tigerland (2000)                   ┆ Drama                        │\n",
      "│ 3951     ┆ Two Family House (2000)            ┆ Drama                        │\n",
      "│ 3952     ┆ Contender, The (2000)              ┆ Drama|Thriller               │\n",
      "└──────────┴────────────────────────────────────┴──────────────────────────────┘>\n"
     ]
    }
   ],
   "source": [
    "%run src/main/python/eda/eda_raw.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a6b2d4-2479-4069-aee1-59ecd131e040",
   "metadata": {},
   "source": [
    "### Run data pre-processing on full dataset to get the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a693174b-6f67-48b0-a227-85324cb3bf2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD=/home/nichole/projects/github/recommender_systems, kaggle=False\n",
      "removing: /home/nichole/projects/github/recommender_systems/bin/local_notebook/1/TestPipelines\n"
     ]
    }
   ],
   "source": [
    "infiles_dict_ser, output_config_ser, split_names = get_test_data(use_small=False)\n",
    "user_id_max = 6040\n",
    "movie_id_max = 3952\n",
    "n_genres = N_GENRES\n",
    "n_age_groups = N_AGE_GROUPS\n",
    "n_occupations = 21\n",
    "MIN_EVAL_SIZE = 50 #make this larger for production pipeline\n",
    "\n",
    "test_num = \"1\"\n",
    "    \n",
    "PIPELINE_NAME = 'TestPipelines'\n",
    "output_data_dir = os.path.join(get_bin_dir(), \"local_notebook\", test_num)\n",
    "PIPELINE_ROOT = os.path.join(output_data_dir, PIPELINE_NAME)\n",
    "\n",
    "# remove results from previous test runs:\n",
    "try:\n",
    "  print(f\"removing: {PIPELINE_ROOT}\")\n",
    "  shutil.rmtree(PIPELINE_ROOT)\n",
    "except OSError as e:\n",
    "  pass\n",
    "METADATA_PATH = os.path.join(PIPELINE_ROOT, 'tfx_metadata',\n",
    "                             'metadata.db')\n",
    "os.makedirs(os.path.join(PIPELINE_ROOT, 'tfx_metadata'),\n",
    "            exist_ok=True)\n",
    "\n",
    "ENABLE_CACHE = True\n",
    "\n",
    "# metadata_connection_config = metadata_store_pb2.ConnectionConfig()\n",
    "# metadata_connection_config.sqlite.SetInParent()\n",
    "# metadata_connection = metadata.Metadata(metadata_connection_config)\n",
    "metadata_connection_config = metadata.sqlite_metadata_connection_config(\n",
    "  METADATA_PATH)\n",
    "\n",
    "store = metadata_store.MetadataStore(metadata_connection_config)\n",
    "\n",
    "if get_kaggle():\n",
    "  tr_dir = \"/kaggle/working/\"\n",
    "else:\n",
    "  tr_dir = os.path.join(get_project_dir(), \"src/main/python/movie_lens_tfx\")\n",
    "\n",
    "serving_model_dir = os.path.join(PIPELINE_ROOT, 'serving_model')\n",
    "output_parquet_path = os.path.join(PIPELINE_ROOT, \"transformed_parquet\")\n",
    "\n",
    "# for the custom ingestion component, the apache beam pipeline needs to be able to\n",
    "# find the sibling scripts it imports.\n",
    "# 2 solutions: (1) create a tar archive and use --extra_package in pipeline args\n",
    "# or (2) use setup.py and --setup_file in pipeline args.\n",
    "\n",
    "beam_pipeline_args = [\n",
    "  '--direct_running_mode=multi_processing',\n",
    "  '--direct_num_workers=0',\n",
    "  '--setup_file=setup.py',\n",
    "  #f'--extra_package={ingest_tar_file}'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aba56d14-a868-4878-a64f-74ade8c57b98",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'example_resolver' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113609/2128073724.py\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     MIN_EVAL_SIZE, serving_model_dir, output_parquet_path)\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mcomponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPIPELINE_TYPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREPROCESSING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/github/recommender_systems/src/main/python/movie_lens_tfx/PipelineComponentsFactory.py\u001b[0m in \u001b[0;36mbuild_components\u001b[0;34m(self, type, run_example_diff)\u001b[0m\n\u001b[1;32m    100\u001b[0m       )\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtuner_custom_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         return [example_gen, statistics_gen, schema_gen, example_resolver, example_diff,\n\u001b[0m\u001b[1;32m    103\u001b[0m                 example_validator, ratings_transform, parquet_task]\n\u001b[1;32m    104\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'example_resolver' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "\n",
    "tf.get_logger().propagate = False\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.WARNING)\n",
    "logging.set_stderrthreshold(logging.WARNING)\n",
    "\n",
    "context = InteractiveContext(pipeline_name=PIPELINE_NAME, pipeline_root=PIPELINE_ROOT,\n",
    "  metadata_connection_config=metadata_connection_config,\n",
    "  beam_pipeline_args=beam_pipeline_args\n",
    ")\n",
    "\n",
    "factory = PipelineComponentsFactory(infiles_dict_ser, output_config_ser, tr_dir,\n",
    "    user_id_max, movie_id_max, n_genres, n_age_groups,\n",
    "    MIN_EVAL_SIZE, serving_model_dir, output_parquet_path)\n",
    "\n",
    "components = factory.build_components(PIPELINE_TYPE.PREPROCESSING)\n",
    "\n",
    "for component in components:\n",
    "    context.run(component)\n",
    "\n",
    "print(f'done pre-processing data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dfcaa8-d03f-4c52-a47e-c32da31b6071",
   "metadata": {},
   "source": [
    "## EDA on the transformed data\n",
    "output is written to bin/local_notebook/images/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc80d679-b7ab-40f4-90a3-77c24f06fd2e",
   "metadata": {},
   "source": [
    "### using Polars, Plotly.express \n",
    "\n",
    "this can take an hour on a single COTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f10a4-6b75-464e-8f7e-fec52c9928a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/main/python/eda/eda_transformed.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f330e36e-74b9-4695-973c-25431bc3ea12",
   "metadata": {},
   "source": [
    "### using Pandas, Pyspark MLLIB FPGrowth\n",
    "\n",
    "This does a market basket analysis with movie_ids.\n",
    "\n",
    "If you want the PrefixSpan plots also, set\n",
    "PLOT_PREFIXSPAN = True\n",
    "but beware that the script will take much longer to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba2cda2-d3c6-4289-90a8-3ebc634373aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_PREFIXSPAN=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4b977-4809-4c03-a2d1-6629b062ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/main/python/eda/eda_transformed_pyspark_mllib.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951c493f-6964-452d-997d-e51cb246c912",
   "metadata": {},
   "source": [
    "### Data and Concept Drift\n",
    "After exploring the data inputs to the model, we want to define monitoring\n",
    "for data and concept shifts.\n",
    "\n",
    "let X = features\n",
    "\n",
    "let Y = targets\n",
    "\n",
    "Data shift is a change in the joint distribution, P(X, Y). \n",
    "\n",
    "Using the probability product rule, we can explore 4 causes for the\n",
    "simplest changes in P(X,Y)\n",
    "$$ P(X, Y) = P(Y, X) = P(X|Y)P(Y) = P(Y|X)P(X) $$\n",
    "\n",
    "We can look for changes in one member in the following pairs at any time\n",
    "(one is simpler than exploring more than 1 member changing at same time):\n",
    "$$ P(X|Y) * P(Y) $$\n",
    "$$ P(Y|X) * P(X) $$\n",
    "\n",
    "* Covariate shift:\n",
    "  $$ P(X) changed.  P(Y|X) unchanged $$\n",
    "  Distr of model inputs changes.\n",
    "* Label shift:\n",
    "  $$ P(Y) changed,  P(X|Y) unchanged $$\n",
    "  Distr of model outputs changes, but for any given output, the input distribution stays the same.\n",
    "  \n",
    "* Concept shift:\n",
    "  $$ P(X) unchanged,  P(Y|X) changed $$\n",
    "* Manifestation shift:\n",
    "  $$ P(Y) unchanged,  P(X|Y) changed $$\n",
    "\n",
    "[see more at NannyML](https://www.nannyml.com/blog/concept-drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0770fd1-41d6-4f7a-848e-9e73589c10ca",
   "metadata": {},
   "source": [
    "### using TFDV to look at the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa6e114-d61a-40d3-ac2a-b3c4dde3fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.dsl.io import fileio\n",
    "from tfx.orchestration import metadata\n",
    "from tfx.components import StatisticsGen, SchemaGen, ExampleValidator\n",
    "from tfx.utils import io_utils\n",
    "from tensorflow_metadata.proto.v0 import anomalies_pb2, schema_pb2\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "\n",
    "_list = store.get_artifacts_by_type(\"ExampleStatistics\")\n",
    "print(f'artifacts={_list}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"ExampleStatistics\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name, \"FeatureStats.pb\") \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    stats_proto = tfdv.load_stats_binary(file_path)\n",
    "    tfdv.visualize_statistics(stats_proto)\n",
    "\n",
    "#ExampleAnomalies\n",
    "_list = store.get_artifacts_by_type(\"ExampleAnomalies\")\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"ExampleAnomalies\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name, \"SchemaDiff.pb\") \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    stats_proto = tfdv.load_stats_binary(file_path)\n",
    "    tfdv.visualize_artifacts(stats_proto)\n",
    "\n",
    "_list = store.get_artifacts_by_type(\"ExampleStatistics\")\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"pre_transform_stats\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name, \"FeatureStats.pb\") \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    stats_proto = tfdv.load_stats_binary(file_path)\n",
    "    tfdv.visualize_statistics(stats_proto)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d681e-6788-456e-8a77-91c4ea809963",
   "metadata": {},
   "source": [
    "### using TFDV to look at the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30943e-9caa-4009-a73c-c4fa7298639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_list = store.get_artifacts_by_type(\"ExampleStatistics\")\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"post_transform_stats\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name, \"FeatureStats.pb\") \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    stats_proto = tfdv.load_stats_binary(file_path)\n",
    "    tfdv.visualize_statistics(stats_proto)\n",
    "    \n",
    "#ExampleAnomalies\n",
    "_list = store.get_artifacts_by_type(\"ExampleAnomalies\")\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"post_transform_anomalies\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name, \"SchemaDiff.pb\") \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    stats_proto = tfdv.load_stats_binary(file_path)\n",
    "    tfdv.visualize_artifacts(stats_proto)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307091b-211e-4f81-95ae-eed7ef9389b2",
   "metadata": {},
   "source": [
    "## Run baseline model pipeline with full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ef186-8c42-4e25-a8ca-cc0295879a68",
   "metadata": {},
   "source": [
    "pipeline_factory = PipelineComponentsFactory(\n",
    "  infiles_dict_ser=infiles_dict_ser, output_config_ser=output_config_ser,\n",
    "  transform_dir=tr_dir, user_id_max=user_id_max, movie_id_max=movie_id_max,\n",
    "  n_genres=n_genres, n_age_groups=n_age_groups, min_eval_size=MIN_EVAL_SIZE,\n",
    "  serving_model_dir=serving_model_dir,\n",
    ")\n",
    "\n",
    "beam_pipeline_args = [\n",
    "  '--direct_running_mode=multi_processing',\n",
    "  '--direct_num_workers=0'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c1ddd2-250f-4ebb-be31-dac45c7845ea",
   "metadata": {},
   "source": [
    "baseline_components = pipeline_factory.build_components(MODEL_TYPE.BASELINE)\n",
    "    \n",
    "# create baseline model\n",
    "my_pipeline = tfx.dsl.Pipeline(\n",
    "  pipeline_name=PIPELINE_NAME,\n",
    "  pipeline_root=PIPELINE_ROOT,\n",
    "  components=baseline_components,\n",
    "  enable_cache=ENABLE_CACHE,\n",
    "  metadata_connection_config=metadata_connection_config,\n",
    "  beam_pipeline_args=beam_pipeline_args,\n",
    ")\n",
    "\n",
    "tfx.orchestration.LocalDagRunner().run(my_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e2c108-fea6-4d88-a788-d4c21ebfd0a1",
   "metadata": {},
   "source": [
    "artifact_types = store.get_artifact_types()\n",
    "logging.debug(f\"MLMD store artifact_types={artifact_types}\")\n",
    "artifacts = store.get_artifacts()\n",
    "logging.debug(f\"MLMD store artifacts={artifacts}\")\n",
    "\n",
    "components = pipeline_factory.build_components(MODEL_TYPE.PRODUCTION)\n",
    "# simulate experimentation of one model family\n",
    "my_pipeline = tfx.dsl.Pipeline(\n",
    "  pipeline_name=PIPELINE_NAME,\n",
    "  pipeline_root=PIPELINE_ROOT,\n",
    "  components=components,\n",
    "  enable_cache=ENABLE_CACHE,\n",
    "  metadata_connection_config=metadata_connection_config,\n",
    "  beam_pipeline_args=beam_pipeline_args,\n",
    ")\n",
    "\n",
    "tfx.orchestration.LocalDagRunner().run(my_pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4cee9-c91e-49e3-a0ec-a6389f1a01c5",
   "metadata": {},
   "source": [
    "artifact_types = store.get_artifact_types()\n",
    "print(f\"MLMD store artifact_types={artifact_types}\")\n",
    "artifacts = store.get_artifacts()\n",
    "print(f\"MLMD store artifacts={artifacts}\")\n",
    "\n",
    "executions = store.get_executions()\n",
    "logging.debug(f\"MLMD store executions={executions}\")\n",
    "\n",
    "# executions has custom_properties.key: \"infiles_dict_ser\"\n",
    "#    and custom_properties.key: \"output_config_ser\"\n",
    "artifact_count = len(artifacts)\n",
    "execution_count = len(executions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
