{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50571b6d-4578-48a7-8864-cfa7565dfcbc",
   "metadata": {},
   "source": [
    "This is a local, non-Kaggle notebook in which TFX 1.16.0 and python 3.10 and the compatible versions of other libraries are installed in a virtual environment that this notebook is running in.\n",
    "\n",
    "paths are relative to the github repository directory, \"recommender_systems\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed99ee786e13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "from tfx.orchestration import metadata\n",
    "\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "from ml_metadata.metadata_store import metadata_store\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src/test/python/movie_lens_tfx\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src/main/python/movie_lens_tfx\"))\n",
    "\n",
    "from helper import *\n",
    "from movie_lens_tfx.PipelineComponentsFactory import *\n",
    "from movie_lens_tfx.tune_train_movie_lens import *\n",
    "\n",
    "from absl import logging\n",
    "tf.get_logger().propagate = False\n",
    "logging.set_verbosity(logging.WARNING)\n",
    "logging.set_stderrthreshold(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c98cdd-f021-49f6-af4a-aa571bf03b04",
   "metadata": {},
   "source": [
    "## EDA on the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad33acc-b994-420b-a0ad-ae1f178987e3",
   "metadata": {},
   "source": [
    "### w/ Polars and Plotly express\n",
    "output is written to bin/local_notebook/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e6b19f-4bd3-46eb-b4a2-537f9f2507fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/main/python/eda/eda_raw.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a6b2d4-2479-4069-aee1-59ecd131e040",
   "metadata": {},
   "source": [
    "### Run data pre-processing on full dataset to get the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693174b-6f67-48b0-a227-85324cb3bf2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "infiles_dict_ser, output_config_ser, split_names = get_test_data(use_small=False)\n",
    "user_id_max = 6040\n",
    "movie_id_max = 3952\n",
    "n_genres = N_GENRES\n",
    "n_age_groups = N_AGE_GROUPS\n",
    "n_occupations = 21\n",
    "MIN_EVAL_SIZE = 50 #make this larger for production pipeline\n",
    "\n",
    "test_num = \"1\"\n",
    "    \n",
    "PIPELINE_NAME = 'TestPipelines'\n",
    "output_data_dir = os.path.join(get_bin_dir(), \"local_notebook\", test_num)\n",
    "PIPELINE_ROOT = os.path.join(output_data_dir, PIPELINE_NAME)\n",
    "\n",
    "# remove results from previous test runs:\n",
    "try:\n",
    "  print(f\"removing: {PIPELINE_ROOT}\")\n",
    "  shutil.rmtree(PIPELINE_ROOT)\n",
    "except OSError as e:\n",
    "  pass\n",
    "METADATA_PATH = os.path.join(PIPELINE_ROOT, 'tfx_metadata',\n",
    "                             'metadata.db')\n",
    "os.makedirs(os.path.join(PIPELINE_ROOT, 'tfx_metadata'),\n",
    "            exist_ok=True)\n",
    "\n",
    "ENABLE_CACHE = True\n",
    "\n",
    "# metadata_connection_config = metadata_store_pb2.ConnectionConfig()\n",
    "# metadata_connection_config.sqlite.SetInParent()\n",
    "# metadata_connection = metadata.Metadata(metadata_connection_config)\n",
    "metadata_connection_config = metadata.sqlite_metadata_connection_config(\n",
    "  METADATA_PATH)\n",
    "\n",
    "store = metadata_store.MetadataStore(metadata_connection_config)\n",
    "\n",
    "if get_kaggle():\n",
    "  tr_dir = \"/kaggle/working/\"\n",
    "else:\n",
    "  tr_dir = os.path.join(get_project_dir(), \"src/main/python/movie_lens_tfx\")\n",
    "\n",
    "serving_model_dir = os.path.join(PIPELINE_ROOT, 'serving_model')\n",
    "output_parquet_path = os.path.join(PIPELINE_ROOT, \"transformed_parquet\")\n",
    "\n",
    "# for the custom ingestion component, the apache beam pipeline needs to be able to\n",
    "# find the sibling scripts it imports.\n",
    "# 2 solutions: (1) create a tar archive and use --extra_package in pipeline args\n",
    "# or (2) use setup.py and --setup_file in pipeline args.\n",
    "\n",
    "beam_pipeline_args = [\n",
    "  '--direct_running_mode=multi_processing',\n",
    "  '--direct_num_workers=0',\n",
    "  '--setup_file=setup.py',\n",
    "  #f'--extra_package={ingest_tar_file}'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba56d14-a868-4878-a64f-74ade8c57b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "\n",
    "tf.get_logger().propagate = False\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.WARNING)\n",
    "logging.set_stderrthreshold(logging.WARNING)\n",
    "\n",
    "context = InteractiveContext(pipeline_name=PIPELINE_NAME, pipeline_root=PIPELINE_ROOT,\n",
    "  metadata_connection_config=metadata_connection_config,\n",
    "  beam_pipeline_args=beam_pipeline_args\n",
    ")\n",
    "\n",
    "factory = PipelineComponentsFactory(infiles_dict_ser, output_config_ser, tr_dir,\n",
    "    user_id_max, movie_id_max, n_genres, n_age_groups,\n",
    "    MIN_EVAL_SIZE, serving_model_dir, output_parquet_path)\n",
    "\n",
    "components = factory.build_components(PIPELINE_TYPE.PREPROCESSING)\n",
    "\n",
    "for component in components:\n",
    "    context.run(component)\n",
    "\n",
    "print(f'done pre-processing data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dfcaa8-d03f-4c52-a47e-c32da31b6071",
   "metadata": {},
   "source": [
    "## EDA on the transformed data\n",
    "output is written to bin/local_notebook/images/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc80d679-b7ab-40f4-90a3-77c24f06fd2e",
   "metadata": {},
   "source": [
    "### using Polars, Plotly.express \n",
    "\n",
    "this can take an hour on a single COTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f10a4-6b75-464e-8f7e-fec52c9928a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/main/python/eda/eda_transformed.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f330e36e-74b9-4695-973c-25431bc3ea12",
   "metadata": {},
   "source": [
    "### using Pandas, Pyspark MLLIB FPGrowth\n",
    "\n",
    "This does a market basket analysis with movie_ids.\n",
    "\n",
    "If you want the PrefixSpan plots also, set\n",
    "PLOT_PREFIXSPAN = True\n",
    "but beware that the script will take much longer to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba2cda2-d3c6-4289-90a8-3ebc634373aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_PREFIXSPAN=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4b977-4809-4c03-a2d1-6629b062ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/main/python/eda/eda_transformed_pyspark_mllib.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951c493f-6964-452d-997d-e51cb246c912",
   "metadata": {},
   "source": [
    "### Data and Concept Drift\n",
    "After exploring the data inputs to the model, we want to define monitoring\n",
    "for data and concept shifts.\n",
    "\n",
    "let X = features\n",
    "\n",
    "let Y = targets\n",
    "\n",
    "Data shift is a change in the joint distribution, P(X, Y). \n",
    "\n",
    "Using the probability product rule, we can explore 4 causes for the\n",
    "simplest changes in P(X,Y)\n",
    "$$ P(X, Y) = P(Y, X) = P(X|Y)P(Y) = P(Y|X)P(X) $$\n",
    "\n",
    "We can look for changes in one member in the following pairs at any time\n",
    "(one is simpler than exploring more than 1 member changing at same time):\n",
    "$$ P(X|Y) * P(Y) $$\n",
    "$$ P(Y|X) * P(X) $$\n",
    "\n",
    "* Covariate shift:\n",
    "  $$ P(X) changed.  P(Y|X) unchanged $$\n",
    "  Distr of model inputs changes.\n",
    "* Label shift:\n",
    "  $$ P(Y) changed,  P(X|Y) unchanged $$\n",
    "  Distr of model outputs changes, but for any given output, the input distribution stays the same.\n",
    "  \n",
    "* Concept shift\n",
    "  $$ P(X) unchanged.  P(Y|X) changed $$\n",
    "* Manifestation shift:\n",
    "  $$ P(Y) unchanged,  P(X|Y) changed $$\n",
    "\n",
    "[see more at NannyML](https://www.nannyml.com/blog/concept-drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0770fd1-41d6-4f7a-848e-9e73589c10ca",
   "metadata": {},
   "source": [
    "### using TFDV to look at the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa6e114-d61a-40d3-ac2a-b3c4dde3fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.dsl.io import fileio\n",
    "from tfx.orchestration import metadata\n",
    "from tfx.components import StatisticsGen, SchemaGen, ExampleValidator\n",
    "from tfx.utils import io_utils\n",
    "from tensorflow_metadata.proto.v0 import anomalies_pb2, schema_pb2\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "\n",
    "_list = store.get_artifacts_by_type(\"ExampleStatistics\")\n",
    "print(f'artifacts={_list}')\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"ExampleStatistics\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name, \"FeatureStats.pb\") \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    stats_proto = tfdv.load_stats_binary(file_path)\n",
    "    tfdv.visualize_statistics(stats_proto)\n",
    "\n",
    "#ExampleAnomalies\n",
    "_list = store.get_artifacts_by_type(\"ExampleAnomalies\")\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"ExampleAnomalies\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name, \"SchemaDiff.pb\") \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    stats_proto = tfdv.load_stats_binary(file_path)\n",
    "    tfdv.visualize_artifacts(stats_proto)\n",
    "\n",
    "_list = store.get_artifacts_by_type(\"ExampleStatistics\")\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"pre_transform_stats\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name, \"FeatureStats.pb\") \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    stats_proto = tfdv.load_stats_binary(file_path)\n",
    "    tfdv.visualize_statistics(stats_proto)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d681e-6788-456e-8a77-91c4ea809963",
   "metadata": {},
   "source": [
    "### using TFDV to look at the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30943e-9caa-4009-a73c-c4fa7298639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_list = store.get_artifacts_by_type(\"ExampleStatistics\")\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"post_transform_stats\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name, \"FeatureStats.pb\") \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    stats_proto = tfdv.load_stats_binary(file_path)\n",
    "    tfdv.visualize_statistics(stats_proto)\n",
    "    \n",
    "#ExampleAnomalies\n",
    "_list = store.get_artifacts_by_type(\"ExampleAnomalies\")\n",
    "_list = sorted(_list, key=lambda x: x.create_time_since_epoch, reverse=True)\n",
    "for artifact in _list:\n",
    "    if \"post_transform_anomalies\" in artifact.uri:\n",
    "        artifact_uri = artifact.uri\n",
    "        break\n",
    "assert(artifact_uri is not None)\n",
    "file_paths = [os.path.join(artifact_uri, name, \"SchemaDiff.pb\") \n",
    "  for name in os.listdir(artifact_uri)]\n",
    "for file_path in file_paths:\n",
    "    stats_proto = tfdv.load_stats_binary(file_path)\n",
    "    tfdv.visualize_artifacts(stats_proto)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307091b-211e-4f81-95ae-eed7ef9389b2",
   "metadata": {},
   "source": [
    "## Run baseline model pipeline with full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ef186-8c42-4e25-a8ca-cc0295879a68",
   "metadata": {},
   "source": [
    "pipeline_factory = PipelineComponentsFactory(\n",
    "  infiles_dict_ser=infiles_dict_ser, output_config_ser=output_config_ser,\n",
    "  transform_dir=tr_dir, user_id_max=user_id_max, movie_id_max=movie_id_max,\n",
    "  n_genres=n_genres, n_age_groups=n_age_groups, min_eval_size=MIN_EVAL_SIZE,\n",
    "  serving_model_dir=serving_model_dir,\n",
    ")\n",
    "\n",
    "beam_pipeline_args = [\n",
    "  '--direct_running_mode=multi_processing',\n",
    "  '--direct_num_workers=0'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c1ddd2-250f-4ebb-be31-dac45c7845ea",
   "metadata": {},
   "source": [
    "baseline_components = pipeline_factory.build_components(MODEL_TYPE.BASELINE)\n",
    "    \n",
    "# create baseline model\n",
    "my_pipeline = tfx.dsl.Pipeline(\n",
    "  pipeline_name=PIPELINE_NAME,\n",
    "  pipeline_root=PIPELINE_ROOT,\n",
    "  components=baseline_components,\n",
    "  enable_cache=ENABLE_CACHE,\n",
    "  metadata_connection_config=metadata_connection_config,\n",
    "  beam_pipeline_args=beam_pipeline_args,\n",
    ")\n",
    "\n",
    "tfx.orchestration.LocalDagRunner().run(my_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e2c108-fea6-4d88-a788-d4c21ebfd0a1",
   "metadata": {},
   "source": [
    "artifact_types = store.get_artifact_types()\n",
    "logging.debug(f\"MLMD store artifact_types={artifact_types}\")\n",
    "artifacts = store.get_artifacts()\n",
    "logging.debug(f\"MLMD store artifacts={artifacts}\")\n",
    "\n",
    "components = pipeline_factory.build_components(MODEL_TYPE.PRODUCTION)\n",
    "# simulate experimentation of one model family\n",
    "my_pipeline = tfx.dsl.Pipeline(\n",
    "  pipeline_name=PIPELINE_NAME,\n",
    "  pipeline_root=PIPELINE_ROOT,\n",
    "  components=components,\n",
    "  enable_cache=ENABLE_CACHE,\n",
    "  metadata_connection_config=metadata_connection_config,\n",
    "  beam_pipeline_args=beam_pipeline_args,\n",
    ")\n",
    "\n",
    "tfx.orchestration.LocalDagRunner().run(my_pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4cee9-c91e-49e3-a0ec-a6389f1a01c5",
   "metadata": {},
   "source": [
    "artifact_types = store.get_artifact_types()\n",
    "print(f\"MLMD store artifact_types={artifact_types}\")\n",
    "artifacts = store.get_artifacts()\n",
    "print(f\"MLMD store artifacts={artifacts}\")\n",
    "\n",
    "executions = store.get_executions()\n",
    "logging.debug(f\"MLMD store executions={executions}\")\n",
    "\n",
    "# executions has custom_properties.key: \"infiles_dict_ser\"\n",
    "#    and custom_properties.key: \"output_config_ser\"\n",
    "artifact_count = len(artifacts)\n",
    "execution_count = len(executions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
