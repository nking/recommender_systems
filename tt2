INFO:absl:Excluding no splits because exclude_splits is not set.
INFO:absl:Excluding no splits because exclude_splits is not set.
INFO:absl:Generating ephemeral wheel package for '/kaggle/working/transform_movie_lens.py' (including modules: ['ingest_movie_lens_beam_pa', 'ingest_movie_lens_custom_component', 'csv_example_gen_test', 'ingest_movie_lens_component_test', 'CustomUTF8Coder', 'helper', 'ingest_movie_lens_component', 'dataset_tfxio_example', 'movie_lens_utils_test', 'transform_movie_lens_test', 'transform_movie_lens', 'movie_lens_utils', 'ingest_movie_lens_custom_component_test', 'ingest_movie_lens_beam_test', 'ingest_movie_lens_beam_pa_test', 'ingest_movie_lens_beam']).
INFO:absl:User module package has hash fingerprint version 885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9.
INFO:absl:Executing: ['/usr/local/envs/my_tfx_env/bin/python', '/tmp/tmp3pq5tkqu/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmp3of2qslr', '--dist-dir', '/tmp/tmpwhlopv2l']
/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:90: SetuptoolsDeprecationWarning: setup.py install is deprecated.
!!

        ********************************************************************************
        Please avoid running ``setup.py`` directly.
        Instead, use pypa/build, pypa/installer or other
        standards-based tools.

        By 2025-Oct-31, you need to update your project and remove deprecated calls
        or your builds will no longer be supported.

        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.
        ********************************************************************************

!!
  self.initialize_options()
INFO:absl:Successfully built user code wheel distribution at '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl'; target user module is 'transform_movie_lens'.
INFO:absl:Full user module path is 'transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl'
INFO:absl:Using deployment config:
 executor_specs {
  key: "MovieLensExampleGen"
  value {
    beam_executable_spec {
      python_executor_spec {
        class_path: "ingest_movie_lens_component.MovieLensExampleGen_Executor"
      }
      beam_pipeline_args: "--direct_running_mode=multi_processing"
      beam_pipeline_args: "--direct_num_workers=0"
      beam_pipeline_args_placeholders {
        value {
          string_value: "--direct_running_mode=multi_processing"
        }
      }
      beam_pipeline_args_placeholders {
        value {
          string_value: "--direct_num_workers=0"
        }
      }
    }
  }
}
executor_specs {
  key: "SchemaGen"
  value {
    python_class_executable_spec {
      class_path: "tfx.components.schema_gen.executor.Executor"
    }
  }
}
executor_specs {
  key: "StatisticsGen"
  value {
    beam_executable_spec {
      python_executor_spec {
        class_path: "tfx.components.statistics_gen.executor.Executor"
      }
      beam_pipeline_args: "--direct_running_mode=multi_processing"
      beam_pipeline_args: "--direct_num_workers=0"
      beam_pipeline_args_placeholders {
        value {
          string_value: "--direct_running_mode=multi_processing"
        }
      }
      beam_pipeline_args_placeholders {
        value {
          string_value: "--direct_num_workers=0"
        }
      }
    }
  }
}
executor_specs {
  key: "Transform"
  value {
    beam_executable_spec {
      python_executor_spec {
        class_path: "tfx.components.transform.executor.Executor"
      }
      beam_pipeline_args: "--direct_running_mode=multi_processing"
      beam_pipeline_args: "--direct_num_workers=0"
      beam_pipeline_args_placeholders {
        value {
          string_value: "--direct_running_mode=multi_processing"
        }
      }
      beam_pipeline_args_placeholders {
        value {
          string_value: "--direct_num_workers=0"
        }
      }
    }
  }
}
metadata_connection_config {
  database_connection_config {
    sqlite {
      filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
      connection_mode: READWRITE_OPENCREATE
    }
  }
}

INFO:absl:Using connection config:
 sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

INFO:absl:Component MovieLensExampleGen is running.
INFO:absl:Running launcher for node_info {
  type {
    name: "ingest_movie_lens_component.MovieLensExampleGen"
  }
  id: "MovieLensExampleGen"
}
contexts {
  contexts {
    type {
      name: "pipeline"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline"
      }
    }
  }
  contexts {
    type {
      name: "pipeline_run"
    }
    name {
      field_value {
        string_value: "2025-10-15T18:21:14.982988"
      }
    }
  }
  contexts {
    type {
      name: "node"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline.MovieLensExampleGen"
      }
    }
  }
}
outputs {
  outputs {
    key: "output_examples"
    value {
      artifact_spec {
        type {
          name: "Examples"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          properties {
            key: "version"
            value: INT
          }
          base_type: DATASET
        }
      }
    }
  }
}
parameters {
  parameters {
    key: "infiles_dict_ser"
    value {
      field_value {
        string_value: "gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg=="
      }
    }
  }
  parameters {
    key: "output_config_ser"
    value {
      field_value {
        string_value: "Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK"
      }
    }
  }
}
downstream_nodes: "StatisticsGen"
downstream_nodes: "Transform"
execution_options {
  caching_options {
  }
}

INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

DEBUG:absl:Failed to get context of type pipeline and name TestPythonTransformPipeline
DEBUG:absl:ID of context type {
  name: "pipeline"
}
name {
  field_value {
    string_value: "TestPythonTransformPipeline"
  }
}
 is 1.
DEBUG:absl:Failed to get context of type pipeline_run and name 2025-10-15T18:21:14.982988
DEBUG:absl:ID of context type {
  name: "pipeline_run"
}
name {
  field_value {
    string_value: "2025-10-15T18:21:14.982988"
  }
}
 is 2.
DEBUG:absl:Failed to get context of type node and name TestPythonTransformPipeline.MovieLensExampleGen
DEBUG:absl:ID of context type {
  name: "node"
}
name {
  field_value {
    string_value: "TestPythonTransformPipeline.MovieLensExampleGen"
  }
}
 is 3.
DEBUG:absl:Before conditional:
{}
DEBUG:absl:After conditional:
{}
INFO:absl:[MovieLensExampleGen] Resolved inputs: ({},)
DEBUG:absl:Prepared EXECUTION:
 type_id: 13
last_known_state: RUNNING
custom_properties {
  key: "infiles_dict_ser"
  value {
    string_value: "gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg=="
  }
}
custom_properties {
  key: "output_config_ser"
  value {
    string_value: "Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK"
  }
}
name: "601bb4aa-5f79-408d-9fcb-22a76892030d"

DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1
INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

DEBUG:absl:Failed to get context of type execution_cache and name 9c8ee902c018e9e330485b35a8dcba812ad906560ec1fa358c345cfb41f487bf
DEBUG:absl:ID of context type {
  name: "execution_cache"
}
name {
  field_value {
    string_value: "9c8ee902c018e9e330485b35a8dcba812ad906560ec1fa358c345cfb41f487bf"
  }
}
 is 4.
INFO:absl:Going to run a new execution 1
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1760552475.150689    5633 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}
INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=1, input_dict={}, output_dict=defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1"
, artifact_type: name: "Examples"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
properties {
  key: "version"
  value: INT
}
base_type: DATASET
)]}), exec_properties={'output_config_ser': 'Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK', 'infiles_dict_ser': 'gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg=='}, execution_output_uri='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/.system/executor_execution/1/executor_output.pb', stateful_working_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/.system/stateful_working_dir/0a3ce594-d1f9-4fad-8fb9-3d7180261231', tmp_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/.system/executor_execution/1/.temp/', pipeline_node=node_info {
  type {
    name: "ingest_movie_lens_component.MovieLensExampleGen"
  }
  id: "MovieLensExampleGen"
}
contexts {
  contexts {
    type {
      name: "pipeline"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline"
      }
    }
  }
  contexts {
    type {
      name: "pipeline_run"
    }
    name {
      field_value {
        string_value: "2025-10-15T18:21:14.982988"
      }
    }
  }
  contexts {
    type {
      name: "node"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline.MovieLensExampleGen"
      }
    }
  }
}
outputs {
  outputs {
    key: "output_examples"
    value {
      artifact_spec {
        type {
          name: "Examples"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          properties {
            key: "version"
            value: INT
          }
          base_type: DATASET
        }
      }
    }
  }
}
parameters {
  parameters {
    key: "infiles_dict_ser"
    value {
      field_value {
        string_value: "gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg=="
      }
    }
  }
  parameters {
    key: "output_config_ser"
    value {
      field_value {
        string_value: "Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK"
      }
    }
  }
}
downstream_nodes: "StatisticsGen"
downstream_nodes: "Transform"
execution_options {
  caching_options {
  }
}
, pipeline_info=id: "TestPythonTransformPipeline"
, pipeline_run_id='2025-10-15T18:21:14.982988', top_level_pipeline_run_id=None, frontend_url=None)
INFO:absl:Attempting to infer TFX Python dependency for beam
INFO:absl:Copying all content from install dir /usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx to temp dir /tmp/tmprg24n3tm/build/tfx
INFO:absl:Generating a temp setup file at /tmp/tmprg24n3tm/build/tfx/setup.py
INFO:absl:Creating temporary sdist package, logs available at /tmp/tmprg24n3tm/build/tfx/setup.log
INFO:absl:Added --extra_package=/tmp/tmprg24n3tm/build/tfx/dist/tfx_ephemeral-1.16.0.tar.gz to beam args
INFO:absl:MovieLensExampleGen
DEBUG:absl:output_examples was passed in to component
DEBUG:absl:output_examples TYPE=<class 'tfx.types.standard_artifacts.Examples'>
DEBUG:absl:output_examples=Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1"
properties {
  key: "span"
  value {
    int_value: 0
  }
}
properties {
  key: "split_names"
  value {
    string_value: "[\"train\", \"eval\", \"test\"]"
  }
}
properties {
  key: "version"
  value {
    int_value: 1
  }
}
, artifact_type: name: "Examples"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
properties {
  key: "version"
  value: INT
}
base_type: DATASET
)
DEBUG:absl:split_names=['train', 'eval', 'test']
DEBUG:absl:columns=[('user_id', <class 'int'>), ('movie_id', <class 'int'>), ('rating', <class 'int'>), ('timestamp', <class 'int'>), ('gender', <class 'str'>), ('age', <class 'int'>), ('occupation', <class 'int'>), ('genres', <class 'str'>)]
DEBUG:absl:cumulative_buckets=[80, 90, 100]
DEBUG:absl:have ratings_tuple.  type=<class 'apache_beam.pvalue.DoOutputsTuple'>
DEBUG:absl:prefix_path=/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord
DEBUG:absl:prefix_path=/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord
DEBUG:absl:prefix_path=/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord
INFO:absl:output_examples written as TFRecords
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552481   nanos: 98775148 } message: "No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail." log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552481   nanos: 106040477 } message: "Discarding unparseable args: [\'--direct_runner_use_stacked_bundle\', \'--pipeline_type_check\']" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552481   nanos: 110731840 } message: "No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail." log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552481   nanos: 117663145 } message: "Discarding unparseable args: [\'--direct_runner_use_stacked_bundle\', \'--pipeline_type_check\']" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552481   nanos: 126104354 } message: "No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail." log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552481   nanos: 135364770 } message: "Discarding unparseable args: [\'--direct_runner_use_stacked_bundle\', \'--pipeline_type_check\']" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552481   nanos: 145302057 } message: "No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail." log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552481   nanos: 153333902 } message: "Discarding unparseable args: [\'--direct_runner_use_stacked_bundle\', \'--pipeline_type_check\']" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552492   nanos: 726884365 } message: "Couldn\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be." instruction_id: "bundle_52" transform_id: "write_to_tfrecord_421920178746/Write/WriteImpl/WriteBundles" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59" thread: "Thread-14" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552492   nanos: 774333238 } message: "Couldn\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be." instruction_id: "bundle_49" transform_id: "write_to_tfrecord_421920178746/Write/WriteImpl/WriteBundles" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59" thread: "Thread-14" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552493   nanos: 362018346 } message: "Couldn\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be." instruction_id: "bundle_51" transform_id: "write_to_tfrecord_421920178746/Write/WriteImpl/WriteBundles" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59" thread: "Thread-12" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552493   nanos: 480974435 } message: "Couldn\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be." instruction_id: "bundle_50" transform_id: "write_to_tfrecord_341158322707/Write/WriteImpl/WriteBundles" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59" thread: "Thread-13" 
INFO:absl:Cleaning up stateless execution info.
INFO:absl:Execution 1 succeeded.
INFO:absl:Cleaning up stateful execution info.
INFO:absl:Deleted stateful_working_dir /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/.system/stateful_working_dir/0a3ce594-d1f9-4fad-8fb9-3d7180261231
INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1"
, artifact_type: name: "Examples"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
properties {
  key: "version"
  value: INT
}
base_type: DATASET
)]}) for execution 1
INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

INFO:absl:Component MovieLensExampleGen is finished.
INFO:absl:Component StatisticsGen is running.
INFO:absl:Running launcher for node_info {
  type {
    name: "tfx.components.statistics_gen.component.StatisticsGen"
    base_type: PROCESS
  }
  id: "StatisticsGen"
}
contexts {
  contexts {
    type {
      name: "pipeline"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline"
      }
    }
  }
  contexts {
    type {
      name: "pipeline_run"
    }
    name {
      field_value {
        string_value: "2025-10-15T18:21:14.982988"
      }
    }
  }
  contexts {
    type {
      name: "node"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline.StatisticsGen"
      }
    }
  }
}
inputs {
  inputs {
    key: "examples"
    value {
      channels {
        producer_node_query {
          id: "MovieLensExampleGen"
        }
        context_queries {
          type {
            name: "pipeline"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline"
            }
          }
        }
        context_queries {
          type {
            name: "pipeline_run"
          }
          name {
            field_value {
              string_value: "2025-10-15T18:21:14.982988"
            }
          }
        }
        context_queries {
          type {
            name: "node"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline.MovieLensExampleGen"
            }
          }
        }
        artifact_query {
          type {
            name: "Examples"
            base_type: DATASET
          }
        }
        output_key: "output_examples"
      }
      min_count: 1
    }
  }
}
outputs {
  outputs {
    key: "statistics"
    value {
      artifact_spec {
        type {
          name: "ExampleStatistics"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          base_type: STATISTICS
        }
      }
    }
  }
}
parameters {
  parameters {
    key: "exclude_splits"
    value {
      field_value {
        string_value: "[]"
      }
    }
  }
}
upstream_nodes: "MovieLensExampleGen"
downstream_nodes: "SchemaGen"
execution_options {
  caching_options {
  }
}

INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

DEBUG:absl:Failed to get context of type node and name TestPythonTransformPipeline.StatisticsGen
DEBUG:absl:ID of context type {
  name: "node"
}
name {
  field_value {
    string_value: "TestPythonTransformPipeline.StatisticsGen"
  }
}
 is 5.
WARNING:absl:ArtifactQuery.property_predicate is not supported.
DEBUG:absl:examples <- [
  [NO_PARTITION]: [Examples(id=1, span=0, version=1)]
]
DEBUG:absl:Before conditional:
{examples: [Examples(id=1, span=0, version=1)]}
DEBUG:absl:After conditional:
{examples: [Examples(id=1, span=0, version=1)]}
INFO:absl:[StatisticsGen] Resolved inputs: ({'examples': [Artifact(artifact: id: 1
type_id: 15
uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1"
properties {
  key: "span"
  value {
    int_value: 0
  }
}
properties {
  key: "split_names"
  value {
    string_value: "[\"train\", \"eval\", \"test\"]"
  }
}
properties {
  key: "version"
  value {
    int_value: 1
  }
}
custom_properties {
  key: "is_external"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "tfx_version"
  value {
    string_value: "1.16.0"
  }
}
state: LIVE
type: "Examples"
create_time_since_epoch: 1760552504176
last_update_time_since_epoch: 1760552504176
, artifact_type: id: 15
name: "Examples"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
properties {
  key: "version"
  value: INT
}
base_type: DATASET
)]},)
DEBUG:absl:Prepared EXECUTION:
 type_id: 16
last_known_state: RUNNING
custom_properties {
  key: "exclude_splits"
  value {
    string_value: "[]"
  }
}
name: "216aea72-b9c6-47db-ad33-7fceb48e6810"

DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2
INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

DEBUG:absl:Failed to get context of type execution_cache and name b40c760541c9576a5b771f5d56fe2b5dcc84969326b9070fa7c4cd2af1d15b01
DEBUG:absl:ID of context type {
  name: "execution_cache"
}
name {
  field_value {
    string_value: "b40c760541c9576a5b771f5d56fe2b5dcc84969326b9070fa7c4cd2af1d15b01"
  }
}
 is 6.
INFO:absl:Going to run a new execution 2
I0000 00:00:1760552504.280774    5633 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}
INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=2, input_dict={'examples': [Artifact(artifact: id: 1
type_id: 15
uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1"
properties {
  key: "span"
  value {
    int_value: 0
  }
}
properties {
  key: "split_names"
  value {
    string_value: "[\"train\", \"eval\", \"test\"]"
  }
}
properties {
  key: "version"
  value {
    int_value: 1
  }
}
custom_properties {
  key: "is_external"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "tfx_version"
  value {
    string_value: "1.16.0"
  }
}
state: LIVE
type: "Examples"
create_time_since_epoch: 1760552504176
last_update_time_since_epoch: 1760552504176
, artifact_type: id: 15
name: "Examples"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
properties {
  key: "version"
  value: INT
}
base_type: DATASET
)]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2"
, artifact_type: name: "ExampleStatistics"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
base_type: STATISTICS
)]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/.system/executor_execution/2/executor_output.pb', stateful_working_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/.system/stateful_working_dir/f5404033-0aca-480e-8d96-3cd69aeb4e0b', tmp_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/.system/executor_execution/2/.temp/', pipeline_node=node_info {
  type {
    name: "tfx.components.statistics_gen.component.StatisticsGen"
    base_type: PROCESS
  }
  id: "StatisticsGen"
}
contexts {
  contexts {
    type {
      name: "pipeline"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline"
      }
    }
  }
  contexts {
    type {
      name: "pipeline_run"
    }
    name {
      field_value {
        string_value: "2025-10-15T18:21:14.982988"
      }
    }
  }
  contexts {
    type {
      name: "node"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline.StatisticsGen"
      }
    }
  }
}
inputs {
  inputs {
    key: "examples"
    value {
      channels {
        producer_node_query {
          id: "MovieLensExampleGen"
        }
        context_queries {
          type {
            name: "pipeline"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline"
            }
          }
        }
        context_queries {
          type {
            name: "pipeline_run"
          }
          name {
            field_value {
              string_value: "2025-10-15T18:21:14.982988"
            }
          }
        }
        context_queries {
          type {
            name: "node"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline.MovieLensExampleGen"
            }
          }
        }
        artifact_query {
          type {
            name: "Examples"
            base_type: DATASET
          }
        }
        output_key: "output_examples"
      }
      min_count: 1
    }
  }
}
outputs {
  outputs {
    key: "statistics"
    value {
      artifact_spec {
        type {
          name: "ExampleStatistics"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          base_type: STATISTICS
        }
      }
    }
  }
}
parameters {
  parameters {
    key: "exclude_splits"
    value {
      field_value {
        string_value: "[]"
      }
    }
  }
}
upstream_nodes: "MovieLensExampleGen"
downstream_nodes: "SchemaGen"
execution_options {
  caching_options {
  }
}
, pipeline_info=id: "TestPythonTransformPipeline"
, pipeline_run_id='2025-10-15T18:21:14.982988', top_level_pipeline_run_id=None, frontend_url=None)
INFO:absl:Attempting to infer TFX Python dependency for beam
INFO:absl:Copying all content from install dir /usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx to temp dir /tmp/tmpohezxgae/build/tfx
INFO:absl:Generating a temp setup file at /tmp/tmpohezxgae/build/tfx/setup.py
INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpohezxgae/build/tfx/setup.log
INFO:absl:Added --extra_package=/tmp/tmpohezxgae/build/tfx/dist/tfx_ephemeral-1.16.0.tar.gz to beam args
DEBUG:absl:Starting Executor execution.
WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE
WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE
WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE
INFO:absl:Generating statistics for split train.
INFO:absl:Statistics for split train written to /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-train.
INFO:absl:Generating statistics for split eval.
INFO:absl:Statistics for split eval written to /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-eval.
INFO:absl:Generating statistics for split test.
INFO:absl:Statistics for split test written to /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-test.
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552513   nanos: 140390396 } message: "No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail." log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552513   nanos: 139848470 } message: "No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail." log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552513   nanos: 145567893 } message: "Discarding unparseable args: [\'--pipeline_type_check\', \'--direct_runner_use_stacked_bundle\']" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552513   nanos: 148628234 } message: "Discarding unparseable args: [\'--pipeline_type_check\', \'--direct_runner_use_stacked_bundle\']" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552513   nanos: 235493421 } message: "No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail." log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552513   nanos: 242850303 } message: "Discarding unparseable args: [\'--pipeline_type_check\', \'--direct_runner_use_stacked_bundle\']" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552513   nanos: 256427526 } message: "No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail." log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552513   nanos: 262474298 } message: "Discarding unparseable args: [\'--pipeline_type_check\', \'--direct_runner_use_stacked_bundle\']" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552518   nanos: 211581230 } message: "Couldn\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be." instruction_id: "bundle_137" transform_id: "TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59" thread: "Thread-13" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552518   nanos: 215517282 } message: "Couldn\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be." instruction_id: "bundle_139" transform_id: "TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59" thread: "Thread-13" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552518   nanos: 218683242 } message: "Couldn\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be." instruction_id: "bundle_140" transform_id: "TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59" thread: "Thread-12" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760552518   nanos: 222246170 } message: "Couldn\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be." instruction_id: "bundle_138" transform_id: "TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59" thread: "Thread-13" 
INFO:absl:Cleaning up stateless execution info.
INFO:absl:Execution 2 succeeded.
INFO:absl:Cleaning up stateful execution info.
INFO:absl:Deleted stateful_working_dir /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/.system/stateful_working_dir/f5404033-0aca-480e-8d96-3cd69aeb4e0b
INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2"
, artifact_type: name: "ExampleStatistics"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
base_type: STATISTICS
)]}) for execution 2
INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

INFO:absl:Component StatisticsGen is finished.
INFO:absl:Component SchemaGen is running.
INFO:absl:Running launcher for node_info {
  type {
    name: "tfx.components.schema_gen.component.SchemaGen"
    base_type: PROCESS
  }
  id: "SchemaGen"
}
contexts {
  contexts {
    type {
      name: "pipeline"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline"
      }
    }
  }
  contexts {
    type {
      name: "pipeline_run"
    }
    name {
      field_value {
        string_value: "2025-10-15T18:21:14.982988"
      }
    }
  }
  contexts {
    type {
      name: "node"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline.SchemaGen"
      }
    }
  }
}
inputs {
  inputs {
    key: "statistics"
    value {
      channels {
        producer_node_query {
          id: "StatisticsGen"
        }
        context_queries {
          type {
            name: "pipeline"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline"
            }
          }
        }
        context_queries {
          type {
            name: "pipeline_run"
          }
          name {
            field_value {
              string_value: "2025-10-15T18:21:14.982988"
            }
          }
        }
        context_queries {
          type {
            name: "node"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline.StatisticsGen"
            }
          }
        }
        artifact_query {
          type {
            name: "ExampleStatistics"
            base_type: STATISTICS
          }
        }
        output_key: "statistics"
      }
      min_count: 1
    }
  }
}
outputs {
  outputs {
    key: "schema"
    value {
      artifact_spec {
        type {
          name: "Schema"
        }
      }
    }
  }
}
parameters {
  parameters {
    key: "exclude_splits"
    value {
      field_value {
        string_value: "[]"
      }
    }
  }
  parameters {
    key: "infer_feature_shape"
    value {
      field_value {
        int_value: 1
      }
    }
  }
}
upstream_nodes: "StatisticsGen"
downstream_nodes: "Transform"
execution_options {
  caching_options {
  }
}

INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

DEBUG:absl:Failed to get context of type node and name TestPythonTransformPipeline.SchemaGen
DEBUG:absl:ID of context type {
  name: "node"
}
name {
  field_value {
    string_value: "TestPythonTransformPipeline.SchemaGen"
  }
}
 is 7.
WARNING:absl:ArtifactQuery.property_predicate is not supported.
DEBUG:absl:statistics <- [
  [NO_PARTITION]: [ExampleStatistics(id=2, span=0)]
]
DEBUG:absl:Before conditional:
{statistics: [ExampleStatistics(id=2, span=0)]}
DEBUG:absl:After conditional:
{statistics: [ExampleStatistics(id=2, span=0)]}
INFO:absl:[SchemaGen] Resolved inputs: ({'statistics': [Artifact(artifact: id: 2
type_id: 17
uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2"
properties {
  key: "span"
  value {
    int_value: 0
  }
}
properties {
  key: "split_names"
  value {
    string_value: "[\"train\", \"eval\", \"test\"]"
  }
}
custom_properties {
  key: "is_external"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "sample_rate_by_split"
  value {
    struct_value {
      fields {
        key: "__value__"
        value {
          string_value: "{\"eval\": 1.0, \"test\": 1.0, \"train\": 1.0}"
        }
      }
    }
  }
}
custom_properties {
  key: "stats_dashboard_link"
  value {
    string_value: ""
  }
}
custom_properties {
  key: "tfx_version"
  value {
    string_value: "1.16.0"
  }
}
state: LIVE
type: "ExampleStatistics"
create_time_since_epoch: 1760552525502
last_update_time_since_epoch: 1760552525502
, artifact_type: id: 17
name: "ExampleStatistics"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
base_type: STATISTICS
)]},)
DEBUG:absl:Prepared EXECUTION:
 type_id: 18
last_known_state: RUNNING
custom_properties {
  key: "exclude_splits"
  value {
    string_value: "[]"
  }
}
custom_properties {
  key: "infer_feature_shape"
  value {
    int_value: 1
  }
}
name: "74d6a97b-6d7d-4ecd-b70a-cc02fc639ad7"

DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3
INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

DEBUG:absl:Failed to get context of type execution_cache and name e12f34b11511bbab66f590e1b6e4da0530b66148f64e8317adc865c45e5d57fe
DEBUG:absl:ID of context type {
  name: "execution_cache"
}
name {
  field_value {
    string_value: "e12f34b11511bbab66f590e1b6e4da0530b66148f64e8317adc865c45e5d57fe"
  }
}
 is 8.
INFO:absl:Going to run a new execution 3
I0000 00:00:1760552525.569338    5633 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}
INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=3, input_dict={'statistics': [Artifact(artifact: id: 2
type_id: 17
uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2"
properties {
  key: "span"
  value {
    int_value: 0
  }
}
properties {
  key: "split_names"
  value {
    string_value: "[\"train\", \"eval\", \"test\"]"
  }
}
custom_properties {
  key: "is_external"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "sample_rate_by_split"
  value {
    struct_value {
      fields {
        key: "__value__"
        value {
          string_value: "{\"eval\": 1.0, \"test\": 1.0, \"train\": 1.0}"
        }
      }
    }
  }
}
custom_properties {
  key: "stats_dashboard_link"
  value {
    string_value: ""
  }
}
custom_properties {
  key: "tfx_version"
  value {
    string_value: "1.16.0"
  }
}
state: LIVE
type: "ExampleStatistics"
create_time_since_epoch: 1760552525502
last_update_time_since_epoch: 1760552525502
, artifact_type: id: 17
name: "ExampleStatistics"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
base_type: STATISTICS
)]}, output_dict=defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3"
, artifact_type: name: "Schema"
)]}), exec_properties={'infer_feature_shape': 1, 'exclude_splits': '[]'}, execution_output_uri='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/.system/executor_execution/3/executor_output.pb', stateful_working_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/.system/stateful_working_dir/66ad8fb4-3891-49fd-a4a4-87c2e867424e', tmp_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/.system/executor_execution/3/.temp/', pipeline_node=node_info {
  type {
    name: "tfx.components.schema_gen.component.SchemaGen"
    base_type: PROCESS
  }
  id: "SchemaGen"
}
contexts {
  contexts {
    type {
      name: "pipeline"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline"
      }
    }
  }
  contexts {
    type {
      name: "pipeline_run"
    }
    name {
      field_value {
        string_value: "2025-10-15T18:21:14.982988"
      }
    }
  }
  contexts {
    type {
      name: "node"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline.SchemaGen"
      }
    }
  }
}
inputs {
  inputs {
    key: "statistics"
    value {
      channels {
        producer_node_query {
          id: "StatisticsGen"
        }
        context_queries {
          type {
            name: "pipeline"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline"
            }
          }
        }
        context_queries {
          type {
            name: "pipeline_run"
          }
          name {
            field_value {
              string_value: "2025-10-15T18:21:14.982988"
            }
          }
        }
        context_queries {
          type {
            name: "node"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline.StatisticsGen"
            }
          }
        }
        artifact_query {
          type {
            name: "ExampleStatistics"
            base_type: STATISTICS
          }
        }
        output_key: "statistics"
      }
      min_count: 1
    }
  }
}
outputs {
  outputs {
    key: "schema"
    value {
      artifact_spec {
        type {
          name: "Schema"
        }
      }
    }
  }
}
parameters {
  parameters {
    key: "exclude_splits"
    value {
      field_value {
        string_value: "[]"
      }
    }
  }
  parameters {
    key: "infer_feature_shape"
    value {
      field_value {
        int_value: 1
      }
    }
  }
}
upstream_nodes: "StatisticsGen"
downstream_nodes: "Transform"
execution_options {
  caching_options {
  }
}
, pipeline_info=id: "TestPythonTransformPipeline"
, pipeline_run_id='2025-10-15T18:21:14.982988', top_level_pipeline_run_id=None, frontend_url=None)
INFO:absl:Processing schema from statistics for split train.
INFO:absl:Processing schema from statistics for split eval.
INFO:absl:Processing schema from statistics for split test.
INFO:absl:Schema written to /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3/schema.pbtxt.
INFO:absl:Cleaning up stateless execution info.
INFO:absl:Execution 3 succeeded.
INFO:absl:Cleaning up stateful execution info.
INFO:absl:Deleted stateful_working_dir /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/.system/stateful_working_dir/66ad8fb4-3891-49fd-a4a4-87c2e867424e
INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3"
, artifact_type: name: "Schema"
)]}) for execution 3
INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

INFO:absl:Component SchemaGen is finished.
INFO:absl:Component Transform is running.
INFO:absl:Running launcher for node_info {
  type {
    name: "tfx.components.transform.component.Transform"
    base_type: TRANSFORM
  }
  id: "Transform"
}
contexts {
  contexts {
    type {
      name: "pipeline"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline"
      }
    }
  }
  contexts {
    type {
      name: "pipeline_run"
    }
    name {
      field_value {
        string_value: "2025-10-15T18:21:14.982988"
      }
    }
  }
  contexts {
    type {
      name: "node"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline.Transform"
      }
    }
  }
}
inputs {
  inputs {
    key: "examples"
    value {
      channels {
        producer_node_query {
          id: "MovieLensExampleGen"
        }
        context_queries {
          type {
            name: "pipeline"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline"
            }
          }
        }
        context_queries {
          type {
            name: "pipeline_run"
          }
          name {
            field_value {
              string_value: "2025-10-15T18:21:14.982988"
            }
          }
        }
        context_queries {
          type {
            name: "node"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline.MovieLensExampleGen"
            }
          }
        }
        artifact_query {
          type {
            name: "Examples"
            base_type: DATASET
          }
        }
        output_key: "output_examples"
      }
      min_count: 1
    }
  }
  inputs {
    key: "schema"
    value {
      channels {
        producer_node_query {
          id: "SchemaGen"
        }
        context_queries {
          type {
            name: "pipeline"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline"
            }
          }
        }
        context_queries {
          type {
            name: "pipeline_run"
          }
          name {
            field_value {
              string_value: "2025-10-15T18:21:14.982988"
            }
          }
        }
        context_queries {
          type {
            name: "node"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline.SchemaGen"
            }
          }
        }
        artifact_query {
          type {
            name: "Schema"
          }
        }
        output_key: "schema"
      }
      min_count: 1
    }
  }
}
outputs {
  outputs {
    key: "post_transform_anomalies"
    value {
      artifact_spec {
        type {
          name: "ExampleAnomalies"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
        }
      }
    }
  }
  outputs {
    key: "post_transform_schema"
    value {
      artifact_spec {
        type {
          name: "Schema"
        }
      }
    }
  }
  outputs {
    key: "post_transform_stats"
    value {
      artifact_spec {
        type {
          name: "ExampleStatistics"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          base_type: STATISTICS
        }
      }
    }
  }
  outputs {
    key: "pre_transform_schema"
    value {
      artifact_spec {
        type {
          name: "Schema"
        }
      }
    }
  }
  outputs {
    key: "pre_transform_stats"
    value {
      artifact_spec {
        type {
          name: "ExampleStatistics"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          base_type: STATISTICS
        }
      }
    }
  }
  outputs {
    key: "transform_graph"
    value {
      artifact_spec {
        type {
          name: "TransformGraph"
        }
      }
    }
  }
  outputs {
    key: "transformed_examples"
    value {
      artifact_spec {
        type {
          name: "Examples"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          properties {
            key: "version"
            value: INT
          }
          base_type: DATASET
        }
      }
    }
  }
  outputs {
    key: "updated_analyzer_cache"
    value {
      artifact_spec {
        type {
          name: "TransformCache"
        }
      }
    }
  }
}
parameters {
  parameters {
    key: "custom_config"
    value {
      field_value {
        string_value: "null"
      }
    }
  }
  parameters {
    key: "disable_statistics"
    value {
      field_value {
        int_value: 0
      }
    }
  }
  parameters {
    key: "force_tf_compat_v1"
    value {
      field_value {
        int_value: 0
      }
    }
  }
  parameters {
    key: "module_path"
    value {
      field_value {
        string_value: "transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl"
      }
    }
  }
}
upstream_nodes: "MovieLensExampleGen"
upstream_nodes: "SchemaGen"
execution_options {
  caching_options {
  }
}

INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

DEBUG:absl:Failed to get context of type node and name TestPythonTransformPipeline.Transform
DEBUG:absl:ID of context type {
  name: "node"
}
name {
  field_value {
    string_value: "TestPythonTransformPipeline.Transform"
  }
}
 is 9.
WARNING:absl:ArtifactQuery.property_predicate is not supported.
DEBUG:absl:examples <- [
  [NO_PARTITION]: [Examples(id=1, span=0, version=1)]
]
WARNING:absl:ArtifactQuery.property_predicate is not supported.
DEBUG:absl:schema <- [
  [NO_PARTITION]: [Schema(id=3)]
]
DEBUG:absl:Before conditional:
{schema: [Schema(id=3)], examples: [Examples(id=1, span=0, version=1)]}
DEBUG:absl:After conditional:
{schema: [Schema(id=3)], examples: [Examples(id=1, span=0, version=1)]}
INFO:absl:[Transform] Resolved inputs: ({'schema': [Artifact(artifact: id: 3
type_id: 19
uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3"
custom_properties {
  key: "is_external"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "tfx_version"
  value {
    string_value: "1.16.0"
  }
}
state: LIVE
type: "Schema"
create_time_since_epoch: 1760552525590
last_update_time_since_epoch: 1760552525590
, artifact_type: id: 19
name: "Schema"
)], 'examples': [Artifact(artifact: id: 1
type_id: 15
uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1"
properties {
  key: "span"
  value {
    int_value: 0
  }
}
properties {
  key: "split_names"
  value {
    string_value: "[\"train\", \"eval\", \"test\"]"
  }
}
properties {
  key: "version"
  value {
    int_value: 1
  }
}
custom_properties {
  key: "is_external"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "tfx_version"
  value {
    string_value: "1.16.0"
  }
}
state: LIVE
type: "Examples"
create_time_since_epoch: 1760552504176
last_update_time_since_epoch: 1760552504176
, artifact_type: id: 15
name: "Examples"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
properties {
  key: "version"
  value: INT
}
base_type: DATASET
)]},)
DEBUG:absl:Prepared EXECUTION:
 type_id: 20
last_known_state: RUNNING
custom_properties {
  key: "custom_config"
  value {
    string_value: "null"
  }
}
custom_properties {
  key: "disable_statistics"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "force_tf_compat_v1"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "module_path"
  value {
    string_value: "transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl"
  }
}
name: "063fdc21-f28d-45f8-9247-51c059a6d7c7"

DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_schema/4
DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4
DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_stats/4
DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4
DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_stats/4
DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/updated_analyzer_cache/4
DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_anomalies/4
DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_schema/4
INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

DEBUG:absl:Failed to get context of type execution_cache and name 302c4937af319d94cd3caf865d716191baa899ea26b35bf4551e58af8582dc54
DEBUG:absl:ID of context type {
  name: "execution_cache"
}
name {
  field_value {
    string_value: "302c4937af319d94cd3caf865d716191baa899ea26b35bf4551e58af8582dc54"
  }
}
 is 10.
INFO:absl:Going to run a new execution 4
I0000 00:00:1760552525.656185    5633 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}
INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=4, input_dict={'schema': [Artifact(artifact: id: 3
type_id: 19
uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3"
custom_properties {
  key: "is_external"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "tfx_version"
  value {
    string_value: "1.16.0"
  }
}
state: LIVE
type: "Schema"
create_time_since_epoch: 1760552525590
last_update_time_since_epoch: 1760552525590
, artifact_type: id: 19
name: "Schema"
)], 'examples': [Artifact(artifact: id: 1
type_id: 15
uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1"
properties {
  key: "span"
  value {
    int_value: 0
  }
}
properties {
  key: "split_names"
  value {
    string_value: "[\"train\", \"eval\", \"test\"]"
  }
}
properties {
  key: "version"
  value {
    int_value: 1
  }
}
custom_properties {
  key: "is_external"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "tfx_version"
  value {
    string_value: "1.16.0"
  }
}
state: LIVE
type: "Examples"
create_time_since_epoch: 1760552504176
last_update_time_since_epoch: 1760552504176
, artifact_type: id: 15
name: "Examples"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
properties {
  key: "version"
  value: INT
}
base_type: DATASET
)]}, output_dict=defaultdict(<class 'list'>, {'pre_transform_schema': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_schema/4"
, artifact_type: name: "Schema"
)], 'transformed_examples': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4"
, artifact_type: name: "Examples"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
properties {
  key: "version"
  value: INT
}
base_type: DATASET
)], 'pre_transform_stats': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_stats/4"
, artifact_type: name: "ExampleStatistics"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
base_type: STATISTICS
)], 'transform_graph': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4"
, artifact_type: name: "TransformGraph"
)], 'post_transform_stats': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_stats/4"
, artifact_type: name: "ExampleStatistics"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
base_type: STATISTICS
)], 'updated_analyzer_cache': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/updated_analyzer_cache/4"
, artifact_type: name: "TransformCache"
)], 'post_transform_anomalies': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_anomalies/4"
, artifact_type: name: "ExampleAnomalies"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
)], 'post_transform_schema': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_schema/4"
, artifact_type: name: "Schema"
)]}), exec_properties={'force_tf_compat_v1': 0, 'module_path': 'transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl', 'custom_config': 'null', 'disable_statistics': 0}, execution_output_uri='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/.system/executor_execution/4/executor_output.pb', stateful_working_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/.system/stateful_working_dir/46cd654d-ad1f-40ef-a464-b2e59f9eddc8', tmp_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/.system/executor_execution/4/.temp/', pipeline_node=node_info {
  type {
    name: "tfx.components.transform.component.Transform"
    base_type: TRANSFORM
  }
  id: "Transform"
}
contexts {
  contexts {
    type {
      name: "pipeline"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline"
      }
    }
  }
  contexts {
    type {
      name: "pipeline_run"
    }
    name {
      field_value {
        string_value: "2025-10-15T18:21:14.982988"
      }
    }
  }
  contexts {
    type {
      name: "node"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline.Transform"
      }
    }
  }
}
inputs {
  inputs {
    key: "examples"
    value {
      channels {
        producer_node_query {
          id: "MovieLensExampleGen"
        }
        context_queries {
          type {
            name: "pipeline"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline"
            }
          }
        }
        context_queries {
          type {
            name: "pipeline_run"
          }
          name {
            field_value {
              string_value: "2025-10-15T18:21:14.982988"
            }
          }
        }
        context_queries {
          type {
            name: "node"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline.MovieLensExampleGen"
            }
          }
        }
        artifact_query {
          type {
            name: "Examples"
            base_type: DATASET
          }
        }
        output_key: "output_examples"
      }
      min_count: 1
    }
  }
  inputs {
    key: "schema"
    value {
      channels {
        producer_node_query {
          id: "SchemaGen"
        }
        context_queries {
          type {
            name: "pipeline"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline"
            }
          }
        }
        context_queries {
          type {
            name: "pipeline_run"
          }
          name {
            field_value {
              string_value: "2025-10-15T18:21:14.982988"
            }
          }
        }
        context_queries {
          type {
            name: "node"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline.SchemaGen"
            }
          }
        }
        artifact_query {
          type {
            name: "Schema"
          }
        }
        output_key: "schema"
      }
      min_count: 1
    }
  }
}
outputs {
  outputs {
    key: "post_transform_anomalies"
    value {
      artifact_spec {
        type {
          name: "ExampleAnomalies"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
        }
      }
    }
  }
  outputs {
    key: "post_transform_schema"
    value {
      artifact_spec {
        type {
          name: "Schema"
        }
      }
    }
  }
  outputs {
    key: "post_transform_stats"
    value {
      artifact_spec {
        type {
          name: "ExampleStatistics"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          base_type: STATISTICS
        }
      }
    }
  }
  outputs {
    key: "pre_transform_schema"
    value {
      artifact_spec {
        type {
          name: "Schema"
        }
      }
    }
  }
  outputs {
    key: "pre_transform_stats"
    value {
      artifact_spec {
        type {
          name: "ExampleStatistics"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          base_type: STATISTICS
        }
      }
    }
  }
  outputs {
    key: "transform_graph"
    value {
      artifact_spec {
        type {
          name: "TransformGraph"
        }
      }
    }
  }
  outputs {
    key: "transformed_examples"
    value {
      artifact_spec {
        type {
          name: "Examples"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          properties {
            key: "version"
            value: INT
          }
          base_type: DATASET
        }
      }
    }
  }
  outputs {
    key: "updated_analyzer_cache"
    value {
      artifact_spec {
        type {
          name: "TransformCache"
        }
      }
    }
  }
}
parameters {
  parameters {
    key: "custom_config"
    value {
      field_value {
        string_value: "null"
      }
    }
  }
  parameters {
    key: "disable_statistics"
    value {
      field_value {
        int_value: 0
      }
    }
  }
  parameters {
    key: "force_tf_compat_v1"
    value {
      field_value {
        int_value: 0
      }
    }
  }
  parameters {
    key: "module_path"
    value {
      field_value {
        string_value: "transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl"
      }
    }
  }
}
upstream_nodes: "MovieLensExampleGen"
upstream_nodes: "SchemaGen"
execution_options {
  caching_options {
  }
}
, pipeline_info=id: "TestPythonTransformPipeline"
, pipeline_run_id='2025-10-15T18:21:14.982988', top_level_pipeline_run_id=None, frontend_url=None)
INFO:absl:Attempting to infer TFX Python dependency for beam
INFO:absl:Copying all content from install dir /usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx to temp dir /tmp/tmp2va91wl9/build/tfx
INFO:absl:Generating a temp setup file at /tmp/tmp2va91wl9/build/tfx/setup.py
INFO:absl:Creating temporary sdist package, logs available at /tmp/tmp2va91wl9/build/tfx/setup.log
INFO:absl:Added --extra_package=/tmp/tmp2va91wl9/build/tfx/dist/tfx_ephemeral-1.16.0.tar.gz to beam args
DEBUG:absl:Starting Executor execution.
INFO:absl:Analyze the 'train' split and transform all splits when splits_config is not set.
WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE
DEBUG:absl:Using temp path /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4/.temp_path for tft.beam
INFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl', 'preprocessing_fn': None} 'preprocessing_fn'
INFO:absl:Installing '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl' to a temporary directory.
INFO:absl:Executing: ['/usr/local/envs/my_tfx_env/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmpdals0ws1', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl']
INFO:absl:Successfully installed '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl'.
INFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl', 'stats_options_updater_fn': None} 'stats_options_updater_fn'
INFO:absl:Installing '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl' to a temporary directory.
INFO:absl:Executing: ['/usr/local/envs/my_tfx_env/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmpgf3bgrvr', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl']
INFO:absl:Successfully installed '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl'.
INFO:absl:Installing '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl' to a temporary directory.
INFO:absl:Executing: ['/usr/local/envs/my_tfx_env/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmp3v1inzlv', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl']
INFO:absl:Successfully installed '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+885d6edc9a6e34c4858e5e5f81490dcd26f8916f4798fe22f1b19305fc5889e9-py3-none-any.whl'.
DEBUG:absl:Inputs to executor.Transform function: {'disable_statistics': False, 'schema_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3/schema.pbtxt', 'examples_data_format': 6, 'data_view_uri': None, 'analyze_data_paths': ['/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/*'], 'analyze_paths_file_formats': ['tfrecords_gzip'], 'transform_data_paths': ['/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/*', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/*', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/*'], 'transform_paths_file_formats': ['tfrecords_gzip', 'tfrecords_gzip', 'tfrecords_gzip'], 'preprocessing_fn': <function preprocessing_fn at 0x7da78413e8c0>, 'stats_options_updater_fn': None, 'make_beam_pipeline_fn': <bound method BaseBeamExecutor._make_beam_pipeline of <tfx.components.transform.executor.Executor object at 0x7da767738130>>, 'force_tf_compat_v1': False, 'save_options': None}
DEBUG:absl:Outputs to executor.Transform function: {'transform_output_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4', 'transform_materialize_output_paths': ['/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-train/transformed_examples', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-eval/transformed_examples', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-test/transformed_examples'], 'temp_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4/.temp_path', 'pre_transform_output_stats_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_stats/4', 'pre_transform_output_schema_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_schema/4', 'post_transform_output_anomalies_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_anomalies/4', 'post_transform_output_stats_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_stats/4', 'post_transform_output_schema_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_schema/4', 'cache_output_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/updated_analyzer_cache/4'}
DEBUG:absl:Force tf.compat.v1: False
DEBUG:absl:SaveOptions: None
DEBUG:absl:Analyze data patterns: [(0, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/*')]
DEBUG:absl:Transform data patterns: [(0, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/*'), (1, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/*'), (2, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/*')]
DEBUG:absl:Transform materialization output paths: [(0, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-train/transformed_examples'), (1, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-eval/transformed_examples'), (2, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-test/transformed_examples')]
DEBUG:absl:Transform output path: /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4
INFO:absl:Feature gender has a shape dim {
  size: 1
}
. Setting to DenseTensor.
INFO:absl:Feature genres has a shape dim {
  size: 1
}
. Setting to DenseTensor.
INFO:absl:Feature age has a shape dim {
  size: 1
}
. Setting to DenseTensor.
INFO:absl:Feature movie_id has a shape dim {
  size: 1
}
. Setting to DenseTensor.
INFO:absl:Feature occupation has a shape dim {
  size: 1
}
. Setting to DenseTensor.
INFO:absl:Feature rating has a shape dim {
  size: 1
}
. Setting to DenseTensor.
INFO:absl:Feature timestamp has a shape dim {
  size: 1
}
. Setting to DenseTensor.
INFO:absl:Feature user_id has a shape dim {
  size: 1
}
. Setting to DenseTensor.
DEBUG:absl:inputs={'gender': <tf.Tensor 'inputs_copy:0' shape=(None, 1) dtype=string>, 'genres': <tf.Tensor 'inputs_1_copy:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'inputs_2_copy:0' shape=(None, 1) dtype=int64>, 'movie_id': <tf.Tensor 'inputs_3_copy:0' shape=(None, 1) dtype=int64>, 'occupation': <tf.Tensor 'inputs_4_copy:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'inputs_5_copy:0' shape=(None, 1) dtype=int64>, 'timestamp': <tf.Tensor 'inputs_6_copy:0' shape=(None, 1) dtype=int64>, 'user_id': <tf.Tensor 'inputs_7_copy:0' shape=(None, 1) dtype=int64>}

DEBUG:absl:inputs['genres']=Tensor("inputs_1_copy:0", shape=(None, 1), dtype=string)

DEBUG:absl:outputs['genres']=
  tf.RaggedTensor(
    values=tf.RaggedTensor(
      values=Tensor("StringSplit/StringSplit/StringSplit/StringSplitV2:1", shape=(None,), dtype=string)
      , row_splits
        =Tensor("StringSplit/StringSplit/StringSplit/RaggedFromValueRowIds/RowPartitionFromValueRowIds/concat:0", shape=(None,), dtype=int64)
    )
    , row_splits
      =Tensor("StringSplit/RaggedFromTensor/RaggedFromUniformRowLength/RowPartitionFromUniformRowLength/mul:0", shape=(None,), dtype=int64)
  )

  RaggedTensor of a string Tensor of shape=(None,)


DEBUG:absl:padded_tensor=Tensor("RaggedToTensor/RaggedTensorToTensor:0", shape=(None, 1, None), dtype=string)
DEBUG:absl:flattened_tensor=Tensor("Reshape:0", shape=(None,), dtype=string)
DEBUG:absl:lookup_results_flat=Tensor("None_Lookup_2/LookupTableFindV2:0", shape=(None,), dtype=int64)
DEBUG:absl:padded_tensor.shape=(None, 1, None)
INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

ERROR:absl:Execution 4 failed.
INFO:absl:Cleaning up stateless execution info.
Es
======================================================================
ERROR: test_MovieLensExampleGen (transform_movie_lens_test.IngestMovieLensComponentTest)
transform_movie_lens_test.IngestMovieLensComponentTest.test_MovieLensExampleGen
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py", line 531, in _ExtractInputsAndAttrs
    inferred = ops.convert_to_tensor(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py", line 183, in wrapped
    return func(*args, **kwargs)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 713, in convert_to_tensor
    return tensor_conversion_registry.convert(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 234, in convert
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py", line 344, in _tensor_shape_tensor_conversion_function
    raise ValueError(
ValueError: Cannot convert a partially known TensorShape (None, 1, None) to a Tensor.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py", line 569, in _ExtractInputsAndAttrs
    observed = ops.convert_to_tensor(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py", line 183, in wrapped
    return func(*args, **kwargs)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 713, in convert_to_tensor
    return tensor_conversion_registry.convert(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 234, in convert
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py", line 344, in _tensor_shape_tensor_conversion_function
    raise ValueError(
ValueError: Cannot convert a partially known TensorShape (None, 1, None) to a Tensor.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/kaggle/working/transform_movie_lens_test.py", line 115, in test_MovieLensExampleGen
    tfx.orchestration.LocalDagRunner().run(my_pipeline)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/tfx_runner.py", line 124, in run
    return self.run_with_ir(pipeline_pb, run_options=run_options_pb, **kwargs)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/local/local_dag_runner.py", line 109, in run_with_ir
    component_launcher.launch()
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/launcher.py", line 613, in launch
    executor_output = self._run_executor(execution_info)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/launcher.py", line 487, in _run_executor
    executor_output = self._executor_operator.run_executor(execution_info)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/beam_executor_operator.py", line 112, in run_executor
    return python_executor_operator.run_with_executor(execution_info, executor)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/python_executor_operator.py", line 84, in run_with_executor
    result = executor.Do(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/components/transform/executor.py", line 641, in Do
    TransformProcessor().Transform(label_inputs, label_outputs, status_file)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/components/transform/executor.py", line 1216, in Transform
    analyze_input_columns = tft.get_analyze_input_columns(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow_transform/inspect_preprocessing_fn.py", line 49, in get_analyze_input_columns
    impl_helper.trace_preprocessing_function(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow_transform/impl_helper.py", line 441, in trace_preprocessing_function
    return _trace_preprocessing_fn_v2(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow_transform/impl_helper.py", line 409, in _trace_preprocessing_fn_v2
    preprocessing_fn, specs, tf_graph_context).get_concrete_function()
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 1251, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 1221, in _get_concrete_function_garbage_collected
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 696, in _initialize
    self._concrete_variable_creation_fn = tracing_compilation.trace_function(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py", line 178, in trace_function
    concrete_function = _maybe_define_function(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py", line 283, in _maybe_define_function
    concrete_function = _create_concrete_function(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py", line 310, in _create_concrete_function
    traced_func_graph = func_graph_module.func_graph_from_py_func(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py", line 1059, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 599, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow_transform/impl_helper.py", line 365, in transform_fn
    transformed_features = preprocessing_fn(inputs_copy)
  File "/kaggle/working/transform_movie_lens.py", line 94, in preprocessing_fn
    lookup_results_padded = tf.reshape(lookup_results_flat, padded_tensor.shape)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py", line 88, in wrapper
    return op(*args, **kwargs)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py", line 141, in error_handler
    return fn(*args, **kwargs)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py", line 1260, in op_dispatch_handler
    return dispatch_target(*args, **kwargs)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py", line 199, in reshape
    result = gen_array_ops.reshape(tensor, shape, name)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py", line 8758, in reshape
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py", line 778, in _apply_op_helper
    _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py", line 572, in _ExtractInputsAndAttrs
    raise ValueError(
ValueError: Tried to convert 'shape' to a tensor and failed. Error: Cannot convert a partially known TensorShape (None, 1, None) to a Tensor.

----------------------------------------------------------------------
Ran 2 tests in 56.471s

FAILED (errors=1, skipped=1)
