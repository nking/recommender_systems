DEBUG:absl:outputs['genres']=
  tf.RaggedTensor(
    values=tf.RaggedTensor(
      values=Tensor("StringSplit/StringSplit/StringSplit/StringSplitV2:1", shape=(None,), dtype=string)
      , row_splits
        =Tensor("StringSplit/StringSplit/StringSplit/RaggedFromValueRowIds/RowPartitionFromValueRowIds/concat:0", shape=(None,), dtype=int64)
    )
    , row_splits
      =Tensor("StringSplit/RaggedFromTensor/RaggedFromUniformRowLength/RowPartitionFromUniformRowLength/mul:0", shape=(None,), dtype=int64)
  )

  RaggedTensor of a string Tensor of shape=(None,)

====
INFO:absl:Excluding no splits because exclude_splits is not set.
INFO:absl:Excluding no splits because exclude_splits is not set.
INFO:absl:Generating ephemeral wheel package for '/kaggle/working/transform_movie_lens.py' (including modules: ['ingest_movie_lens_beam_pa', 'ingest_movie_lens_custom_component', 'csv_example_gen_test', 'ingest_movie_lens_component_test', 'CustomUTF8Coder', 'helper', 'ingest_movie_lens_component', 'dataset_tfxio_example', 'movie_lens_utils_test', 'transform_movie_lens_test', 'transform_movie_lens', 'movie_lens_utils', 'ingest_movie_lens_custom_component_test', 'ingest_movie_lens_beam_test', 'ingest_movie_lens_beam_pa_test', 'ingest_movie_lens_beam']).
INFO:absl:User module package has hash fingerprint version 8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a.
INFO:absl:Executing: ['/usr/local/envs/my_tfx_env/bin/python', '/tmp/tmpmfmk7fc0/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmp2j6gvn4m', '--dist-dir', '/tmp/tmpshtezqgo']
/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:90: SetuptoolsDeprecationWarning: setup.py install is deprecated.
!!

        ********************************************************************************
        Please avoid running ``setup.py`` directly.
        Instead, use pypa/build, pypa/installer or other
        standards-based tools.

        By 2025-Oct-31, you need to update your project and remove deprecated calls
        or your builds will no longer be supported.

        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.
        ********************************************************************************

!!
  self.initialize_options()
INFO:absl:Successfully built user code wheel distribution at '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl'; target user module is 'transform_movie_lens'.
INFO:absl:Full user module path is 'transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl'
INFO:absl:Using deployment config:
 executor_specs {
  key: "MovieLensExampleGen"
  value {
    beam_executable_spec {
      python_executor_spec {
        class_path: "ingest_movie_lens_component.MovieLensExampleGen_Executor"
      }
      beam_pipeline_args: "--direct_running_mode=multi_processing"
      beam_pipeline_args: "--direct_num_workers=0"
      beam_pipeline_args_placeholders {
        value {
          string_value: "--direct_running_mode=multi_processing"
        }
      }
      beam_pipeline_args_placeholders {
        value {
          string_value: "--direct_num_workers=0"
        }
      }
    }
  }
}
executor_specs {
  key: "SchemaGen"
  value {
    python_class_executable_spec {
      class_path: "tfx.components.schema_gen.executor.Executor"
    }
  }
}
executor_specs {
  key: "StatisticsGen"
  value {
    beam_executable_spec {
      python_executor_spec {
        class_path: "tfx.components.statistics_gen.executor.Executor"
      }
      beam_pipeline_args: "--direct_running_mode=multi_processing"
      beam_pipeline_args: "--direct_num_workers=0"
      beam_pipeline_args_placeholders {
        value {
          string_value: "--direct_running_mode=multi_processing"
        }
      }
      beam_pipeline_args_placeholders {
        value {
          string_value: "--direct_num_workers=0"
        }
      }
    }
  }
}
executor_specs {
  key: "Transform"
  value {
    beam_executable_spec {
      python_executor_spec {
        class_path: "tfx.components.transform.executor.Executor"
      }
      beam_pipeline_args: "--direct_running_mode=multi_processing"
      beam_pipeline_args: "--direct_num_workers=0"
      beam_pipeline_args_placeholders {
        value {
          string_value: "--direct_running_mode=multi_processing"
        }
      }
      beam_pipeline_args_placeholders {
        value {
          string_value: "--direct_num_workers=0"
        }
      }
    }
  }
}
metadata_connection_config {
  database_connection_config {
    sqlite {
      filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
      connection_mode: READWRITE_OPENCREATE
    }
  }
}

INFO:absl:Using connection config:
 sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

INFO:absl:Component MovieLensExampleGen is running.
INFO:absl:Running launcher for node_info {
  type {
    name: "ingest_movie_lens_component.MovieLensExampleGen"
  }
  id: "MovieLensExampleGen"
}
contexts {
  contexts {
    type {
      name: "pipeline"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline"
      }
    }
  }
  contexts {
    type {
      name: "pipeline_run"
    }
    name {
      field_value {
        string_value: "2025-10-15T19:51:34.676953"
      }
    }
  }
  contexts {
    type {
      name: "node"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline.MovieLensExampleGen"
      }
    }
  }
}
outputs {
  outputs {
    key: "output_examples"
    value {
      artifact_spec {
        type {
          name: "Examples"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          properties {
            key: "version"
            value: INT
          }
          base_type: DATASET
        }
      }
    }
  }
}
parameters {
  parameters {
    key: "infiles_dict_ser"
    value {
      field_value {
        string_value: "gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg=="
      }
    }
  }
  parameters {
    key: "output_config_ser"
    value {
      field_value {
        string_value: "Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK"
      }
    }
  }
}
downstream_nodes: "StatisticsGen"
downstream_nodes: "Transform"
execution_options {
  caching_options {
  }
}

INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

DEBUG:absl:Failed to get context of type pipeline and name TestPythonTransformPipeline
DEBUG:absl:ID of context type {
  name: "pipeline"
}
name {
  field_value {
    string_value: "TestPythonTransformPipeline"
  }
}
 is 1.
DEBUG:absl:Failed to get context of type pipeline_run and name 2025-10-15T19:51:34.676953
DEBUG:absl:ID of context type {
  name: "pipeline_run"
}
name {
  field_value {
    string_value: "2025-10-15T19:51:34.676953"
  }
}
 is 2.
DEBUG:absl:Failed to get context of type node and name TestPythonTransformPipeline.MovieLensExampleGen
DEBUG:absl:ID of context type {
  name: "node"
}
name {
  field_value {
    string_value: "TestPythonTransformPipeline.MovieLensExampleGen"
  }
}
 is 3.
DEBUG:absl:Before conditional:
{}
DEBUG:absl:After conditional:
{}
INFO:absl:[MovieLensExampleGen] Resolved inputs: ({},)
DEBUG:absl:Prepared EXECUTION:
 type_id: 13
last_known_state: RUNNING
custom_properties {
  key: "infiles_dict_ser"
  value {
    string_value: "gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg=="
  }
}
custom_properties {
  key: "output_config_ser"
  value {
    string_value: "Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK"
  }
}
name: "e6909b52-0394-4f3a-9658-ec676ae6e617"

DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1
INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

DEBUG:absl:Failed to get context of type execution_cache and name 9c8ee902c018e9e330485b35a8dcba812ad906560ec1fa358c345cfb41f487bf
DEBUG:absl:ID of context type {
  name: "execution_cache"
}
name {
  field_value {
    string_value: "9c8ee902c018e9e330485b35a8dcba812ad906560ec1fa358c345cfb41f487bf"
  }
}
 is 4.
INFO:absl:Going to run a new execution 1
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1760557894.848602    6957 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}
INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=1, input_dict={}, output_dict=defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1"
, artifact_type: name: "Examples"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
properties {
  key: "version"
  value: INT
}
base_type: DATASET
)]}), exec_properties={'infiles_dict_ser': 'gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg==', 'output_config_ser': 'Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK'}, execution_output_uri='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/.system/executor_execution/1/executor_output.pb', stateful_working_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/.system/stateful_working_dir/f8a3588c-c8b2-4dbe-bc90-973005ddfe07', tmp_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/.system/executor_execution/1/.temp/', pipeline_node=node_info {
  type {
    name: "ingest_movie_lens_component.MovieLensExampleGen"
  }
  id: "MovieLensExampleGen"
}
contexts {
  contexts {
    type {
      name: "pipeline"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline"
      }
    }
  }
  contexts {
    type {
      name: "pipeline_run"
    }
    name {
      field_value {
        string_value: "2025-10-15T19:51:34.676953"
      }
    }
  }
  contexts {
    type {
      name: "node"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline.MovieLensExampleGen"
      }
    }
  }
}
outputs {
  outputs {
    key: "output_examples"
    value {
      artifact_spec {
        type {
          name: "Examples"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          properties {
            key: "version"
            value: INT
          }
          base_type: DATASET
        }
      }
    }
  }
}
parameters {
  parameters {
    key: "infiles_dict_ser"
    value {
      field_value {
        string_value: "gASVEgIAAAAAAAB9lCiMB3JhdGluZ3OUfZQojARjb2xzlH2UKIwHdXNlcl9pZJR9lCiMBWluZGV4lEsAjAR0eXBllIwIYnVpbHRpbnOUjANpbnSUk5R1jAhtb3ZpZV9pZJR9lChoB0sBaAhoC3WMBnJhdGluZ5R9lChoB0sCaAhoC3WMCXRpbWVzdGFtcJR9lChoB0sDaAhoC3V1jAN1cmmUjCYva2FnZ2xlL3dvcmtpbmcvbWwtMW0vcmF0aW5nc18xMDAwLmRhdJSMD2hlYWRlcnNfcHJlc2VudJSJjAVkZWxpbZSMAjo6lHWMBm1vdmllc5R9lChoA32UKGgMfZQoaAdLAGgIaAt1jAV0aXRsZZR9lChoB0sBaAhoCYwDc3RylJOUdYwGZ2VucmVzlH2UKGgHSwJoCGgedXVoEowgL2thZ2dsZS93b3JraW5nL21sLTFtL21vdmllcy5kYXSUaBSJaBVoFnWMBXVzZXJzlH2UKGgDfZQoaAV9lChoB0sAaAhoC3WMBmdlbmRlcpR9lChoB0sBaAhoHnWMA2FnZZR9lChoB0sCaAhoC3WMCm9jY3VwYXRpb26UfZQoaAdLA2gIaAt1jAd6aXBjb2RllH2UKGgHSwRoCGgedXVoEowjL2thZ2dsZS93b3JraW5nL21sLTFtL3VzZXJzXzEwMC5kYXSUaBSJaBVoFnWMB3ZlcnNpb26USwF1Lg=="
      }
    }
  }
  parameters {
    key: "output_config_ser"
    value {
      field_value {
        string_value: "Gh8KCQoFdHJhaW4QUAoICgRldmFsEAoKCAoEdGVzdBAK"
      }
    }
  }
}
downstream_nodes: "StatisticsGen"
downstream_nodes: "Transform"
execution_options {
  caching_options {
  }
}
, pipeline_info=id: "TestPythonTransformPipeline"
, pipeline_run_id='2025-10-15T19:51:34.676953', top_level_pipeline_run_id=None, frontend_url=None)
INFO:absl:Attempting to infer TFX Python dependency for beam
INFO:absl:Copying all content from install dir /usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx to temp dir /tmp/tmp0eqf5fko/build/tfx
INFO:absl:Generating a temp setup file at /tmp/tmp0eqf5fko/build/tfx/setup.py
INFO:absl:Creating temporary sdist package, logs available at /tmp/tmp0eqf5fko/build/tfx/setup.log
INFO:absl:Added --extra_package=/tmp/tmp0eqf5fko/build/tfx/dist/tfx_ephemeral-1.16.0.tar.gz to beam args
INFO:absl:MovieLensExampleGen
DEBUG:absl:output_examples was passed in to component
DEBUG:absl:output_examples TYPE=<class 'tfx.types.standard_artifacts.Examples'>
DEBUG:absl:output_examples=Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1"
properties {
  key: "span"
  value {
    int_value: 0
  }
}
properties {
  key: "split_names"
  value {
    string_value: "[\"train\", \"eval\", \"test\"]"
  }
}
properties {
  key: "version"
  value {
    int_value: 1
  }
}
, artifact_type: name: "Examples"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
properties {
  key: "version"
  value: INT
}
base_type: DATASET
)
DEBUG:absl:split_names=['train', 'eval', 'test']
DEBUG:absl:columns=[('user_id', <class 'int'>), ('movie_id', <class 'int'>), ('rating', <class 'int'>), ('timestamp', <class 'int'>), ('gender', <class 'str'>), ('age', <class 'int'>), ('occupation', <class 'int'>), ('genres', <class 'str'>)]
DEBUG:absl:cumulative_buckets=[80, 90, 100]
DEBUG:absl:have ratings_tuple.  type=<class 'apache_beam.pvalue.DoOutputsTuple'>
DEBUG:absl:prefix_path=/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/data_tfrecord
DEBUG:absl:prefix_path=/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/data_tfrecord
DEBUG:absl:prefix_path=/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/data_tfrecord
INFO:absl:output_examples written as TFRecords
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557900   nanos: 394519329 } message: "No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail." log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557900   nanos: 399531126 } message: "Discarding unparseable args: [\'--pipeline_type_check\', \'--direct_runner_use_stacked_bundle\']" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557900   nanos: 398397684 } message: "No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail." log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557900   nanos: 403666973 } message: "Discarding unparseable args: [\'--pipeline_type_check\', \'--direct_runner_use_stacked_bundle\']" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557900   nanos: 438807964 } message: "No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail." log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557900   nanos: 445314884 } message: "Discarding unparseable args: [\'--pipeline_type_check\', \'--direct_runner_use_stacked_bundle\']" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557900   nanos: 464097976 } message: "No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail." log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557900   nanos: 469828844 } message: "Discarding unparseable args: [\'--pipeline_type_check\', \'--direct_runner_use_stacked_bundle\']" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557911   nanos: 44667720 } message: "Couldn\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be." instruction_id: "bundle_50" transform_id: "write_to_tfrecord_421920178746/Write/WriteImpl/WriteBundles" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59" thread: "Thread-14" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557911   nanos: 44403791 } message: "Couldn\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be." instruction_id: "bundle_51" transform_id: "write_to_tfrecord_421920178746/Write/WriteImpl/WriteBundles" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59" thread: "Thread-14" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557911   nanos: 64056634 } message: "Couldn\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be." instruction_id: "bundle_52" transform_id: "write_to_tfrecord_421920178746/Write/WriteImpl/WriteBundles" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59" thread: "Thread-12" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557911   nanos: 131616830 } message: "Couldn\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be." instruction_id: "bundle_49" transform_id: "write_to_tfrecord_281587505522/Write/WriteImpl/WriteBundles" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59" thread: "Thread-13" 
INFO:absl:Cleaning up stateless execution info.
INFO:absl:Execution 1 succeeded.
INFO:absl:Cleaning up stateful execution info.
INFO:absl:Deleted stateful_working_dir /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/.system/stateful_working_dir/f8a3588c-c8b2-4dbe-bc90-973005ddfe07
INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'output_examples': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1"
, artifact_type: name: "Examples"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
properties {
  key: "version"
  value: INT
}
base_type: DATASET
)]}) for execution 1
INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

INFO:absl:Component MovieLensExampleGen is finished.
INFO:absl:Component StatisticsGen is running.
INFO:absl:Running launcher for node_info {
  type {
    name: "tfx.components.statistics_gen.component.StatisticsGen"
    base_type: PROCESS
  }
  id: "StatisticsGen"
}
contexts {
  contexts {
    type {
      name: "pipeline"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline"
      }
    }
  }
  contexts {
    type {
      name: "pipeline_run"
    }
    name {
      field_value {
        string_value: "2025-10-15T19:51:34.676953"
      }
    }
  }
  contexts {
    type {
      name: "node"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline.StatisticsGen"
      }
    }
  }
}
inputs {
  inputs {
    key: "examples"
    value {
      channels {
        producer_node_query {
          id: "MovieLensExampleGen"
        }
        context_queries {
          type {
            name: "pipeline"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline"
            }
          }
        }
        context_queries {
          type {
            name: "pipeline_run"
          }
          name {
            field_value {
              string_value: "2025-10-15T19:51:34.676953"
            }
          }
        }
        context_queries {
          type {
            name: "node"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline.MovieLensExampleGen"
            }
          }
        }
        artifact_query {
          type {
            name: "Examples"
            base_type: DATASET
          }
        }
        output_key: "output_examples"
      }
      min_count: 1
    }
  }
}
outputs {
  outputs {
    key: "statistics"
    value {
      artifact_spec {
        type {
          name: "ExampleStatistics"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          base_type: STATISTICS
        }
      }
    }
  }
}
parameters {
  parameters {
    key: "exclude_splits"
    value {
      field_value {
        string_value: "[]"
      }
    }
  }
}
upstream_nodes: "MovieLensExampleGen"
downstream_nodes: "SchemaGen"
execution_options {
  caching_options {
  }
}

INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

DEBUG:absl:Failed to get context of type node and name TestPythonTransformPipeline.StatisticsGen
DEBUG:absl:ID of context type {
  name: "node"
}
name {
  field_value {
    string_value: "TestPythonTransformPipeline.StatisticsGen"
  }
}
 is 5.
WARNING:absl:ArtifactQuery.property_predicate is not supported.
DEBUG:absl:examples <- [
  [NO_PARTITION]: [Examples(id=1, span=0, version=1)]
]
DEBUG:absl:Before conditional:
{examples: [Examples(id=1, span=0, version=1)]}
DEBUG:absl:After conditional:
{examples: [Examples(id=1, span=0, version=1)]}
INFO:absl:[StatisticsGen] Resolved inputs: ({'examples': [Artifact(artifact: id: 1
type_id: 15
uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1"
properties {
  key: "span"
  value {
    int_value: 0
  }
}
properties {
  key: "split_names"
  value {
    string_value: "[\"train\", \"eval\", \"test\"]"
  }
}
properties {
  key: "version"
  value {
    int_value: 1
  }
}
custom_properties {
  key: "is_external"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "tfx_version"
  value {
    string_value: "1.16.0"
  }
}
state: LIVE
type: "Examples"
create_time_since_epoch: 1760557919866
last_update_time_since_epoch: 1760557919866
, artifact_type: id: 15
name: "Examples"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
properties {
  key: "version"
  value: INT
}
base_type: DATASET
)]},)
DEBUG:absl:Prepared EXECUTION:
 type_id: 16
last_known_state: RUNNING
custom_properties {
  key: "exclude_splits"
  value {
    string_value: "[]"
  }
}
name: "257c5da3-8ede-41ee-a816-8938661fb776"

DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2
INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

DEBUG:absl:Failed to get context of type execution_cache and name b5013f3f49f26aa8abd74da60b1b5d40152fe02f76498cd5fd47b6c45e068677
DEBUG:absl:ID of context type {
  name: "execution_cache"
}
name {
  field_value {
    string_value: "b5013f3f49f26aa8abd74da60b1b5d40152fe02f76498cd5fd47b6c45e068677"
  }
}
 is 6.
INFO:absl:Going to run a new execution 2
I0000 00:00:1760557919.931333    6957 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}
INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=2, input_dict={'examples': [Artifact(artifact: id: 1
type_id: 15
uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1"
properties {
  key: "span"
  value {
    int_value: 0
  }
}
properties {
  key: "split_names"
  value {
    string_value: "[\"train\", \"eval\", \"test\"]"
  }
}
properties {
  key: "version"
  value {
    int_value: 1
  }
}
custom_properties {
  key: "is_external"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "tfx_version"
  value {
    string_value: "1.16.0"
  }
}
state: LIVE
type: "Examples"
create_time_since_epoch: 1760557919866
last_update_time_since_epoch: 1760557919866
, artifact_type: id: 15
name: "Examples"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
properties {
  key: "version"
  value: INT
}
base_type: DATASET
)]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2"
, artifact_type: name: "ExampleStatistics"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
base_type: STATISTICS
)]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/.system/executor_execution/2/executor_output.pb', stateful_working_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/.system/stateful_working_dir/45bc1a0c-8c42-4d4e-b4cd-f173c358beaa', tmp_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/.system/executor_execution/2/.temp/', pipeline_node=node_info {
  type {
    name: "tfx.components.statistics_gen.component.StatisticsGen"
    base_type: PROCESS
  }
  id: "StatisticsGen"
}
contexts {
  contexts {
    type {
      name: "pipeline"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline"
      }
    }
  }
  contexts {
    type {
      name: "pipeline_run"
    }
    name {
      field_value {
        string_value: "2025-10-15T19:51:34.676953"
      }
    }
  }
  contexts {
    type {
      name: "node"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline.StatisticsGen"
      }
    }
  }
}
inputs {
  inputs {
    key: "examples"
    value {
      channels {
        producer_node_query {
          id: "MovieLensExampleGen"
        }
        context_queries {
          type {
            name: "pipeline"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline"
            }
          }
        }
        context_queries {
          type {
            name: "pipeline_run"
          }
          name {
            field_value {
              string_value: "2025-10-15T19:51:34.676953"
            }
          }
        }
        context_queries {
          type {
            name: "node"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline.MovieLensExampleGen"
            }
          }
        }
        artifact_query {
          type {
            name: "Examples"
            base_type: DATASET
          }
        }
        output_key: "output_examples"
      }
      min_count: 1
    }
  }
}
outputs {
  outputs {
    key: "statistics"
    value {
      artifact_spec {
        type {
          name: "ExampleStatistics"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          base_type: STATISTICS
        }
      }
    }
  }
}
parameters {
  parameters {
    key: "exclude_splits"
    value {
      field_value {
        string_value: "[]"
      }
    }
  }
}
upstream_nodes: "MovieLensExampleGen"
downstream_nodes: "SchemaGen"
execution_options {
  caching_options {
  }
}
, pipeline_info=id: "TestPythonTransformPipeline"
, pipeline_run_id='2025-10-15T19:51:34.676953', top_level_pipeline_run_id=None, frontend_url=None)
INFO:absl:Attempting to infer TFX Python dependency for beam
INFO:absl:Copying all content from install dir /usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx to temp dir /tmp/tmp41fqvony/build/tfx
INFO:absl:Generating a temp setup file at /tmp/tmp41fqvony/build/tfx/setup.py
INFO:absl:Creating temporary sdist package, logs available at /tmp/tmp41fqvony/build/tfx/setup.log
INFO:absl:Added --extra_package=/tmp/tmp41fqvony/build/tfx/dist/tfx_ephemeral-1.16.0.tar.gz to beam args
DEBUG:absl:Starting Executor execution.
WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE
WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE
WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE
INFO:absl:Generating statistics for split train.
INFO:absl:Statistics for split train written to /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-train.
INFO:absl:Generating statistics for split eval.
INFO:absl:Statistics for split eval written to /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-eval.
INFO:absl:Generating statistics for split test.
INFO:absl:Statistics for split test written to /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2/Split-test.
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557926   nanos: 675874710 } message: "No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail." log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557926   nanos: 681647062 } message: "Discarding unparseable args: [\'--pipeline_type_check\', \'--direct_runner_use_stacked_bundle\']" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557926   nanos: 707295417 } message: "No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail." log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557926   nanos: 713232040 } message: "Discarding unparseable args: [\'--pipeline_type_check\', \'--direct_runner_use_stacked_bundle\']" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557926   nanos: 728281021 } message: "No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail." log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557926   nanos: 736550569 } message: "Discarding unparseable args: [\'--pipeline_type_check\', \'--direct_runner_use_stacked_bundle\']" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557926   nanos: 735099554 } message: "No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail." log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/runners/worker/sdk_worker_main.py:361" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557926   nanos: 740375041 } message: "Discarding unparseable args: [\'--pipeline_type_check\', \'--direct_runner_use_stacked_bundle\']" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/options/pipeline_options.py:386" thread: "MainThread" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557930   nanos: 793683052 } message: "Couldn\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be." instruction_id: "bundle_137" transform_id: "TFXIORead[eval]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59" thread: "Thread-13" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557930   nanos: 800972223 } message: "Couldn\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be." instruction_id: "bundle_138" transform_id: "TFXIORead[eval]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59" thread: "Thread-12" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557930   nanos: 805353641 } message: "Couldn\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be." instruction_id: "bundle_140" transform_id: "TFXIORead[eval]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59" thread: "Thread-13" 
WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1760557930   nanos: 807521104 } message: "Couldn\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be." instruction_id: "bundle_139" transform_id: "TFXIORead[eval]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process" log_location: "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/apache_beam/io/tfrecordio.py:59" thread: "Thread-14" 
INFO:absl:Cleaning up stateless execution info.
INFO:absl:Execution 2 succeeded.
INFO:absl:Cleaning up stateful execution info.
INFO:absl:Deleted stateful_working_dir /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/.system/stateful_working_dir/45bc1a0c-8c42-4d4e-b4cd-f173c358beaa
INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2"
, artifact_type: name: "ExampleStatistics"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
base_type: STATISTICS
)]}) for execution 2
INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

INFO:absl:Component StatisticsGen is finished.
INFO:absl:Component SchemaGen is running.
INFO:absl:Running launcher for node_info {
  type {
    name: "tfx.components.schema_gen.component.SchemaGen"
    base_type: PROCESS
  }
  id: "SchemaGen"
}
contexts {
  contexts {
    type {
      name: "pipeline"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline"
      }
    }
  }
  contexts {
    type {
      name: "pipeline_run"
    }
    name {
      field_value {
        string_value: "2025-10-15T19:51:34.676953"
      }
    }
  }
  contexts {
    type {
      name: "node"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline.SchemaGen"
      }
    }
  }
}
inputs {
  inputs {
    key: "statistics"
    value {
      channels {
        producer_node_query {
          id: "StatisticsGen"
        }
        context_queries {
          type {
            name: "pipeline"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline"
            }
          }
        }
        context_queries {
          type {
            name: "pipeline_run"
          }
          name {
            field_value {
              string_value: "2025-10-15T19:51:34.676953"
            }
          }
        }
        context_queries {
          type {
            name: "node"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline.StatisticsGen"
            }
          }
        }
        artifact_query {
          type {
            name: "ExampleStatistics"
            base_type: STATISTICS
          }
        }
        output_key: "statistics"
      }
      min_count: 1
    }
  }
}
outputs {
  outputs {
    key: "schema"
    value {
      artifact_spec {
        type {
          name: "Schema"
        }
      }
    }
  }
}
parameters {
  parameters {
    key: "exclude_splits"
    value {
      field_value {
        string_value: "[]"
      }
    }
  }
  parameters {
    key: "infer_feature_shape"
    value {
      field_value {
        int_value: 1
      }
    }
  }
}
upstream_nodes: "StatisticsGen"
downstream_nodes: "Transform"
execution_options {
  caching_options {
  }
}

INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

DEBUG:absl:Failed to get context of type node and name TestPythonTransformPipeline.SchemaGen
DEBUG:absl:ID of context type {
  name: "node"
}
name {
  field_value {
    string_value: "TestPythonTransformPipeline.SchemaGen"
  }
}
 is 7.
WARNING:absl:ArtifactQuery.property_predicate is not supported.
DEBUG:absl:statistics <- [
  [NO_PARTITION]: [ExampleStatistics(id=2, span=0)]
]
DEBUG:absl:Before conditional:
{statistics: [ExampleStatistics(id=2, span=0)]}
DEBUG:absl:After conditional:
{statistics: [ExampleStatistics(id=2, span=0)]}
INFO:absl:[SchemaGen] Resolved inputs: ({'statistics': [Artifact(artifact: id: 2
type_id: 17
uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2"
properties {
  key: "span"
  value {
    int_value: 0
  }
}
properties {
  key: "split_names"
  value {
    string_value: "[\"train\", \"eval\", \"test\"]"
  }
}
custom_properties {
  key: "is_external"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "sample_rate_by_split"
  value {
    struct_value {
      fields {
        key: "__value__"
        value {
          string_value: "{\"eval\": 1.0, \"test\": 1.0, \"train\": 1.0}"
        }
      }
    }
  }
}
custom_properties {
  key: "stats_dashboard_link"
  value {
    string_value: ""
  }
}
custom_properties {
  key: "tfx_version"
  value {
    string_value: "1.16.0"
  }
}
state: LIVE
type: "ExampleStatistics"
create_time_since_epoch: 1760557938907
last_update_time_since_epoch: 1760557938907
, artifact_type: id: 17
name: "ExampleStatistics"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
base_type: STATISTICS
)]},)
DEBUG:absl:Prepared EXECUTION:
 type_id: 18
last_known_state: RUNNING
custom_properties {
  key: "exclude_splits"
  value {
    string_value: "[]"
  }
}
custom_properties {
  key: "infer_feature_shape"
  value {
    int_value: 1
  }
}
name: "d9c71d13-f146-42a5-8892-cbfa2f9f0a78"

DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3
INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

DEBUG:absl:Failed to get context of type execution_cache and name 6cefa0833d0167b1458f9a95fca519664fa273f9e6ce2aa0f9f94c7e7030c09f
DEBUG:absl:ID of context type {
  name: "execution_cache"
}
name {
  field_value {
    string_value: "6cefa0833d0167b1458f9a95fca519664fa273f9e6ce2aa0f9f94c7e7030c09f"
  }
}
 is 8.
INFO:absl:Going to run a new execution 3
I0000 00:00:1760557938.984184    6957 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}
INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=3, input_dict={'statistics': [Artifact(artifact: id: 2
type_id: 17
uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/StatisticsGen/statistics/2"
properties {
  key: "span"
  value {
    int_value: 0
  }
}
properties {
  key: "split_names"
  value {
    string_value: "[\"train\", \"eval\", \"test\"]"
  }
}
custom_properties {
  key: "is_external"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "sample_rate_by_split"
  value {
    struct_value {
      fields {
        key: "__value__"
        value {
          string_value: "{\"eval\": 1.0, \"test\": 1.0, \"train\": 1.0}"
        }
      }
    }
  }
}
custom_properties {
  key: "stats_dashboard_link"
  value {
    string_value: ""
  }
}
custom_properties {
  key: "tfx_version"
  value {
    string_value: "1.16.0"
  }
}
state: LIVE
type: "ExampleStatistics"
create_time_since_epoch: 1760557938907
last_update_time_since_epoch: 1760557938907
, artifact_type: id: 17
name: "ExampleStatistics"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
base_type: STATISTICS
)]}, output_dict=defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3"
, artifact_type: name: "Schema"
)]}), exec_properties={'exclude_splits': '[]', 'infer_feature_shape': 1}, execution_output_uri='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/.system/executor_execution/3/executor_output.pb', stateful_working_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/.system/stateful_working_dir/c862b53e-d913-447f-b50c-44c008742208', tmp_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/.system/executor_execution/3/.temp/', pipeline_node=node_info {
  type {
    name: "tfx.components.schema_gen.component.SchemaGen"
    base_type: PROCESS
  }
  id: "SchemaGen"
}
contexts {
  contexts {
    type {
      name: "pipeline"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline"
      }
    }
  }
  contexts {
    type {
      name: "pipeline_run"
    }
    name {
      field_value {
        string_value: "2025-10-15T19:51:34.676953"
      }
    }
  }
  contexts {
    type {
      name: "node"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline.SchemaGen"
      }
    }
  }
}
inputs {
  inputs {
    key: "statistics"
    value {
      channels {
        producer_node_query {
          id: "StatisticsGen"
        }
        context_queries {
          type {
            name: "pipeline"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline"
            }
          }
        }
        context_queries {
          type {
            name: "pipeline_run"
          }
          name {
            field_value {
              string_value: "2025-10-15T19:51:34.676953"
            }
          }
        }
        context_queries {
          type {
            name: "node"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline.StatisticsGen"
            }
          }
        }
        artifact_query {
          type {
            name: "ExampleStatistics"
            base_type: STATISTICS
          }
        }
        output_key: "statistics"
      }
      min_count: 1
    }
  }
}
outputs {
  outputs {
    key: "schema"
    value {
      artifact_spec {
        type {
          name: "Schema"
        }
      }
    }
  }
}
parameters {
  parameters {
    key: "exclude_splits"
    value {
      field_value {
        string_value: "[]"
      }
    }
  }
  parameters {
    key: "infer_feature_shape"
    value {
      field_value {
        int_value: 1
      }
    }
  }
}
upstream_nodes: "StatisticsGen"
downstream_nodes: "Transform"
execution_options {
  caching_options {
  }
}
, pipeline_info=id: "TestPythonTransformPipeline"
, pipeline_run_id='2025-10-15T19:51:34.676953', top_level_pipeline_run_id=None, frontend_url=None)
INFO:absl:Processing schema from statistics for split train.
INFO:absl:Processing schema from statistics for split eval.
INFO:absl:Processing schema from statistics for split test.
INFO:absl:Schema written to /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3/schema.pbtxt.
INFO:absl:Cleaning up stateless execution info.
INFO:absl:Execution 3 succeeded.
INFO:absl:Cleaning up stateful execution info.
INFO:absl:Deleted stateful_working_dir /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/.system/stateful_working_dir/c862b53e-d913-447f-b50c-44c008742208
INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'schema': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3"
, artifact_type: name: "Schema"
)]}) for execution 3
INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

INFO:absl:Component SchemaGen is finished.
INFO:absl:Component Transform is running.
INFO:absl:Running launcher for node_info {
  type {
    name: "tfx.components.transform.component.Transform"
    base_type: TRANSFORM
  }
  id: "Transform"
}
contexts {
  contexts {
    type {
      name: "pipeline"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline"
      }
    }
  }
  contexts {
    type {
      name: "pipeline_run"
    }
    name {
      field_value {
        string_value: "2025-10-15T19:51:34.676953"
      }
    }
  }
  contexts {
    type {
      name: "node"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline.Transform"
      }
    }
  }
}
inputs {
  inputs {
    key: "examples"
    value {
      channels {
        producer_node_query {
          id: "MovieLensExampleGen"
        }
        context_queries {
          type {
            name: "pipeline"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline"
            }
          }
        }
        context_queries {
          type {
            name: "pipeline_run"
          }
          name {
            field_value {
              string_value: "2025-10-15T19:51:34.676953"
            }
          }
        }
        context_queries {
          type {
            name: "node"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline.MovieLensExampleGen"
            }
          }
        }
        artifact_query {
          type {
            name: "Examples"
            base_type: DATASET
          }
        }
        output_key: "output_examples"
      }
      min_count: 1
    }
  }
  inputs {
    key: "schema"
    value {
      channels {
        producer_node_query {
          id: "SchemaGen"
        }
        context_queries {
          type {
            name: "pipeline"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline"
            }
          }
        }
        context_queries {
          type {
            name: "pipeline_run"
          }
          name {
            field_value {
              string_value: "2025-10-15T19:51:34.676953"
            }
          }
        }
        context_queries {
          type {
            name: "node"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline.SchemaGen"
            }
          }
        }
        artifact_query {
          type {
            name: "Schema"
          }
        }
        output_key: "schema"
      }
      min_count: 1
    }
  }
}
outputs {
  outputs {
    key: "post_transform_anomalies"
    value {
      artifact_spec {
        type {
          name: "ExampleAnomalies"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
        }
      }
    }
  }
  outputs {
    key: "post_transform_schema"
    value {
      artifact_spec {
        type {
          name: "Schema"
        }
      }
    }
  }
  outputs {
    key: "post_transform_stats"
    value {
      artifact_spec {
        type {
          name: "ExampleStatistics"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          base_type: STATISTICS
        }
      }
    }
  }
  outputs {
    key: "pre_transform_schema"
    value {
      artifact_spec {
        type {
          name: "Schema"
        }
      }
    }
  }
  outputs {
    key: "pre_transform_stats"
    value {
      artifact_spec {
        type {
          name: "ExampleStatistics"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          base_type: STATISTICS
        }
      }
    }
  }
  outputs {
    key: "transform_graph"
    value {
      artifact_spec {
        type {
          name: "TransformGraph"
        }
      }
    }
  }
  outputs {
    key: "transformed_examples"
    value {
      artifact_spec {
        type {
          name: "Examples"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          properties {
            key: "version"
            value: INT
          }
          base_type: DATASET
        }
      }
    }
  }
  outputs {
    key: "updated_analyzer_cache"
    value {
      artifact_spec {
        type {
          name: "TransformCache"
        }
      }
    }
  }
}
parameters {
  parameters {
    key: "custom_config"
    value {
      field_value {
        string_value: "null"
      }
    }
  }
  parameters {
    key: "disable_statistics"
    value {
      field_value {
        int_value: 0
      }
    }
  }
  parameters {
    key: "force_tf_compat_v1"
    value {
      field_value {
        int_value: 0
      }
    }
  }
  parameters {
    key: "module_path"
    value {
      field_value {
        string_value: "transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl"
      }
    }
  }
}
upstream_nodes: "MovieLensExampleGen"
upstream_nodes: "SchemaGen"
execution_options {
  caching_options {
  }
}

INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

DEBUG:absl:Failed to get context of type node and name TestPythonTransformPipeline.Transform
DEBUG:absl:ID of context type {
  name: "node"
}
name {
  field_value {
    string_value: "TestPythonTransformPipeline.Transform"
  }
}
 is 9.
WARNING:absl:ArtifactQuery.property_predicate is not supported.
DEBUG:absl:examples <- [
  [NO_PARTITION]: [Examples(id=1, span=0, version=1)]
]
WARNING:absl:ArtifactQuery.property_predicate is not supported.
DEBUG:absl:schema <- [
  [NO_PARTITION]: [Schema(id=3)]
]
DEBUG:absl:Before conditional:
{schema: [Schema(id=3)], examples: [Examples(id=1, span=0, version=1)]}
DEBUG:absl:After conditional:
{schema: [Schema(id=3)], examples: [Examples(id=1, span=0, version=1)]}
INFO:absl:[Transform] Resolved inputs: ({'schema': [Artifact(artifact: id: 3
type_id: 19
uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3"
custom_properties {
  key: "is_external"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "tfx_version"
  value {
    string_value: "1.16.0"
  }
}
state: LIVE
type: "Schema"
create_time_since_epoch: 1760557939014
last_update_time_since_epoch: 1760557939014
, artifact_type: id: 19
name: "Schema"
)], 'examples': [Artifact(artifact: id: 1
type_id: 15
uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1"
properties {
  key: "span"
  value {
    int_value: 0
  }
}
properties {
  key: "split_names"
  value {
    string_value: "[\"train\", \"eval\", \"test\"]"
  }
}
properties {
  key: "version"
  value {
    int_value: 1
  }
}
custom_properties {
  key: "is_external"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "tfx_version"
  value {
    string_value: "1.16.0"
  }
}
state: LIVE
type: "Examples"
create_time_since_epoch: 1760557919866
last_update_time_since_epoch: 1760557919866
, artifact_type: id: 15
name: "Examples"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
properties {
  key: "version"
  value: INT
}
base_type: DATASET
)]},)
DEBUG:absl:Prepared EXECUTION:
 type_id: 20
last_known_state: RUNNING
custom_properties {
  key: "custom_config"
  value {
    string_value: "null"
  }
}
custom_properties {
  key: "disable_statistics"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "force_tf_compat_v1"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "module_path"
  value {
    string_value: "transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl"
  }
}
name: "f6ddabb1-982e-431a-9bf0-09b5ad46678a"

DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_schema/4
DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/updated_analyzer_cache/4
DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_anomalies/4
DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4
DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4
DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_stats/4
DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_stats/4
DEBUG:absl:Creating output artifact uri /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_schema/4
INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

DEBUG:absl:Failed to get context of type execution_cache and name c173ba1543229a7107dc5790caeb158cf10dc80bc3674d7b5cb829638c20dad6
DEBUG:absl:ID of context type {
  name: "execution_cache"
}
name {
  field_value {
    string_value: "c173ba1543229a7107dc5790caeb158cf10dc80bc3674d7b5cb829638c20dad6"
  }
}
 is 10.
INFO:absl:Going to run a new execution 4
I0000 00:00:1760557939.096676    6957 chttp2_server.cc:712] WARNING: UNKNOWN:Only 1 addresses added out of total 2 resolved {children:[UNKNOWN:socket: Address family not supported by protocol (97)]}
INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=4, input_dict={'schema': [Artifact(artifact: id: 3
type_id: 19
uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3"
custom_properties {
  key: "is_external"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "tfx_version"
  value {
    string_value: "1.16.0"
  }
}
state: LIVE
type: "Schema"
create_time_since_epoch: 1760557939014
last_update_time_since_epoch: 1760557939014
, artifact_type: id: 19
name: "Schema"
)], 'examples': [Artifact(artifact: id: 1
type_id: 15
uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1"
properties {
  key: "span"
  value {
    int_value: 0
  }
}
properties {
  key: "split_names"
  value {
    string_value: "[\"train\", \"eval\", \"test\"]"
  }
}
properties {
  key: "version"
  value {
    int_value: 1
  }
}
custom_properties {
  key: "is_external"
  value {
    int_value: 0
  }
}
custom_properties {
  key: "tfx_version"
  value {
    string_value: "1.16.0"
  }
}
state: LIVE
type: "Examples"
create_time_since_epoch: 1760557919866
last_update_time_since_epoch: 1760557919866
, artifact_type: id: 15
name: "Examples"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
properties {
  key: "version"
  value: INT
}
base_type: DATASET
)]}, output_dict=defaultdict(<class 'list'>, {'post_transform_schema': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_schema/4"
, artifact_type: name: "Schema"
)], 'updated_analyzer_cache': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/updated_analyzer_cache/4"
, artifact_type: name: "TransformCache"
)], 'post_transform_anomalies': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_anomalies/4"
, artifact_type: name: "ExampleAnomalies"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
)], 'transform_graph': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4"
, artifact_type: name: "TransformGraph"
)], 'transformed_examples': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4"
, artifact_type: name: "Examples"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
properties {
  key: "version"
  value: INT
}
base_type: DATASET
)], 'post_transform_stats': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_stats/4"
, artifact_type: name: "ExampleStatistics"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
base_type: STATISTICS
)], 'pre_transform_stats': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_stats/4"
, artifact_type: name: "ExampleStatistics"
properties {
  key: "span"
  value: INT
}
properties {
  key: "split_names"
  value: STRING
}
base_type: STATISTICS
)], 'pre_transform_schema': [Artifact(artifact: uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_schema/4"
, artifact_type: name: "Schema"
)]}), exec_properties={'module_path': 'transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl', 'disable_statistics': 0, 'custom_config': 'null', 'force_tf_compat_v1': 0}, execution_output_uri='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/.system/executor_execution/4/executor_output.pb', stateful_working_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/.system/stateful_working_dir/2878ca63-d930-4629-837b-db29b254feb0', tmp_dir='/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/.system/executor_execution/4/.temp/', pipeline_node=node_info {
  type {
    name: "tfx.components.transform.component.Transform"
    base_type: TRANSFORM
  }
  id: "Transform"
}
contexts {
  contexts {
    type {
      name: "pipeline"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline"
      }
    }
  }
  contexts {
    type {
      name: "pipeline_run"
    }
    name {
      field_value {
        string_value: "2025-10-15T19:51:34.676953"
      }
    }
  }
  contexts {
    type {
      name: "node"
    }
    name {
      field_value {
        string_value: "TestPythonTransformPipeline.Transform"
      }
    }
  }
}
inputs {
  inputs {
    key: "examples"
    value {
      channels {
        producer_node_query {
          id: "MovieLensExampleGen"
        }
        context_queries {
          type {
            name: "pipeline"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline"
            }
          }
        }
        context_queries {
          type {
            name: "pipeline_run"
          }
          name {
            field_value {
              string_value: "2025-10-15T19:51:34.676953"
            }
          }
        }
        context_queries {
          type {
            name: "node"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline.MovieLensExampleGen"
            }
          }
        }
        artifact_query {
          type {
            name: "Examples"
            base_type: DATASET
          }
        }
        output_key: "output_examples"
      }
      min_count: 1
    }
  }
  inputs {
    key: "schema"
    value {
      channels {
        producer_node_query {
          id: "SchemaGen"
        }
        context_queries {
          type {
            name: "pipeline"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline"
            }
          }
        }
        context_queries {
          type {
            name: "pipeline_run"
          }
          name {
            field_value {
              string_value: "2025-10-15T19:51:34.676953"
            }
          }
        }
        context_queries {
          type {
            name: "node"
          }
          name {
            field_value {
              string_value: "TestPythonTransformPipeline.SchemaGen"
            }
          }
        }
        artifact_query {
          type {
            name: "Schema"
          }
        }
        output_key: "schema"
      }
      min_count: 1
    }
  }
}
outputs {
  outputs {
    key: "post_transform_anomalies"
    value {
      artifact_spec {
        type {
          name: "ExampleAnomalies"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
        }
      }
    }
  }
  outputs {
    key: "post_transform_schema"
    value {
      artifact_spec {
        type {
          name: "Schema"
        }
      }
    }
  }
  outputs {
    key: "post_transform_stats"
    value {
      artifact_spec {
        type {
          name: "ExampleStatistics"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          base_type: STATISTICS
        }
      }
    }
  }
  outputs {
    key: "pre_transform_schema"
    value {
      artifact_spec {
        type {
          name: "Schema"
        }
      }
    }
  }
  outputs {
    key: "pre_transform_stats"
    value {
      artifact_spec {
        type {
          name: "ExampleStatistics"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          base_type: STATISTICS
        }
      }
    }
  }
  outputs {
    key: "transform_graph"
    value {
      artifact_spec {
        type {
          name: "TransformGraph"
        }
      }
    }
  }
  outputs {
    key: "transformed_examples"
    value {
      artifact_spec {
        type {
          name: "Examples"
          properties {
            key: "span"
            value: INT
          }
          properties {
            key: "split_names"
            value: STRING
          }
          properties {
            key: "version"
            value: INT
          }
          base_type: DATASET
        }
      }
    }
  }
  outputs {
    key: "updated_analyzer_cache"
    value {
      artifact_spec {
        type {
          name: "TransformCache"
        }
      }
    }
  }
}
parameters {
  parameters {
    key: "custom_config"
    value {
      field_value {
        string_value: "null"
      }
    }
  }
  parameters {
    key: "disable_statistics"
    value {
      field_value {
        int_value: 0
      }
    }
  }
  parameters {
    key: "force_tf_compat_v1"
    value {
      field_value {
        int_value: 0
      }
    }
  }
  parameters {
    key: "module_path"
    value {
      field_value {
        string_value: "transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl"
      }
    }
  }
}
upstream_nodes: "MovieLensExampleGen"
upstream_nodes: "SchemaGen"
execution_options {
  caching_options {
  }
}
, pipeline_info=id: "TestPythonTransformPipeline"
, pipeline_run_id='2025-10-15T19:51:34.676953', top_level_pipeline_run_id=None, frontend_url=None)
INFO:absl:Attempting to infer TFX Python dependency for beam
INFO:absl:Copying all content from install dir /usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx to temp dir /tmp/tmpx1za7_78/build/tfx
INFO:absl:Generating a temp setup file at /tmp/tmpx1za7_78/build/tfx/setup.py
INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpx1za7_78/build/tfx/setup.log
INFO:absl:Added --extra_package=/tmp/tmpx1za7_78/build/tfx/dist/tfx_ephemeral-1.16.0.tar.gz to beam args
DEBUG:absl:Starting Executor execution.
INFO:absl:Analyze the 'train' split and transform all splits when splits_config is not set.
WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE
DEBUG:absl:Using temp path /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4/.temp_path for tft.beam
INFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl', 'preprocessing_fn': None} 'preprocessing_fn'
INFO:absl:Installing '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl' to a temporary directory.
INFO:absl:Executing: ['/usr/local/envs/my_tfx_env/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmpk5usaz9_', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl']
INFO:absl:Successfully installed '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl'.
INFO:absl:udf_utils.get_fn {'module_file': None, 'module_path': 'transform_movie_lens@/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl', 'stats_options_updater_fn': None} 'stats_options_updater_fn'
INFO:absl:Installing '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl' to a temporary directory.
INFO:absl:Executing: ['/usr/local/envs/my_tfx_env/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmpt1ikqnws', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl']
INFO:absl:Successfully installed '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl'.
INFO:absl:Installing '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl' to a temporary directory.
INFO:absl:Executing: ['/usr/local/envs/my_tfx_env/bin/python', '-m', 'pip', 'install', '--target', '/tmp/tmp5vwf0219', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl']
INFO:absl:Successfully installed '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/_wheels/tfx_user_code_transform-0.0+8465016ecbbdbb6c887c4b6f3e5e2bb3cd22a98799b06268938441ecef30619a-py3-none-any.whl'.
DEBUG:absl:Inputs to executor.Transform function: {'disable_statistics': False, 'schema_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/SchemaGen/schema/3/schema.pbtxt', 'examples_data_format': 6, 'data_view_uri': None, 'analyze_data_paths': ['/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/*'], 'analyze_paths_file_formats': ['tfrecords_gzip'], 'transform_data_paths': ['/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/*', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/*', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/*'], 'transform_paths_file_formats': ['tfrecords_gzip', 'tfrecords_gzip', 'tfrecords_gzip'], 'preprocessing_fn': <function preprocessing_fn at 0x7d24540ba0e0>, 'stats_options_updater_fn': None, 'make_beam_pipeline_fn': <bound method BaseBeamExecutor._make_beam_pipeline of <tfx.components.transform.executor.Executor object at 0x7d243ef79600>>, 'force_tf_compat_v1': False, 'save_options': None}
DEBUG:absl:Outputs to executor.Transform function: {'transform_output_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4', 'transform_materialize_output_paths': ['/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-test/transformed_examples', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-train/transformed_examples', '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-eval/transformed_examples'], 'temp_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4/.temp_path', 'pre_transform_output_stats_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_stats/4', 'pre_transform_output_schema_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/pre_transform_schema/4', 'post_transform_output_anomalies_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_anomalies/4', 'post_transform_output_stats_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_stats/4', 'post_transform_output_schema_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/post_transform_schema/4', 'cache_output_path': '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/updated_analyzer_cache/4'}
DEBUG:absl:Force tf.compat.v1: False
DEBUG:absl:SaveOptions: None
DEBUG:absl:Analyze data patterns: [(0, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/*')]
DEBUG:absl:Transform data patterns: [(0, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-test/*'), (1, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-train/*'), (2, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/MovieLensExampleGen/output_examples/1/Split-eval/*')]
DEBUG:absl:Transform materialization output paths: [(0, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-test/transformed_examples'), (1, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-train/transformed_examples'), (2, '/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transformed_examples/4/Split-eval/transformed_examples')]
DEBUG:absl:Transform output path: /kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/Transform/transform_graph/4
INFO:absl:Feature genres has a shape dim {
  size: 1
}
. Setting to DenseTensor.
INFO:absl:Feature age has a shape dim {
  size: 1
}
. Setting to DenseTensor.
INFO:absl:Feature gender has a shape dim {
  size: 1
}
. Setting to DenseTensor.
INFO:absl:Feature movie_id has a shape dim {
  size: 1
}
. Setting to DenseTensor.
INFO:absl:Feature occupation has a shape dim {
  size: 1
}
. Setting to DenseTensor.
INFO:absl:Feature rating has a shape dim {
  size: 1
}
. Setting to DenseTensor.
INFO:absl:Feature timestamp has a shape dim {
  size: 1
}
. Setting to DenseTensor.
INFO:absl:Feature user_id has a shape dim {
  size: 1
}
. Setting to DenseTensor.
DEBUG:absl:inputs={'genres': <tf.Tensor 'inputs_copy:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'inputs_1_copy:0' shape=(None, 1) dtype=int64>, 'gender': <tf.Tensor 'inputs_2_copy:0' shape=(None, 1) dtype=string>, 'movie_id': <tf.Tensor 'inputs_3_copy:0' shape=(None, 1) dtype=int64>, 'occupation': <tf.Tensor 'inputs_4_copy:0' shape=(None, 1) dtype=int64>, 'rating': <tf.Tensor 'inputs_5_copy:0' shape=(None, 1) dtype=int64>, 'timestamp': <tf.Tensor 'inputs_6_copy:0' shape=(None, 1) dtype=int64>, 'user_id': <tf.Tensor 'inputs_7_copy:0' shape=(None, 1) dtype=int64>}
DEBUG:absl:inputs['genres']=Tensor("inputs_copy:0", shape=(None, 1), dtype=string)
DEBUG:absl:outputs['genres']=tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor("StringSplit/StringSplit/StringSplit/StringSplitV2:1", shape=(None,), dtype=string), row_splits=Tensor("StringSplit/StringSplit/StringSplit/RaggedFromValueRowIds/RowPartitionFromValueRowIds/concat:0", shape=(None,), dtype=int64)), row_splits=Tensor("StringSplit/RaggedFromTensor/RaggedFromUniformRowLength/RowPartitionFromUniformRowLength/mul:0", shape=(None,), dtype=int64))
DEBUG:absl:padded_tensor=Tensor("RaggedToTensor/RaggedTensorToTensor:0", shape=(None, 1, None), dtype=string)
DEBUG:absl:flattened_tensor=Tensor("Reshape:0", shape=(None,), dtype=string)
DEBUG:absl:lookup_results_flat=Tensor("None_Lookup_2/LookupTableFindV2:0", shape=(None,), dtype=int64)
DEBUG:absl:padded_tensor.shape=(None, 1, None)
INFO:absl:MetadataStore with DB connection initialized
DEBUG:absl:ConnectionConfig: sqlite {
  filename_uri: "/kaggle/working/bin/transform_1/test_MovieLensExampleGen/TestPythonTransformPipeline/tfx_metadata/metadata.db"
  connection_mode: READWRITE_OPENCREATE
}

ERROR:absl:Execution 4 failed.
INFO:absl:Cleaning up stateless execution info.
Es
======================================================================
ERROR: test_MovieLensExampleGen (transform_movie_lens_test.IngestMovieLensComponentTest)
transform_movie_lens_test.IngestMovieLensComponentTest.test_MovieLensExampleGen
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py", line 531, in _ExtractInputsAndAttrs
    inferred = ops.convert_to_tensor(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py", line 183, in wrapped
    return func(*args, **kwargs)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 713, in convert_to_tensor
    return tensor_conversion_registry.convert(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 234, in convert
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py", line 344, in _tensor_shape_tensor_conversion_function
    raise ValueError(
ValueError: Cannot convert a partially known TensorShape (None, 1, None) to a Tensor.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py", line 569, in _ExtractInputsAndAttrs
    observed = ops.convert_to_tensor(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py", line 183, in wrapped
    return func(*args, **kwargs)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 713, in convert_to_tensor
    return tensor_conversion_registry.convert(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 234, in convert
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py", line 344, in _tensor_shape_tensor_conversion_function
    raise ValueError(
ValueError: Cannot convert a partially known TensorShape (None, 1, None) to a Tensor.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/kaggle/working/transform_movie_lens_test.py", line 115, in test_MovieLensExampleGen
    tfx.orchestration.LocalDagRunner().run(my_pipeline)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/tfx_runner.py", line 124, in run
    return self.run_with_ir(pipeline_pb, run_options=run_options_pb, **kwargs)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/local/local_dag_runner.py", line 109, in run_with_ir
    component_launcher.launch()
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/launcher.py", line 613, in launch
    executor_output = self._run_executor(execution_info)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/launcher.py", line 487, in _run_executor
    executor_output = self._executor_operator.run_executor(execution_info)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/beam_executor_operator.py", line 112, in run_executor
    return python_executor_operator.run_with_executor(execution_info, executor)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/orchestration/portable/python_executor_operator.py", line 84, in run_with_executor
    result = executor.Do(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/components/transform/executor.py", line 641, in Do
    TransformProcessor().Transform(label_inputs, label_outputs, status_file)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tfx/components/transform/executor.py", line 1216, in Transform
    analyze_input_columns = tft.get_analyze_input_columns(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow_transform/inspect_preprocessing_fn.py", line 49, in get_analyze_input_columns
    impl_helper.trace_preprocessing_function(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow_transform/impl_helper.py", line 441, in trace_preprocessing_function
    return _trace_preprocessing_fn_v2(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow_transform/impl_helper.py", line 409, in _trace_preprocessing_fn_v2
    preprocessing_fn, specs, tf_graph_context).get_concrete_function()
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 1251, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 1221, in _get_concrete_function_garbage_collected
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 696, in _initialize
    self._concrete_variable_creation_fn = tracing_compilation.trace_function(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py", line 178, in trace_function
    concrete_function = _maybe_define_function(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py", line 283, in _maybe_define_function
    concrete_function = _create_concrete_function(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py", line 310, in _create_concrete_function
    traced_func_graph = func_graph_module.func_graph_from_py_func(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py", line 1059, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 599, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow_transform/impl_helper.py", line 365, in transform_fn
    transformed_features = preprocessing_fn(inputs_copy)
  File "/kaggle/working/transform_movie_lens.py", line 105, in preprocessing_fn
    lookup_results_padded = tf.reshape(lookup_results_flat, padded_tensor.shape)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py", line 88, in wrapper
    return op(*args, **kwargs)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py", line 141, in error_handler
    return fn(*args, **kwargs)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py", line 1260, in op_dispatch_handler
    return dispatch_target(*args, **kwargs)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py", line 199, in reshape
    result = gen_array_ops.reshape(tensor, shape, name)
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py", line 8758, in reshape
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py", line 778, in _apply_op_helper
    _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,
  File "/usr/local/envs/my_tfx_env/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py", line 572, in _ExtractInputsAndAttrs
    raise ValueError(
ValueError: Tried to convert 'shape' to a tensor and failed. Error: Cannot convert a partially known TensorShape (None, 1, None) to a Tensor.

----------------------------------------------------------------------
Ran 2 tests in 50.600s

FAILED (errors=1, skipped=1)
