- consider adding to pipeline:
  - transform_input_cache

- reconsider better way to pass best parameters used
  in final model to the Retrieval model (see other project).
  e.g. the signature for the serving_query model needs
  inputs that have all of the joined raw ratings input columns, 
  but the only columns
  it will use is user_id and age when feature_acronym="a".
  similarly, the serving_candidate models needs movie_id and genres.

- consider adding other model families to the
  pipeline, that is, a wrapper to use Tuner on
  each model family and then compare among best of each.
  - consider using SNAS to build a good model
    - transformer layers, dot product layers,
      feature interaction layers, embedding layers, ...
  - best practices for optimizing multi-tower NNs
  - best practices for optimizing mixture of experts (MOE) NNs

- consider adding 
  NannyML OSS: Performance estimation 
  - CBPE (for classification) and DLE (regression)

- see TODO throughout code
 
- future: consider use of ZCTAs and geohashing for 'zipcodes'

- future:
  consider modifying the custom ingest components to add 3 properties 
  to make the data and configuration self-consistent:
    add properties max_user_id,max_movie_id, and n_genres
    to the output_examples.
    add dataset count from beam.combiners.Count.Globally().
    add versioning of datasets.
  the standard_artifact.Examples would need to be extended to
  include those properties:
    class AugmentedExamples(standard_artifacts.Examples):
      max_user_id = Property(type=PropertyType.INT)
      max_movie_id = Property(type=PropertyType.INT)
      n_genres = Property(type=PropertyType.INT)
  Then in the Do method of the Executor:
    use PTransforms to calculate those numbers from the 
    input users.dat and movies.dat files.
    And set them in the output:
    iutput_examples_artifact = artifact_utils.get_single_artifact(
        output_dict['output_examples'])
    output_examples_artifact.max_user_id = max_user_id
     ...
   -> problem is that currently, cannot pass that data as Channels
      to components that could use them like Tuner and Trainer

- CI/CD
  - a linter usable w/ terraform:
    https://www.markcallen.com/tflint-static-analysis-for-terraform/
